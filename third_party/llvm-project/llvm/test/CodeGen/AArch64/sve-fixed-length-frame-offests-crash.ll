; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s | FileCheck %s

target triple = "aarch64-unknown-linux-gnu"

; Ensure we don't crash by trying to fold fixed length frame indexes into
; loads/stores that don't support an appropriate addressing mode, hence creating
; too many extra vregs during frame lowering, when we don't have an emergency
; spill slot.

define dso_local void @func1(i64* %v1, i64* %v2, i64* %v3, i64* %v4, i64* %v5, i64* %v6, i64* %v7, i64* %v8,
; CHECK-LABEL: func1:
; CHECK:       // %bb.0:
; CHECK-NEXT:    str x25, [sp, #-64]! // 8-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 64
; CHECK-NEXT:    stp x24, x23, [sp, #16] // 16-byte Folded Spill
; CHECK-NEXT:    stp x22, x21, [sp, #32] // 16-byte Folded Spill
; CHECK-NEXT:    stp x20, x19, [sp, #48] // 16-byte Folded Spill
; CHECK-NEXT:    .cfi_offset w19, -8
; CHECK-NEXT:    .cfi_offset w20, -16
; CHECK-NEXT:    .cfi_offset w21, -24
; CHECK-NEXT:    .cfi_offset w22, -32
; CHECK-NEXT:    .cfi_offset w23, -40
; CHECK-NEXT:    .cfi_offset w24, -48
; CHECK-NEXT:    .cfi_offset w25, -64
; CHECK-NEXT:    add x8, sp, #64
; CHECK-NEXT:    add x9, sp, #128
; CHECK-NEXT:    add x10, sp, #160
; CHECK-NEXT:    add x11, sp, #192
; CHECK-NEXT:    ptrue p0.d
; CHECK-NEXT:    add x20, sp, #192
; CHECK-NEXT:    ld1d { z0.d }, p0/z, [x8]
; CHECK-NEXT:    ld1d { z1.d }, p0/z, [x9]
; CHECK-NEXT:    ld1d { z2.d }, p0/z, [x10]
; CHECK-NEXT:    ld1d { z3.d }, p0/z, [x11]
; CHECK-NEXT:    ldp x18, x19, [sp, #368]
; CHECK-NEXT:    add x21, sp, #160
; CHECK-NEXT:    add x22, sp, #128
; CHECK-NEXT:    ldp x24, x14, [sp, #296]
; CHECK-NEXT:    add x23, sp, #64
; CHECK-NEXT:    ldr x25, [sp, #288]
; CHECK-NEXT:    ldp x9, x8, [sp, #344]
; CHECK-NEXT:    ldp x11, x10, [sp, #328]
; CHECK-NEXT:    ldp x13, x12, [sp, #312]
; CHECK-NEXT:    ldr x15, [sp, #120]
; CHECK-NEXT:    ldur q4, [sp, #104]
; CHECK-NEXT:    ldp x16, x17, [sp, #224]
; CHECK-NEXT:    st1d { z3.d }, p0, [x20]
; CHECK-NEXT:    st1d { z2.d }, p0, [x21]
; CHECK-NEXT:    st1d { z1.d }, p0, [x22]
; CHECK-NEXT:    st1d { z0.d }, p0, [x23]
; CHECK-NEXT:    stp x18, x19, [sp, #368]
; CHECK-NEXT:    stp x25, x24, [sp, #288]
; CHECK-NEXT:    ldp x20, x19, [sp, #48] // 16-byte Folded Reload
; CHECK-NEXT:    stp x16, x17, [sp, #224]
; CHECK-NEXT:    ldp x22, x21, [sp, #32] // 16-byte Folded Reload
; CHECK-NEXT:    stur q4, [sp, #104]
; CHECK-NEXT:    ldp x24, x23, [sp, #16] // 16-byte Folded Reload
; CHECK-NEXT:    str x15, [sp, #120]
; CHECK-NEXT:    stp x14, x13, [sp, #304]
; CHECK-NEXT:    stp x12, x11, [sp, #320]
; CHECK-NEXT:    stp x10, x9, [sp, #336]
; CHECK-NEXT:    str x8, [sp, #352]
; CHECK-NEXT:    ldr x25, [sp], #64 // 8-byte Folded Reload
; CHECK-NEXT:    b func2
                             i64* %v9, i64* %v10, i64* %v11, i64* %v12, i64* %v13, i64* %v14,  i64* %v15, i64* %v16,
                             i64* %v17, i64* %v18, i64* %v19, i64* %v20, i64* %v21, i64* %v22, i64* %v23, i64* %v24,
                             i64* %v25, i64* %v26, i64* %v27, i64* %v28, i64* %v29, i64* %v30, i64* %v31, i64* %v32,
                             i64* %v33, i64* %v34, i64* %v35, i64* %v36, i64* %v37, i64* %v38, i64* %v39, i64* %v40,
                             i64* %v41, i64* %v42, i64* %v43, i64* %v44, i64* %v45, i64* %v46, i64* %v47, i64* %v48,
                             i64 %v49) #0 {
  tail call void @func2(i64* %v1, i64* %v2, i64* %v3, i64* %v4, i64* %v5, i64* %v6, i64* %v7, i64* %v8,
                        i64* %v9, i64* %v10, i64* %v11, i64* %v12, i64* undef, i64* %v14, i64* %v15, i64* %v16,
                        i64* %v17, i64* %v18, i64* %v19, i64* %v20, i64* %v21, i64* %v22, i64* %v23, i64* %v24,
                        i64* %v25, i64* %v26, i64* %v27, i64* %v28, i64* %v29, i64* %v30, i64* undef, i64* undef,
                        i64* undef, i64* undef, i64* undef, i64* undef, i64* %v37, i64* %v38, i64* %v39, i64* %v40,
                        i64* %v41, i64* %v42, i64* %v43, i64* %v44, i64* %v45, i64* undef, i64* %v47, i64* %v48,
                        i64 undef)
  ret void
}

declare dso_local void @func2(i64*, i64*, i64*, i64*, i64*, i64*, i64*, i64*,
                              i64*, i64*, i64*, i64*, i64*, i64*, i64*, i64*,
                              i64*, i64*, i64*, i64*, i64*, i64*, i64*, i64*,
                              i64*, i64*, i64*, i64*, i64*, i64*, i64*, i64*,
                              i64*, i64*, i64*, i64*, i64*, i64*, i64*, i64*,
                              i64*, i64*, i64*, i64*, i64*, i64*, i64*, i64*,
                              i64)

attributes #0 = { "target-features"="+sve" vscale_range(2,2) }
