; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc < %s -mtriple=aarch64 -mattr=+mte | FileCheck %s

define void @stg1(i8* %p) {
; CHECK-LABEL: stg1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    stg x0, [x0]
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag(i8* %p, i64 16)
  ret void
}

define void @stg2(i8* %p) {
; CHECK-LABEL: stg2:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    st2g x0, [x0]
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag(i8* %p, i64 32)
  ret void
}

define void @stg3(i8* %p) {
; CHECK-LABEL: stg3:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    stg x0, [x0, #32]
; CHECK-NEXT:    st2g x0, [x0]
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag(i8* %p, i64 48)
  ret void
}

define void @stg4(i8* %p) {
; CHECK-LABEL: stg4:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    st2g x0, [x0, #32]
; CHECK-NEXT:    st2g x0, [x0]
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag(i8* %p, i64 64)
  ret void
}

define void @stg5(i8* %p) {
; CHECK-LABEL: stg5:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    stg x0, [x0, #64]
; CHECK-NEXT:    st2g x0, [x0, #32]
; CHECK-NEXT:    st2g x0, [x0]
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag(i8* %p, i64 80)
  ret void
}

define void @stg16(i8* %p) {
; CHECK-LABEL: stg16:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    mov x8, #256
; CHECK-NEXT:  .LBB5_1: // %entry
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    sub x8, x8, #32
; CHECK-NEXT:    st2g x0, [x0], #32
; CHECK-NEXT:    cbnz x8, .LBB5_1
; CHECK-NEXT:  // %bb.2: // %entry
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag(i8* %p, i64 256)
  ret void
}

define void @stg17(i8* %p) {
; CHECK-LABEL: stg17:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    mov x8, #256
; CHECK-NEXT:    stg x0, [x0], #16
; CHECK-NEXT:  .LBB6_1: // %entry
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    sub x8, x8, #32
; CHECK-NEXT:    st2g x0, [x0], #32
; CHECK-NEXT:    cbnz x8, .LBB6_1
; CHECK-NEXT:  // %bb.2: // %entry
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag(i8* %p, i64 272)
  ret void
}

define void @stzg3(i8* %p) {
; CHECK-LABEL: stzg3:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    stzg x0, [x0, #32]
; CHECK-NEXT:    stz2g x0, [x0]
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag.zero(i8* %p, i64 48)
  ret void
}

define void @stzg17(i8* %p) {
; CHECK-LABEL: stzg17:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    mov x8, #256
; CHECK-NEXT:    stzg x0, [x0], #16
; CHECK-NEXT:  .LBB8_1: // %entry
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    sub x8, x8, #32
; CHECK-NEXT:    stz2g x0, [x0], #32
; CHECK-NEXT:    cbnz x8, .LBB8_1
; CHECK-NEXT:  // %bb.2: // %entry
; CHECK-NEXT:    ret
entry:
  call void @llvm.aarch64.settag.zero(i8* %p, i64 272)
  ret void
}

define void @stg_alloca1() {
; CHECK-LABEL: stg_alloca1:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    sub sp, sp, #16
; CHECK-NEXT:    .cfi_def_cfa_offset 16
; CHECK-NEXT:    stg sp, [sp], #16
; CHECK-NEXT:    ret
entry:
  %a = alloca i8, i32 16, align 16
  call void @llvm.aarch64.settag(i8* %a, i64 16)
  ret void
}

define void @stg_alloca5() {
; CHECK-LABEL: stg_alloca5:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    sub sp, sp, #80
; CHECK-NEXT:    .cfi_def_cfa_offset 80
; CHECK-NEXT:    st2g sp, [sp, #32]
; CHECK-NEXT:    stg sp, [sp, #64]
; CHECK-NEXT:    st2g sp, [sp], #80
; CHECK-NEXT:    ret
entry:
  %a = alloca i8, i32 80, align 16
  call void @llvm.aarch64.settag(i8* %a, i64 80)
  ret void
}

define void @stg_alloca17() {
; CHECK-LABEL: stg_alloca17:
; CHECK:       // %bb.0: // %entry
; CHECK-NEXT:    sub sp, sp, #288
; CHECK-NEXT:    str x29, [sp, #272] // 8-byte Folded Spill
; CHECK-NEXT:    .cfi_def_cfa_offset 288
; CHECK-NEXT:    .cfi_offset w29, -16
; CHECK-NEXT:    mov x8, #256
; CHECK-NEXT:  .LBB11_1: // %entry
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    st2g sp, [sp], #32
; CHECK-NEXT:    sub x8, x8, #32
; CHECK-NEXT:    cbnz x8, .LBB11_1
; CHECK-NEXT:  // %bb.2: // %entry
; CHECK-NEXT:    stg sp, [sp], #16
; CHECK-NEXT:    ldr x29, [sp], #16 // 8-byte Folded Reload
; CHECK-NEXT:    ret
entry:
  %a = alloca i8, i32 272, align 16
  call void @llvm.aarch64.settag(i8* %a, i64 272)
  ret void
}

declare void @llvm.aarch64.settag(i8* %p, i64 %a)
declare void @llvm.aarch64.settag.zero(i8* %p, i64 %a)
