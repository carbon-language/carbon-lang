; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -ppc-asm-full-reg-names -mtriple=powerpc64le-unknown-linux-gnu \
; RUN:   %s -o - -verify-machineinstrs -mcpu=pwr9 | FileCheck %s

define <4 x i32> @test(<4 x i32> %a, <4 x i32> %b, <4 x i32> %aa, <8 x i16>* %FromVSCR) {
; CHECK-LABEL: test:
; CHECK:       # %bb.0: # %entry
; CHECK-NEXT:    vsumsws v5, v2, v3
; CHECK-NEXT:    xxlxor vs32, vs32, vs32
; CHECK-NEXT:    mtvscr v0
; CHECK-NEXT:    vadduwm v0, v3, v2
; CHECK-NEXT:    vpkswus v2, v2, v3
; CHECK-NEXT:    mfvscr v1
; CHECK-NEXT:    stxv vs33, 0(r9)
; CHECK-NEXT:    vpkswus v3, v3, v4
; CHECK-NEXT:    vadduwm v4, v0, v5
; CHECK-NEXT:    vadduwm v2, v4, v2
; CHECK-NEXT:    vadduwm v2, v2, v3
; CHECK-NEXT:    blr
entry:
  %0 = tail call <4 x i32> @llvm.ppc.altivec.vsumsws(<4 x i32> %a, <4 x i32> %b)
  tail call void @llvm.ppc.altivec.mtvscr(<4 x i32> zeroinitializer)
  %add = add <4 x i32> %b, %a
  %1 = tail call <8 x i16> @llvm.ppc.altivec.vpkswus(<4 x i32> %a, <4 x i32> %b)
  %2 = bitcast <8 x i16> %1 to <4 x i32>
  %3 = tail call <8 x i16> @llvm.ppc.altivec.mfvscr()
  store <8 x i16> %3, <8 x i16>* %FromVSCR, align 16
  %4 = tail call <8 x i16> @llvm.ppc.altivec.vpkswus(<4 x i32> %b, <4 x i32> %aa)
  %5 = bitcast <8 x i16> %4 to <4 x i32>
  %add1 = add <4 x i32> %add, %0
  %add2 = add <4 x i32> %add1, %2
  %add3 = add <4 x i32> %add2, %5
  ret <4 x i32> %add3
}

declare <4 x i32> @llvm.ppc.altivec.vsumsws(<4 x i32>, <4 x i32>) #1

declare void @llvm.ppc.altivec.mtvscr(<4 x i32>) #1

declare <8 x i16> @llvm.ppc.altivec.vpkswus(<4 x i32>, <4 x i32>) #1

declare <8 x i16> @llvm.ppc.altivec.mfvscr() #1

