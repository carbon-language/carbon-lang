; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: llc -march=amdgcn -amdgpu-atomic-optimizations=true -verify-machineinstrs < %s | FileCheck -enable-var-scope -check-prefixes=GFX6 %s
; RUN: llc -march=amdgcn -mcpu=tonga -amdgpu-atomic-optimizations=true -verify-machineinstrs < %s | FileCheck -enable-var-scope -check-prefixes=GFX8 %s
; RUN: llc -march=amdgcn -mcpu=gfx900 -amdgpu-atomic-optimizations=true -verify-machineinstrs < %s | FileCheck -enable-var-scope -check-prefixes=GFX9 %s
; RUN: llc -march=amdgcn -mcpu=gfx1010 -mattr=-wavefrontsize32,+wavefrontsize64 -amdgpu-atomic-optimizations=true -verify-machineinstrs < %s | FileCheck -enable-var-scope -check-prefixes=GFX10,GFX10W64 %s
; RUN: llc -march=amdgcn -mcpu=gfx1010 -mattr=+wavefrontsize32,-wavefrontsize64 -amdgpu-atomic-optimizations=true -verify-machineinstrs < %s | FileCheck -enable-var-scope -check-prefixes=GFX10,GFX10W32 %s

declare i32 @llvm.amdgcn.workitem.id.x()
declare i32 @llvm.amdgcn.raw.buffer.atomic.add(i32, <4 x i32>, i32, i32, i32)
declare i32 @llvm.amdgcn.raw.buffer.atomic.sub(i32, <4 x i32>, i32, i32, i32)

; Show what the atomic optimization pass will do for raw buffers.

define amdgpu_kernel void @add_i32_constant(i32 addrspace(1)* %out, <4 x i32> %inout) {
; GFX6-LABEL: add_i32_constant:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_mov_b64 s[2:3], exec
; GFX6-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GFX6-NEXT:    v_mbcnt_lo_u32_b32_e64 v0, s2, 0
; GFX6-NEXT:    v_mbcnt_hi_u32_b32_e32 v0, s3, v0
; GFX6-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX6-NEXT:    ; implicit-def: $vgpr1
; GFX6-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX6-NEXT:    s_cbranch_execz .LBB0_2
; GFX6-NEXT:  ; %bb.1:
; GFX6-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GFX6-NEXT:    s_bcnt1_i32_b64 s0, s[2:3]
; GFX6-NEXT:    s_mul_i32 s0, s0, 5
; GFX6-NEXT:    v_mov_b32_e32 v1, s0
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_atomic_add v1, off, s[8:11], 0 glc
; GFX6-NEXT:  .LBB0_2:
; GFX6-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    v_readfirstlane_b32 s0, v1
; GFX6-NEXT:    s_mov_b32 s7, 0xf000
; GFX6-NEXT:    v_mad_u32_u24 v0, v0, 5, s0
; GFX6-NEXT:    s_mov_b32 s6, -1
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: add_i32_constant:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX8-NEXT:    s_mov_b64 s[6:7], exec
; GFX8-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX8-NEXT:    v_mbcnt_hi_u32_b32 v0, s7, v0
; GFX8-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX8-NEXT:    ; implicit-def: $vgpr1
; GFX8-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX8-NEXT:    s_cbranch_execz .LBB0_2
; GFX8-NEXT:  ; %bb.1:
; GFX8-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX8-NEXT:    s_bcnt1_i32_b64 s0, s[6:7]
; GFX8-NEXT:    s_mul_i32 s0, s0, 5
; GFX8-NEXT:    v_mov_b32_e32 v1, s0
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    buffer_atomic_add v1, off, s[8:11], 0 glc
; GFX8-NEXT:  .LBB0_2:
; GFX8-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    v_readfirstlane_b32 s0, v1
; GFX8-NEXT:    v_mad_u32_u24 v2, v0, 5, s0
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    v_mov_b32_e32 v0, s2
; GFX8-NEXT:    v_mov_b32_e32 v1, s3
; GFX8-NEXT:    flat_store_dword v[0:1], v2
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: add_i32_constant:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX9-NEXT:    s_mov_b64 s[6:7], exec
; GFX9-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX9-NEXT:    v_mbcnt_hi_u32_b32 v0, s7, v0
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX9-NEXT:    ; implicit-def: $vgpr1
; GFX9-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX9-NEXT:    s_cbranch_execz .LBB0_2
; GFX9-NEXT:  ; %bb.1:
; GFX9-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX9-NEXT:    s_bcnt1_i32_b64 s0, s[6:7]
; GFX9-NEXT:    s_mul_i32 s0, s0, 5
; GFX9-NEXT:    v_mov_b32_e32 v1, s0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    buffer_atomic_add v1, off, s[8:11], 0 glc
; GFX9-NEXT:  .LBB0_2:
; GFX9-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v1
; GFX9-NEXT:    v_mad_u32_u24 v0, v0, 5, s0
; GFX9-NEXT:    v_mov_b32_e32 v1, 0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX9-NEXT:    s_endpgm
;
; GFX10W64-LABEL: add_i32_constant:
; GFX10W64:       ; %bb.0: ; %entry
; GFX10W64-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W64-NEXT:    s_mov_b64 s[6:7], exec
; GFX10W64-NEXT:    ; implicit-def: $vgpr1
; GFX10W64-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX10W64-NEXT:    v_mbcnt_hi_u32_b32 v0, s7, v0
; GFX10W64-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX10W64-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX10W64-NEXT:    s_cbranch_execz .LBB0_2
; GFX10W64-NEXT:  ; %bb.1:
; GFX10W64-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W64-NEXT:    s_bcnt1_i32_b64 s0, s[6:7]
; GFX10W64-NEXT:    s_mul_i32 s0, s0, 5
; GFX10W64-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    buffer_atomic_add v1, off, s[8:11], 0 glc
; GFX10W64-NEXT:  .LBB0_2:
; GFX10W64-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W64-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX10W64-NEXT:    s_waitcnt vmcnt(0)
; GFX10W64-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W64-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W64-NEXT:    v_mad_u32_u24 v0, v0, 5, s0
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W64-NEXT:    s_endpgm
;
; GFX10W32-LABEL: add_i32_constant:
; GFX10W32:       ; %bb.0: ; %entry
; GFX10W32-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W32-NEXT:    s_mov_b32 s5, exec_lo
; GFX10W32-NEXT:    ; implicit-def: $vgpr1
; GFX10W32-NEXT:    v_mbcnt_lo_u32_b32 v0, s5, 0
; GFX10W32-NEXT:    v_cmp_eq_u32_e32 vcc_lo, 0, v0
; GFX10W32-NEXT:    s_and_saveexec_b32 s4, vcc_lo
; GFX10W32-NEXT:    s_cbranch_execz .LBB0_2
; GFX10W32-NEXT:  ; %bb.1:
; GFX10W32-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W32-NEXT:    s_bcnt1_i32_b32 s0, s5
; GFX10W32-NEXT:    s_mul_i32 s0, s0, 5
; GFX10W32-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    buffer_atomic_add v1, off, s[8:11], 0 glc
; GFX10W32-NEXT:  .LBB0_2:
; GFX10W32-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W32-NEXT:    s_or_b32 exec_lo, exec_lo, s4
; GFX10W32-NEXT:    s_waitcnt vmcnt(0)
; GFX10W32-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W32-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W32-NEXT:    v_mad_u32_u24 v0, v0, 5, s0
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W32-NEXT:    s_endpgm
entry:
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.add(i32 5, <4 x i32> %inout, i32 0, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @add_i32_uniform(i32 addrspace(1)* %out, <4 x i32> %inout, i32 %additive) {
; GFX6-LABEL: add_i32_uniform:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_mov_b64 s[2:3], exec
; GFX6-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GFX6-NEXT:    s_load_dword s8, s[0:1], 0x11
; GFX6-NEXT:    v_mbcnt_lo_u32_b32_e64 v0, s2, 0
; GFX6-NEXT:    v_mbcnt_hi_u32_b32_e32 v0, s3, v0
; GFX6-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX6-NEXT:    ; implicit-def: $vgpr1
; GFX6-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX6-NEXT:    s_cbranch_execz .LBB1_2
; GFX6-NEXT:  ; %bb.1:
; GFX6-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0xd
; GFX6-NEXT:    s_bcnt1_i32_b64 s0, s[2:3]
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    s_mul_i32 s0, s8, s0
; GFX6-NEXT:    v_mov_b32_e32 v1, s0
; GFX6-NEXT:    buffer_atomic_add v1, off, s[12:15], 0 glc
; GFX6-NEXT:  .LBB1_2:
; GFX6-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    v_readfirstlane_b32 s0, v1
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    v_mul_lo_u32 v0, s8, v0
; GFX6-NEXT:    s_mov_b32 s7, 0xf000
; GFX6-NEXT:    v_add_i32_e32 v0, vcc, s0, v0
; GFX6-NEXT:    s_mov_b32 s6, -1
; GFX6-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: add_i32_uniform:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX8-NEXT:    s_load_dword s8, s[0:1], 0x44
; GFX8-NEXT:    s_mov_b64 s[4:5], exec
; GFX8-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX8-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX8-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX8-NEXT:    ; implicit-def: $vgpr1
; GFX8-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX8-NEXT:    s_cbranch_execz .LBB1_2
; GFX8-NEXT:  ; %bb.1:
; GFX8-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0x34
; GFX8-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    s_mul_i32 s0, s8, s0
; GFX8-NEXT:    v_mov_b32_e32 v1, s0
; GFX8-NEXT:    buffer_atomic_add v1, off, s[12:15], 0 glc
; GFX8-NEXT:  .LBB1_2:
; GFX8-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    v_mul_lo_u32 v0, s8, v0
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    v_readfirstlane_b32 s0, v1
; GFX8-NEXT:    v_add_u32_e32 v2, vcc, s0, v0
; GFX8-NEXT:    v_mov_b32_e32 v0, s2
; GFX8-NEXT:    v_mov_b32_e32 v1, s3
; GFX8-NEXT:    flat_store_dword v[0:1], v2
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: add_i32_uniform:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX9-NEXT:    s_load_dword s8, s[0:1], 0x44
; GFX9-NEXT:    s_mov_b64 s[4:5], exec
; GFX9-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX9-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX9-NEXT:    ; implicit-def: $vgpr1
; GFX9-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX9-NEXT:    s_cbranch_execz .LBB1_2
; GFX9-NEXT:  ; %bb.1:
; GFX9-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0x34
; GFX9-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_mul_i32 s0, s8, s0
; GFX9-NEXT:    v_mov_b32_e32 v1, s0
; GFX9-NEXT:    buffer_atomic_add v1, off, s[12:15], 0 glc
; GFX9-NEXT:  .LBB1_2:
; GFX9-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    v_mul_lo_u32 v0, s8, v0
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v1
; GFX9-NEXT:    v_mov_b32_e32 v1, 0
; GFX9-NEXT:    v_add_u32_e32 v0, s0, v0
; GFX9-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX9-NEXT:    s_endpgm
;
; GFX10W64-LABEL: add_i32_uniform:
; GFX10W64:       ; %bb.0: ; %entry
; GFX10W64-NEXT:    s_clause 0x1
; GFX10W64-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W64-NEXT:    s_load_dword s8, s[0:1], 0x44
; GFX10W64-NEXT:    s_mov_b64 s[4:5], exec
; GFX10W64-NEXT:    ; implicit-def: $vgpr1
; GFX10W64-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX10W64-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX10W64-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX10W64-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX10W64-NEXT:    s_cbranch_execz .LBB1_2
; GFX10W64-NEXT:  ; %bb.1:
; GFX10W64-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0x34
; GFX10W64-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    s_mul_i32 s0, s8, s0
; GFX10W64-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W64-NEXT:    buffer_atomic_add v1, off, s[12:15], 0 glc
; GFX10W64-NEXT:  .LBB1_2:
; GFX10W64-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W64-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX10W64-NEXT:    s_waitcnt vmcnt(0)
; GFX10W64-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    v_mad_u64_u32 v[0:1], null, s8, v0, s[0:1]
; GFX10W64-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W64-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W64-NEXT:    s_endpgm
;
; GFX10W32-LABEL: add_i32_uniform:
; GFX10W32:       ; %bb.0: ; %entry
; GFX10W32-NEXT:    s_clause 0x1
; GFX10W32-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W32-NEXT:    s_load_dword s4, s[0:1], 0x44
; GFX10W32-NEXT:    s_mov_b32 s6, exec_lo
; GFX10W32-NEXT:    ; implicit-def: $vgpr1
; GFX10W32-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX10W32-NEXT:    v_cmp_eq_u32_e32 vcc_lo, 0, v0
; GFX10W32-NEXT:    s_and_saveexec_b32 s5, vcc_lo
; GFX10W32-NEXT:    s_cbranch_execz .LBB1_2
; GFX10W32-NEXT:  ; %bb.1:
; GFX10W32-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W32-NEXT:    s_bcnt1_i32_b32 s0, s6
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    s_mul_i32 s0, s4, s0
; GFX10W32-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W32-NEXT:    buffer_atomic_add v1, off, s[8:11], 0 glc
; GFX10W32-NEXT:  .LBB1_2:
; GFX10W32-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W32-NEXT:    s_or_b32 exec_lo, exec_lo, s5
; GFX10W32-NEXT:    s_waitcnt vmcnt(0)
; GFX10W32-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    v_mad_u64_u32 v[0:1], null, s4, v0, s[0:1]
; GFX10W32-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W32-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W32-NEXT:    s_endpgm
entry:
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.add(i32 %additive, <4 x i32> %inout, i32 0, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @add_i32_varying_vdata(i32 addrspace(1)* %out, <4 x i32> %inout) {
; GFX6-LABEL: add_i32_varying_vdata:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0xd
; GFX6-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_atomic_add v0, off, s[4:7], 0 glc
; GFX6-NEXT:    s_mov_b32 s3, 0xf000
; GFX6-NEXT:    s_mov_b32 s2, -1
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: add_i32_varying_vdata:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX8-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX8-NEXT:    v_mov_b32_e32 v1, 0
; GFX8-NEXT:    s_mov_b64 exec, s[4:5]
; GFX8-NEXT:    v_mbcnt_lo_u32_b32 v3, exec_lo, 0
; GFX8-NEXT:    v_mbcnt_hi_u32_b32 v3, exec_hi, v3
; GFX8-NEXT:    v_mov_b32_e32 v2, v0
; GFX8-NEXT:    s_not_b64 exec, exec
; GFX8-NEXT:    v_mov_b32_e32 v2, 0
; GFX8-NEXT:    s_not_b64 exec, exec
; GFX8-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_bcast:15 row_mask:0xa bank_mask:0xf
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_bcast:31 row_mask:0xc bank_mask:0xf
; GFX8-NEXT:    v_readlane_b32 s6, v2, 63
; GFX8-NEXT:    s_nop 0
; GFX8-NEXT:    v_mov_b32_dpp v1, v2 wave_shr:1 row_mask:0xf bank_mask:0xf
; GFX8-NEXT:    s_mov_b64 exec, s[4:5]
; GFX8-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v3
; GFX8-NEXT:    ; implicit-def: $vgpr0
; GFX8-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX8-NEXT:    s_cbranch_execz .LBB2_2
; GFX8-NEXT:  ; %bb.1:
; GFX8-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX8-NEXT:    v_mov_b32_e32 v0, s6
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    buffer_atomic_add v0, off, s[8:11], 0 glc
; GFX8-NEXT:  .LBB2_2:
; GFX8-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    v_readfirstlane_b32 s0, v0
; GFX8-NEXT:    v_mov_b32_e32 v0, v1
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    v_mov_b32_e32 v4, s3
; GFX8-NEXT:    v_add_u32_e32 v0, vcc, s0, v0
; GFX8-NEXT:    v_mov_b32_e32 v3, s2
; GFX8-NEXT:    flat_store_dword v[3:4], v0
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: add_i32_varying_vdata:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX9-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX9-NEXT:    v_mov_b32_e32 v1, 0
; GFX9-NEXT:    s_mov_b64 exec, s[4:5]
; GFX9-NEXT:    v_mbcnt_lo_u32_b32 v3, exec_lo, 0
; GFX9-NEXT:    v_mbcnt_hi_u32_b32 v3, exec_hi, v3
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    s_not_b64 exec, exec
; GFX9-NEXT:    v_mov_b32_e32 v2, 0
; GFX9-NEXT:    s_not_b64 exec, exec
; GFX9-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_bcast:15 row_mask:0xa bank_mask:0xf
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_bcast:31 row_mask:0xc bank_mask:0xf
; GFX9-NEXT:    v_readlane_b32 s6, v2, 63
; GFX9-NEXT:    s_nop 0
; GFX9-NEXT:    v_mov_b32_dpp v1, v2 wave_shr:1 row_mask:0xf bank_mask:0xf
; GFX9-NEXT:    s_mov_b64 exec, s[4:5]
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v3
; GFX9-NEXT:    ; implicit-def: $vgpr0
; GFX9-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX9-NEXT:    s_cbranch_execz .LBB2_2
; GFX9-NEXT:  ; %bb.1:
; GFX9-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX9-NEXT:    v_mov_b32_e32 v0, s6
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    buffer_atomic_add v0, off, s[8:11], 0 glc
; GFX9-NEXT:  .LBB2_2:
; GFX9-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v0
; GFX9-NEXT:    v_mov_b32_e32 v0, v1
; GFX9-NEXT:    v_add_u32_e32 v0, s0, v0
; GFX9-NEXT:    v_mov_b32_e32 v3, 0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v3, v0, s[2:3]
; GFX9-NEXT:    s_endpgm
;
; GFX10W64-LABEL: add_i32_varying_vdata:
; GFX10W64:       ; %bb.0: ; %entry
; GFX10W64-NEXT:    v_mov_b32_e32 v1, v0
; GFX10W64-NEXT:    s_not_b64 exec, exec
; GFX10W64-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W64-NEXT:    s_not_b64 exec, exec
; GFX10W64-NEXT:    s_or_saveexec_b64 s[2:3], -1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_mov_b32_e32 v3, 0
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_mov_b32_e32 v2, v1
; GFX10W64-NEXT:    v_permlanex16_b32 v2, v2, -1, -1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v2, v1 quad_perm:[0,1,2,3] row_mask:0xa bank_mask:0xf
; GFX10W64-NEXT:    v_readlane_b32 s4, v1, 31
; GFX10W64-NEXT:    v_mov_b32_e32 v2, s4
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v2, v1 quad_perm:[0,1,2,3] row_mask:0xc bank_mask:0xf
; GFX10W64-NEXT:    v_readlane_b32 s6, v1, 15
; GFX10W64-NEXT:    v_mov_b32_dpp v3, v1 row_shr:1 row_mask:0xf bank_mask:0xf
; GFX10W64-NEXT:    s_mov_b64 exec, s[2:3]
; GFX10W64-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W64-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX10W64-NEXT:    v_readlane_b32 s7, v1, 31
; GFX10W64-NEXT:    v_writelane_b32 v3, s6, 16
; GFX10W64-NEXT:    s_mov_b64 exec, s[4:5]
; GFX10W64-NEXT:    v_mbcnt_lo_u32_b32 v0, exec_lo, 0
; GFX10W64-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX10W64-NEXT:    v_readlane_b32 s6, v1, 63
; GFX10W64-NEXT:    v_readlane_b32 s8, v1, 47
; GFX10W64-NEXT:    v_writelane_b32 v3, s7, 32
; GFX10W64-NEXT:    s_mov_b64 exec, s[4:5]
; GFX10W64-NEXT:    v_mbcnt_hi_u32_b32 v0, exec_hi, v0
; GFX10W64-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX10W64-NEXT:    v_writelane_b32 v3, s8, 48
; GFX10W64-NEXT:    s_mov_b64 exec, s[4:5]
; GFX10W64-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX10W64-NEXT:    ; implicit-def: $vgpr0
; GFX10W64-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX10W64-NEXT:    s_cbranch_execz .LBB2_2
; GFX10W64-NEXT:  ; %bb.1:
; GFX10W64-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W64-NEXT:    v_mov_b32_e32 v0, s6
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    buffer_atomic_add v0, off, s[8:11], 0 glc
; GFX10W64-NEXT:  .LBB2_2:
; GFX10W64-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W64-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX10W64-NEXT:    s_waitcnt vmcnt(0)
; GFX10W64-NEXT:    v_readfirstlane_b32 s0, v0
; GFX10W64-NEXT:    v_mov_b32_e32 v0, v3
; GFX10W64-NEXT:    v_mov_b32_e32 v4, 0
; GFX10W64-NEXT:    v_add_nc_u32_e32 v0, s0, v0
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    global_store_dword v4, v0, s[2:3]
; GFX10W64-NEXT:    s_endpgm
;
; GFX10W32-LABEL: add_i32_varying_vdata:
; GFX10W32:       ; %bb.0: ; %entry
; GFX10W32-NEXT:    v_mov_b32_e32 v1, v0
; GFX10W32-NEXT:    s_not_b32 exec_lo, exec_lo
; GFX10W32-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W32-NEXT:    s_not_b32 exec_lo, exec_lo
; GFX10W32-NEXT:    s_or_saveexec_b32 s2, -1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_mov_b32_e32 v2, v1
; GFX10W32-NEXT:    v_permlanex16_b32 v2, v2, -1, -1
; GFX10W32-NEXT:    s_mov_b32 exec_lo, s2
; GFX10W32-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W32-NEXT:    s_or_saveexec_b32 s4, -1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v2, v1 quad_perm:[0,1,2,3] row_mask:0xa bank_mask:0xf
; GFX10W32-NEXT:    v_mov_b32_e32 v3, 0
; GFX10W32-NEXT:    v_readlane_b32 s6, v1, 31
; GFX10W32-NEXT:    v_mov_b32_dpp v3, v1 row_shr:1 row_mask:0xf bank_mask:0xf
; GFX10W32-NEXT:    v_readlane_b32 s5, v1, 15
; GFX10W32-NEXT:    s_mov_b32 exec_lo, s4
; GFX10W32-NEXT:    v_mbcnt_lo_u32_b32 v0, exec_lo, 0
; GFX10W32-NEXT:    s_or_saveexec_b32 s4, -1
; GFX10W32-NEXT:    v_writelane_b32 v3, s5, 16
; GFX10W32-NEXT:    s_mov_b32 exec_lo, s4
; GFX10W32-NEXT:    v_cmp_eq_u32_e32 vcc_lo, 0, v0
; GFX10W32-NEXT:    ; implicit-def: $vgpr0
; GFX10W32-NEXT:    s_and_saveexec_b32 s4, vcc_lo
; GFX10W32-NEXT:    s_cbranch_execz .LBB2_2
; GFX10W32-NEXT:  ; %bb.1:
; GFX10W32-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W32-NEXT:    v_mov_b32_e32 v0, s6
; GFX10W32-NEXT:    s_mov_b32 s5, s6
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    buffer_atomic_add v0, off, s[8:11], 0 glc
; GFX10W32-NEXT:  .LBB2_2:
; GFX10W32-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W32-NEXT:    s_or_b32 exec_lo, exec_lo, s4
; GFX10W32-NEXT:    s_waitcnt vmcnt(0)
; GFX10W32-NEXT:    v_readfirstlane_b32 s0, v0
; GFX10W32-NEXT:    v_mov_b32_e32 v0, v3
; GFX10W32-NEXT:    v_mov_b32_e32 v4, 0
; GFX10W32-NEXT:    v_add_nc_u32_e32 v0, s0, v0
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    global_store_dword v4, v0, s[2:3]
; GFX10W32-NEXT:    s_endpgm
entry:
  %lane = call i32 @llvm.amdgcn.workitem.id.x()
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.add(i32 %lane, <4 x i32> %inout, i32 0, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @add_i32_varying_offset(i32 addrspace(1)* %out, <4 x i32> %inout) {
; GFX6-LABEL: add_i32_varying_offset:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0xd
; GFX6-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GFX6-NEXT:    v_mov_b32_e32 v1, 1
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_atomic_add v1, v0, s[4:7], 0 offen glc
; GFX6-NEXT:    s_mov_b32 s3, 0xf000
; GFX6-NEXT:    s_mov_b32 s2, -1
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    buffer_store_dword v1, off, s[0:3], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: add_i32_varying_offset:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x34
; GFX8-NEXT:    v_mov_b32_e32 v2, 1
; GFX8-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    buffer_atomic_add v2, v0, s[4:7], 0 offen glc
; GFX8-NEXT:    v_mov_b32_e32 v0, s0
; GFX8-NEXT:    v_mov_b32_e32 v1, s1
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    flat_store_dword v[0:1], v2
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: add_i32_varying_offset:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x34
; GFX9-NEXT:    v_mov_b32_e32 v1, 1
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    buffer_atomic_add v1, v0, s[4:7], 0 offen glc
; GFX9-NEXT:    v_mov_b32_e32 v0, 0
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: add_i32_varying_offset:
; GFX10:       ; %bb.0: ; %entry
; GFX10-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x34
; GFX10-NEXT:    v_mov_b32_e32 v1, 1
; GFX10-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_add v1, v0, s[4:7], 0 offen glc
; GFX10-NEXT:    v_mov_b32_e32 v0, 0
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX10-NEXT:    s_endpgm
entry:
  %lane = call i32 @llvm.amdgcn.workitem.id.x()
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.add(i32 1, <4 x i32> %inout, i32 %lane, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sub_i32_constant(i32 addrspace(1)* %out, <4 x i32> %inout) {
; GFX6-LABEL: sub_i32_constant:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_mov_b64 s[2:3], exec
; GFX6-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GFX6-NEXT:    v_mbcnt_lo_u32_b32_e64 v0, s2, 0
; GFX6-NEXT:    v_mbcnt_hi_u32_b32_e32 v0, s3, v0
; GFX6-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX6-NEXT:    ; implicit-def: $vgpr1
; GFX6-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX6-NEXT:    s_cbranch_execz .LBB4_2
; GFX6-NEXT:  ; %bb.1:
; GFX6-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GFX6-NEXT:    s_bcnt1_i32_b64 s0, s[2:3]
; GFX6-NEXT:    s_mul_i32 s0, s0, 5
; GFX6-NEXT:    v_mov_b32_e32 v1, s0
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_atomic_sub v1, off, s[8:11], 0 glc
; GFX6-NEXT:  .LBB4_2:
; GFX6-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    v_readfirstlane_b32 s0, v1
; GFX6-NEXT:    v_mul_u32_u24_e32 v0, 5, v0
; GFX6-NEXT:    s_mov_b32 s7, 0xf000
; GFX6-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GFX6-NEXT:    s_mov_b32 s6, -1
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: sub_i32_constant:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX8-NEXT:    s_mov_b64 s[6:7], exec
; GFX8-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX8-NEXT:    v_mbcnt_hi_u32_b32 v0, s7, v0
; GFX8-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX8-NEXT:    ; implicit-def: $vgpr1
; GFX8-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX8-NEXT:    s_cbranch_execz .LBB4_2
; GFX8-NEXT:  ; %bb.1:
; GFX8-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX8-NEXT:    s_bcnt1_i32_b64 s0, s[6:7]
; GFX8-NEXT:    s_mul_i32 s0, s0, 5
; GFX8-NEXT:    v_mov_b32_e32 v1, s0
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    buffer_atomic_sub v1, off, s[8:11], 0 glc
; GFX8-NEXT:  .LBB4_2:
; GFX8-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    v_readfirstlane_b32 s0, v1
; GFX8-NEXT:    v_mul_u32_u24_e32 v0, 5, v0
; GFX8-NEXT:    v_sub_u32_e32 v2, vcc, s0, v0
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    v_mov_b32_e32 v0, s2
; GFX8-NEXT:    v_mov_b32_e32 v1, s3
; GFX8-NEXT:    flat_store_dword v[0:1], v2
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: sub_i32_constant:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX9-NEXT:    s_mov_b64 s[6:7], exec
; GFX9-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX9-NEXT:    v_mbcnt_hi_u32_b32 v0, s7, v0
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX9-NEXT:    ; implicit-def: $vgpr1
; GFX9-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX9-NEXT:    s_cbranch_execz .LBB4_2
; GFX9-NEXT:  ; %bb.1:
; GFX9-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX9-NEXT:    s_bcnt1_i32_b64 s0, s[6:7]
; GFX9-NEXT:    s_mul_i32 s0, s0, 5
; GFX9-NEXT:    v_mov_b32_e32 v1, s0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    buffer_atomic_sub v1, off, s[8:11], 0 glc
; GFX9-NEXT:  .LBB4_2:
; GFX9-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v1
; GFX9-NEXT:    v_mul_u32_u24_e32 v0, 5, v0
; GFX9-NEXT:    v_sub_u32_e32 v0, s0, v0
; GFX9-NEXT:    v_mov_b32_e32 v1, 0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX9-NEXT:    s_endpgm
;
; GFX10W64-LABEL: sub_i32_constant:
; GFX10W64:       ; %bb.0: ; %entry
; GFX10W64-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W64-NEXT:    s_mov_b64 s[6:7], exec
; GFX10W64-NEXT:    ; implicit-def: $vgpr1
; GFX10W64-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX10W64-NEXT:    v_mbcnt_hi_u32_b32 v0, s7, v0
; GFX10W64-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX10W64-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX10W64-NEXT:    s_cbranch_execz .LBB4_2
; GFX10W64-NEXT:  ; %bb.1:
; GFX10W64-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W64-NEXT:    s_bcnt1_i32_b64 s0, s[6:7]
; GFX10W64-NEXT:    s_mul_i32 s0, s0, 5
; GFX10W64-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    buffer_atomic_sub v1, off, s[8:11], 0 glc
; GFX10W64-NEXT:  .LBB4_2:
; GFX10W64-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W64-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX10W64-NEXT:    s_waitcnt vmcnt(0)
; GFX10W64-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W64-NEXT:    v_mul_u32_u24_e32 v0, 5, v0
; GFX10W64-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W64-NEXT:    v_sub_nc_u32_e32 v0, s0, v0
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W64-NEXT:    s_endpgm
;
; GFX10W32-LABEL: sub_i32_constant:
; GFX10W32:       ; %bb.0: ; %entry
; GFX10W32-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W32-NEXT:    s_mov_b32 s5, exec_lo
; GFX10W32-NEXT:    ; implicit-def: $vgpr1
; GFX10W32-NEXT:    v_mbcnt_lo_u32_b32 v0, s5, 0
; GFX10W32-NEXT:    v_cmp_eq_u32_e32 vcc_lo, 0, v0
; GFX10W32-NEXT:    s_and_saveexec_b32 s4, vcc_lo
; GFX10W32-NEXT:    s_cbranch_execz .LBB4_2
; GFX10W32-NEXT:  ; %bb.1:
; GFX10W32-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W32-NEXT:    s_bcnt1_i32_b32 s0, s5
; GFX10W32-NEXT:    s_mul_i32 s0, s0, 5
; GFX10W32-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    buffer_atomic_sub v1, off, s[8:11], 0 glc
; GFX10W32-NEXT:  .LBB4_2:
; GFX10W32-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W32-NEXT:    s_or_b32 exec_lo, exec_lo, s4
; GFX10W32-NEXT:    s_waitcnt vmcnt(0)
; GFX10W32-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W32-NEXT:    v_mul_u32_u24_e32 v0, 5, v0
; GFX10W32-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W32-NEXT:    v_sub_nc_u32_e32 v0, s0, v0
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W32-NEXT:    s_endpgm
entry:
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.sub(i32 5, <4 x i32> %inout, i32 0, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sub_i32_uniform(i32 addrspace(1)* %out, <4 x i32> %inout, i32 %subitive) {
; GFX6-LABEL: sub_i32_uniform:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_mov_b64 s[2:3], exec
; GFX6-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GFX6-NEXT:    s_load_dword s8, s[0:1], 0x11
; GFX6-NEXT:    v_mbcnt_lo_u32_b32_e64 v0, s2, 0
; GFX6-NEXT:    v_mbcnt_hi_u32_b32_e32 v0, s3, v0
; GFX6-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX6-NEXT:    ; implicit-def: $vgpr1
; GFX6-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX6-NEXT:    s_cbranch_execz .LBB5_2
; GFX6-NEXT:  ; %bb.1:
; GFX6-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0xd
; GFX6-NEXT:    s_bcnt1_i32_b64 s0, s[2:3]
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    s_mul_i32 s0, s8, s0
; GFX6-NEXT:    v_mov_b32_e32 v1, s0
; GFX6-NEXT:    buffer_atomic_sub v1, off, s[12:15], 0 glc
; GFX6-NEXT:  .LBB5_2:
; GFX6-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    v_readfirstlane_b32 s0, v1
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    v_mul_lo_u32 v0, s8, v0
; GFX6-NEXT:    s_mov_b32 s7, 0xf000
; GFX6-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GFX6-NEXT:    s_mov_b32 s6, -1
; GFX6-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: sub_i32_uniform:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX8-NEXT:    s_load_dword s8, s[0:1], 0x44
; GFX8-NEXT:    s_mov_b64 s[4:5], exec
; GFX8-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX8-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX8-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX8-NEXT:    ; implicit-def: $vgpr1
; GFX8-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX8-NEXT:    s_cbranch_execz .LBB5_2
; GFX8-NEXT:  ; %bb.1:
; GFX8-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0x34
; GFX8-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    s_mul_i32 s0, s8, s0
; GFX8-NEXT:    v_mov_b32_e32 v1, s0
; GFX8-NEXT:    buffer_atomic_sub v1, off, s[12:15], 0 glc
; GFX8-NEXT:  .LBB5_2:
; GFX8-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    v_mul_lo_u32 v0, s8, v0
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    v_readfirstlane_b32 s0, v1
; GFX8-NEXT:    v_sub_u32_e32 v2, vcc, s0, v0
; GFX8-NEXT:    v_mov_b32_e32 v0, s2
; GFX8-NEXT:    v_mov_b32_e32 v1, s3
; GFX8-NEXT:    flat_store_dword v[0:1], v2
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: sub_i32_uniform:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX9-NEXT:    s_load_dword s8, s[0:1], 0x44
; GFX9-NEXT:    s_mov_b64 s[4:5], exec
; GFX9-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX9-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX9-NEXT:    ; implicit-def: $vgpr1
; GFX9-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX9-NEXT:    s_cbranch_execz .LBB5_2
; GFX9-NEXT:  ; %bb.1:
; GFX9-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0x34
; GFX9-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    s_mul_i32 s0, s8, s0
; GFX9-NEXT:    v_mov_b32_e32 v1, s0
; GFX9-NEXT:    buffer_atomic_sub v1, off, s[12:15], 0 glc
; GFX9-NEXT:  .LBB5_2:
; GFX9-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    v_mul_lo_u32 v0, s8, v0
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v1
; GFX9-NEXT:    v_mov_b32_e32 v1, 0
; GFX9-NEXT:    v_sub_u32_e32 v0, s0, v0
; GFX9-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX9-NEXT:    s_endpgm
;
; GFX10W64-LABEL: sub_i32_uniform:
; GFX10W64:       ; %bb.0: ; %entry
; GFX10W64-NEXT:    s_clause 0x1
; GFX10W64-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W64-NEXT:    s_load_dword s8, s[0:1], 0x44
; GFX10W64-NEXT:    s_mov_b64 s[4:5], exec
; GFX10W64-NEXT:    ; implicit-def: $vgpr1
; GFX10W64-NEXT:    v_mbcnt_lo_u32_b32 v0, s4, 0
; GFX10W64-NEXT:    v_mbcnt_hi_u32_b32 v0, s5, v0
; GFX10W64-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX10W64-NEXT:    s_and_saveexec_b64 s[6:7], vcc
; GFX10W64-NEXT:    s_cbranch_execz .LBB5_2
; GFX10W64-NEXT:  ; %bb.1:
; GFX10W64-NEXT:    s_load_dwordx4 s[12:15], s[0:1], 0x34
; GFX10W64-NEXT:    s_bcnt1_i32_b64 s0, s[4:5]
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    s_mul_i32 s0, s8, s0
; GFX10W64-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W64-NEXT:    buffer_atomic_sub v1, off, s[12:15], 0 glc
; GFX10W64-NEXT:  .LBB5_2:
; GFX10W64-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W64-NEXT:    s_or_b64 exec, exec, s[6:7]
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    v_mul_lo_u32 v0, s8, v0
; GFX10W64-NEXT:    s_waitcnt vmcnt(0)
; GFX10W64-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W64-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W64-NEXT:    v_sub_nc_u32_e32 v0, s0, v0
; GFX10W64-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W64-NEXT:    s_endpgm
;
; GFX10W32-LABEL: sub_i32_uniform:
; GFX10W32:       ; %bb.0: ; %entry
; GFX10W32-NEXT:    s_clause 0x1
; GFX10W32-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W32-NEXT:    s_load_dword s4, s[0:1], 0x44
; GFX10W32-NEXT:    s_mov_b32 s6, exec_lo
; GFX10W32-NEXT:    ; implicit-def: $vgpr1
; GFX10W32-NEXT:    v_mbcnt_lo_u32_b32 v0, s6, 0
; GFX10W32-NEXT:    v_cmp_eq_u32_e32 vcc_lo, 0, v0
; GFX10W32-NEXT:    s_and_saveexec_b32 s5, vcc_lo
; GFX10W32-NEXT:    s_cbranch_execz .LBB5_2
; GFX10W32-NEXT:  ; %bb.1:
; GFX10W32-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W32-NEXT:    s_bcnt1_i32_b32 s0, s6
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    s_mul_i32 s0, s4, s0
; GFX10W32-NEXT:    v_mov_b32_e32 v1, s0
; GFX10W32-NEXT:    buffer_atomic_sub v1, off, s[8:11], 0 glc
; GFX10W32-NEXT:  .LBB5_2:
; GFX10W32-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W32-NEXT:    s_or_b32 exec_lo, exec_lo, s5
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    v_mul_lo_u32 v0, s4, v0
; GFX10W32-NEXT:    s_waitcnt vmcnt(0)
; GFX10W32-NEXT:    v_readfirstlane_b32 s0, v1
; GFX10W32-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W32-NEXT:    v_sub_nc_u32_e32 v0, s0, v0
; GFX10W32-NEXT:    global_store_dword v1, v0, s[2:3]
; GFX10W32-NEXT:    s_endpgm
entry:
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.sub(i32 %subitive, <4 x i32> %inout, i32 0, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sub_i32_varying_vdata(i32 addrspace(1)* %out, <4 x i32> %inout) {
; GFX6-LABEL: sub_i32_varying_vdata:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0xd
; GFX6-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_atomic_sub v0, off, s[4:7], 0 glc
; GFX6-NEXT:    s_mov_b32 s3, 0xf000
; GFX6-NEXT:    s_mov_b32 s2, -1
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    buffer_store_dword v0, off, s[0:3], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: sub_i32_varying_vdata:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX8-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX8-NEXT:    v_mov_b32_e32 v1, 0
; GFX8-NEXT:    s_mov_b64 exec, s[4:5]
; GFX8-NEXT:    v_mbcnt_lo_u32_b32 v3, exec_lo, 0
; GFX8-NEXT:    v_mbcnt_hi_u32_b32 v3, exec_hi, v3
; GFX8-NEXT:    v_mov_b32_e32 v2, v0
; GFX8-NEXT:    s_not_b64 exec, exec
; GFX8-NEXT:    v_mov_b32_e32 v2, 0
; GFX8-NEXT:    s_not_b64 exec, exec
; GFX8-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_bcast:15 row_mask:0xa bank_mask:0xf
; GFX8-NEXT:    s_nop 1
; GFX8-NEXT:    v_add_u32_dpp v2, vcc, v2, v2 row_bcast:31 row_mask:0xc bank_mask:0xf
; GFX8-NEXT:    v_readlane_b32 s6, v2, 63
; GFX8-NEXT:    s_nop 0
; GFX8-NEXT:    v_mov_b32_dpp v1, v2 wave_shr:1 row_mask:0xf bank_mask:0xf
; GFX8-NEXT:    s_mov_b64 exec, s[4:5]
; GFX8-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v3
; GFX8-NEXT:    ; implicit-def: $vgpr0
; GFX8-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX8-NEXT:    s_cbranch_execz .LBB6_2
; GFX8-NEXT:  ; %bb.1:
; GFX8-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX8-NEXT:    v_mov_b32_e32 v0, s6
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    buffer_atomic_sub v0, off, s[8:11], 0 glc
; GFX8-NEXT:  .LBB6_2:
; GFX8-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    v_readfirstlane_b32 s0, v0
; GFX8-NEXT:    v_mov_b32_e32 v0, v1
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    v_mov_b32_e32 v4, s3
; GFX8-NEXT:    v_sub_u32_e32 v0, vcc, s0, v0
; GFX8-NEXT:    v_mov_b32_e32 v3, s2
; GFX8-NEXT:    flat_store_dword v[3:4], v0
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: sub_i32_varying_vdata:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX9-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX9-NEXT:    v_mov_b32_e32 v1, 0
; GFX9-NEXT:    s_mov_b64 exec, s[4:5]
; GFX9-NEXT:    v_mbcnt_lo_u32_b32 v3, exec_lo, 0
; GFX9-NEXT:    v_mbcnt_hi_u32_b32 v3, exec_hi, v3
; GFX9-NEXT:    v_mov_b32_e32 v2, v0
; GFX9-NEXT:    s_not_b64 exec, exec
; GFX9-NEXT:    v_mov_b32_e32 v2, 0
; GFX9-NEXT:    s_not_b64 exec, exec
; GFX9-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_bcast:15 row_mask:0xa bank_mask:0xf
; GFX9-NEXT:    s_nop 1
; GFX9-NEXT:    v_add_u32_dpp v2, v2, v2 row_bcast:31 row_mask:0xc bank_mask:0xf
; GFX9-NEXT:    v_readlane_b32 s6, v2, 63
; GFX9-NEXT:    s_nop 0
; GFX9-NEXT:    v_mov_b32_dpp v1, v2 wave_shr:1 row_mask:0xf bank_mask:0xf
; GFX9-NEXT:    s_mov_b64 exec, s[4:5]
; GFX9-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v3
; GFX9-NEXT:    ; implicit-def: $vgpr0
; GFX9-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX9-NEXT:    s_cbranch_execz .LBB6_2
; GFX9-NEXT:  ; %bb.1:
; GFX9-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX9-NEXT:    v_mov_b32_e32 v0, s6
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    buffer_atomic_sub v0, off, s[8:11], 0 glc
; GFX9-NEXT:  .LBB6_2:
; GFX9-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    v_readfirstlane_b32 s0, v0
; GFX9-NEXT:    v_mov_b32_e32 v0, v1
; GFX9-NEXT:    v_sub_u32_e32 v0, s0, v0
; GFX9-NEXT:    v_mov_b32_e32 v3, 0
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    global_store_dword v3, v0, s[2:3]
; GFX9-NEXT:    s_endpgm
;
; GFX10W64-LABEL: sub_i32_varying_vdata:
; GFX10W64:       ; %bb.0: ; %entry
; GFX10W64-NEXT:    v_mov_b32_e32 v1, v0
; GFX10W64-NEXT:    s_not_b64 exec, exec
; GFX10W64-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W64-NEXT:    s_not_b64 exec, exec
; GFX10W64-NEXT:    s_or_saveexec_b64 s[2:3], -1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_mov_b32_e32 v3, 0
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W64-NEXT:    v_mov_b32_e32 v2, v1
; GFX10W64-NEXT:    v_permlanex16_b32 v2, v2, -1, -1
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v2, v1 quad_perm:[0,1,2,3] row_mask:0xa bank_mask:0xf
; GFX10W64-NEXT:    v_readlane_b32 s4, v1, 31
; GFX10W64-NEXT:    v_mov_b32_e32 v2, s4
; GFX10W64-NEXT:    v_add_nc_u32_dpp v1, v2, v1 quad_perm:[0,1,2,3] row_mask:0xc bank_mask:0xf
; GFX10W64-NEXT:    v_readlane_b32 s6, v1, 15
; GFX10W64-NEXT:    v_mov_b32_dpp v3, v1 row_shr:1 row_mask:0xf bank_mask:0xf
; GFX10W64-NEXT:    s_mov_b64 exec, s[2:3]
; GFX10W64-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W64-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX10W64-NEXT:    v_readlane_b32 s7, v1, 31
; GFX10W64-NEXT:    v_writelane_b32 v3, s6, 16
; GFX10W64-NEXT:    s_mov_b64 exec, s[4:5]
; GFX10W64-NEXT:    v_mbcnt_lo_u32_b32 v0, exec_lo, 0
; GFX10W64-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX10W64-NEXT:    v_readlane_b32 s6, v1, 63
; GFX10W64-NEXT:    v_readlane_b32 s8, v1, 47
; GFX10W64-NEXT:    v_writelane_b32 v3, s7, 32
; GFX10W64-NEXT:    s_mov_b64 exec, s[4:5]
; GFX10W64-NEXT:    v_mbcnt_hi_u32_b32 v0, exec_hi, v0
; GFX10W64-NEXT:    s_or_saveexec_b64 s[4:5], -1
; GFX10W64-NEXT:    v_writelane_b32 v3, s8, 48
; GFX10W64-NEXT:    s_mov_b64 exec, s[4:5]
; GFX10W64-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v0
; GFX10W64-NEXT:    ; implicit-def: $vgpr0
; GFX10W64-NEXT:    s_and_saveexec_b64 s[4:5], vcc
; GFX10W64-NEXT:    s_cbranch_execz .LBB6_2
; GFX10W64-NEXT:  ; %bb.1:
; GFX10W64-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W64-NEXT:    v_mov_b32_e32 v0, s6
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    buffer_atomic_sub v0, off, s[8:11], 0 glc
; GFX10W64-NEXT:  .LBB6_2:
; GFX10W64-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W64-NEXT:    s_or_b64 exec, exec, s[4:5]
; GFX10W64-NEXT:    s_waitcnt vmcnt(0)
; GFX10W64-NEXT:    v_readfirstlane_b32 s0, v0
; GFX10W64-NEXT:    v_mov_b32_e32 v0, v3
; GFX10W64-NEXT:    v_mov_b32_e32 v4, 0
; GFX10W64-NEXT:    v_sub_nc_u32_e32 v0, s0, v0
; GFX10W64-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W64-NEXT:    global_store_dword v4, v0, s[2:3]
; GFX10W64-NEXT:    s_endpgm
;
; GFX10W32-LABEL: sub_i32_varying_vdata:
; GFX10W32:       ; %bb.0: ; %entry
; GFX10W32-NEXT:    v_mov_b32_e32 v1, v0
; GFX10W32-NEXT:    s_not_b32 exec_lo, exec_lo
; GFX10W32-NEXT:    v_mov_b32_e32 v1, 0
; GFX10W32-NEXT:    s_not_b32 exec_lo, exec_lo
; GFX10W32-NEXT:    s_or_saveexec_b32 s2, -1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:1 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:2 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:4 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v1, v1 row_shr:8 row_mask:0xf bank_mask:0xf bound_ctrl:1
; GFX10W32-NEXT:    v_mov_b32_e32 v2, v1
; GFX10W32-NEXT:    v_permlanex16_b32 v2, v2, -1, -1
; GFX10W32-NEXT:    s_mov_b32 exec_lo, s2
; GFX10W32-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0x24
; GFX10W32-NEXT:    s_or_saveexec_b32 s4, -1
; GFX10W32-NEXT:    v_add_nc_u32_dpp v1, v2, v1 quad_perm:[0,1,2,3] row_mask:0xa bank_mask:0xf
; GFX10W32-NEXT:    v_mov_b32_e32 v3, 0
; GFX10W32-NEXT:    v_readlane_b32 s6, v1, 31
; GFX10W32-NEXT:    v_mov_b32_dpp v3, v1 row_shr:1 row_mask:0xf bank_mask:0xf
; GFX10W32-NEXT:    v_readlane_b32 s5, v1, 15
; GFX10W32-NEXT:    s_mov_b32 exec_lo, s4
; GFX10W32-NEXT:    v_mbcnt_lo_u32_b32 v0, exec_lo, 0
; GFX10W32-NEXT:    s_or_saveexec_b32 s4, -1
; GFX10W32-NEXT:    v_writelane_b32 v3, s5, 16
; GFX10W32-NEXT:    s_mov_b32 exec_lo, s4
; GFX10W32-NEXT:    v_cmp_eq_u32_e32 vcc_lo, 0, v0
; GFX10W32-NEXT:    ; implicit-def: $vgpr0
; GFX10W32-NEXT:    s_and_saveexec_b32 s4, vcc_lo
; GFX10W32-NEXT:    s_cbranch_execz .LBB6_2
; GFX10W32-NEXT:  ; %bb.1:
; GFX10W32-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x34
; GFX10W32-NEXT:    v_mov_b32_e32 v0, s6
; GFX10W32-NEXT:    s_mov_b32 s5, s6
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    buffer_atomic_sub v0, off, s[8:11], 0 glc
; GFX10W32-NEXT:  .LBB6_2:
; GFX10W32-NEXT:    s_waitcnt_depctr 0xffe3
; GFX10W32-NEXT:    s_or_b32 exec_lo, exec_lo, s4
; GFX10W32-NEXT:    s_waitcnt vmcnt(0)
; GFX10W32-NEXT:    v_readfirstlane_b32 s0, v0
; GFX10W32-NEXT:    v_mov_b32_e32 v0, v3
; GFX10W32-NEXT:    v_mov_b32_e32 v4, 0
; GFX10W32-NEXT:    v_sub_nc_u32_e32 v0, s0, v0
; GFX10W32-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10W32-NEXT:    global_store_dword v4, v0, s[2:3]
; GFX10W32-NEXT:    s_endpgm
entry:
  %lane = call i32 @llvm.amdgcn.workitem.id.x()
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.sub(i32 %lane, <4 x i32> %inout, i32 0, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sub_i32_varying_offset(i32 addrspace(1)* %out, <4 x i32> %inout) {
; GFX6-LABEL: sub_i32_varying_offset:
; GFX6:       ; %bb.0: ; %entry
; GFX6-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0xd
; GFX6-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GFX6-NEXT:    v_mov_b32_e32 v1, 1
; GFX6-NEXT:    s_waitcnt lgkmcnt(0)
; GFX6-NEXT:    buffer_atomic_sub v1, v0, s[4:7], 0 offen glc
; GFX6-NEXT:    s_mov_b32 s3, 0xf000
; GFX6-NEXT:    s_mov_b32 s2, -1
; GFX6-NEXT:    s_waitcnt vmcnt(0)
; GFX6-NEXT:    buffer_store_dword v1, off, s[0:3], 0
; GFX6-NEXT:    s_endpgm
;
; GFX8-LABEL: sub_i32_varying_offset:
; GFX8:       ; %bb.0: ; %entry
; GFX8-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x34
; GFX8-NEXT:    v_mov_b32_e32 v2, 1
; GFX8-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; GFX8-NEXT:    s_waitcnt lgkmcnt(0)
; GFX8-NEXT:    buffer_atomic_sub v2, v0, s[4:7], 0 offen glc
; GFX8-NEXT:    v_mov_b32_e32 v0, s0
; GFX8-NEXT:    v_mov_b32_e32 v1, s1
; GFX8-NEXT:    s_waitcnt vmcnt(0)
; GFX8-NEXT:    flat_store_dword v[0:1], v2
; GFX8-NEXT:    s_endpgm
;
; GFX9-LABEL: sub_i32_varying_offset:
; GFX9:       ; %bb.0: ; %entry
; GFX9-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x34
; GFX9-NEXT:    v_mov_b32_e32 v1, 1
; GFX9-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; GFX9-NEXT:    s_waitcnt lgkmcnt(0)
; GFX9-NEXT:    buffer_atomic_sub v1, v0, s[4:7], 0 offen glc
; GFX9-NEXT:    v_mov_b32_e32 v0, 0
; GFX9-NEXT:    s_waitcnt vmcnt(0)
; GFX9-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX9-NEXT:    s_endpgm
;
; GFX10-LABEL: sub_i32_varying_offset:
; GFX10:       ; %bb.0: ; %entry
; GFX10-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x34
; GFX10-NEXT:    v_mov_b32_e32 v1, 1
; GFX10-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x24
; GFX10-NEXT:    s_waitcnt lgkmcnt(0)
; GFX10-NEXT:    buffer_atomic_sub v1, v0, s[4:7], 0 offen glc
; GFX10-NEXT:    v_mov_b32_e32 v0, 0
; GFX10-NEXT:    s_waitcnt vmcnt(0)
; GFX10-NEXT:    global_store_dword v0, v1, s[0:1]
; GFX10-NEXT:    s_endpgm
entry:
  %lane = call i32 @llvm.amdgcn.workitem.id.x()
  %old = call i32 @llvm.amdgcn.raw.buffer.atomic.sub(i32 1, <4 x i32> %inout, i32 %lane, i32 0, i32 0)
  store i32 %old, i32 addrspace(1)* %out
  ret void
}
