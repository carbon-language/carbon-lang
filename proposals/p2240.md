# Variadics

<!--
Part of the Carbon Language project, under the Apache License v2.0 with LLVM
Exceptions. See /LICENSE for license information.
SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
-->

[Pull request](https://github.com/carbon-language/carbon-lang/pull/2240)

<!-- toc -->

## Table of contents

-   [Abstract](#abstract)
-   [Problem](#problem)
-   [Background](#background)
-   [Proposal](#proposal)
    -   [Examples](#examples)
-   [Details](#details)
    -   [Statically sized arrays](#statically-sized-arrays)
    -   [Syntax and semantics of variadics](#syntax-and-semantics-of-variadics)
    -   [Syntactic semantics](#syntactic-semantics)
    -   [Reified semantics and pack values](#reified-semantics-and-pack-values)
    -   [Pattern semantics](#pattern-semantics)
    -   [Typechecking](#typechecking)
        -   [Pattern matching](#pattern-matching)
            -   [Identifying potential matchings](#identifying-potential-matchings)
            -   [The type-checking algorithm](#the-type-checking-algorithm)
-   [Rationale](#rationale)
-   [Alternatives considered](#alternatives-considered)
    -   [Disallow named packs](#disallow-named-packs)
    -   [Use postfix instead of prefix operators](#use-postfix-instead-of-prefix-operators)

<!-- tocstop -->

## Abstract

FIXME

## Problem

Carbon needs a way to define functions and parameterized types that are
_variadic_, meaning they can take a variable number of arguments.

## Background

C has long supported variadic functions (such as `printf`), but that mechanism
is heavily disfavored in C++ because it isn't type-safe. Instead, C++ provides a
separate feature for defining variadic _templates_, which can be functions,
classes, or even variables. However, variadic templates currently suffer from
several shortcomings. Most notably:

-   They must be templates, which mean they typically must be defined in header
    files, are susceptible to code bloat due to template instantiation, and
    generally carry all the other costs associated with templating.
-   It is inordinately difficult to define a variadic function whose parameters
    have a fixed type, and the signature of such a function does not clearly
    communicate that fixed type to readers.
-   There is no procedural mechanism for iterating through a variadic parameter
    list. Although features like
    [fold expressions](https://en.cppreference.com/w/cpp/language/fold) cover
    some special cases, the only fully general way to express iteration is with
    recursion, which is often awkward, and results in more template
    instantiations.

There are a number of pending C++ standard proposals to address these issues,
and improve variadic templates in other ways, such as
[P1306R1: Expansion Statements](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1306r1.pdf),
[P1858R2: Generalized Pack Declaration and Usage](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2020/p1858r2.html),
and
[P2277R0: Packs Outside of Templates](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2021/p2277r0.html).
P1858R2 has been especially influential for this proposal.

## Proposal

`[T; N]` is the type of a statically-sized array of N objects of type `T`.
`[T;]` is a shorthand for the type of an array of objects of type `T`, whose
size is static but deduced.

`...,`, `...and`, and `...or` are prefix unary expression operators with the
same precedence as the corresponding non-pack operators. `...{` is an opening
delimiter that forms a balanced pair with `}`, and can contain any number of
statements. An AST rooted at any of these operations is called a
_pack expansion_.

A pack expansion must contain one or more _expansion arguments_. The most common
form of expansion argument consists of the `[:]` operator followed by a tuple or
statically sized array, but an identifier expression that names a binding with a
pack type is also an expansion argument.

The value of each expansion argument is a _pack_, which is a sequence of values
much like a tuple. The _arity_ of an expansion argument is a compile-time value
representing the number of elements it evaluates to. All arguments of a given
pack expansion must have the same arity.

A pack expansion whose arguments have arity N is rewritten to N copies of the
pack expansion, where in the Kth copy, each expansion argument evaluates to the
Kth element of the pack. Each copy is followed by a separator, and the entire
sequence is followed by a terminator, as determined by the pack operator:

| Pack operator | Separator | Terminator |
| ------------- | --------- | ---------- |
| `...,`        | `,`       | (none)     |
| `...and`      | `and`     | `true`     |
| `...or`       | `or`      | `false`    |

As a consequence, a `...,` pack expansion can only occur where a tuple literal
element is expected, or directly inside parentheses, and in the latter case, the
parentheses form a tuple, even if the pack argument has only one element.

Pack expansion syntax can also be used in patterns, with semantics chosen to
follow the general principle that pattern matching is the inverse of expression
evaluation.

> **Open question:** how should the pack argument operator be spelled? `[:]` is
> taken from the C++ proposal [P1858R2](http://wg21.link/P1858R2), but there is
> was motivated by a syntactic analogy with array indexing, which doesn't carry
> over to Carbon because it
> [needs to be a prefix operator](#use-postfix-instead-of-prefix-operators).
> `[:]` is also uncomfortably close to the `[T; N]` array type syntax, given
> that they will often be used in close proximity.

### Examples

```carbon
// Computes the sum of its arguments, which are i64s
fn SumInts(..., [:]params: [i64;]) -> i64 {
  var sum: i64 = 0;
  for (var i: i64 in params) {
    sum += i;
  }
  return sum;
}
```

```carbon
// Concatenates its arguments, which are all convertible to String
fn StrCat[T:! [ConvertibleToString;]](..., [:]params: T) -> String {
  var len: i64 = 0;
  ...{ len += ([:]params).Length(); }
  var result: String = "";
  result.Reserve(len);
  ...{ result.Append(([:]params).ToString()); }
  return result;
}
```

```carbon
// Returns the minimum of its arguments, which must all have the same type T.
//
// Note that this implementation is not recursive. We split the parameters into
// first and rest in order to forbid calling `Min` with no arguments.
fn Min[T:! Comparable & Value](first: T, ..., [:]rest: [T;]) -> T {
  var result: T = first;
  for (var x: T in rest) {
    if (x < result) {
      result = x;
    }
  }
  return result;
}
```

```carbon
// Invokes f, with the tuple `args` as its arguments.
fn Apply[T:! [type;], F:! CallableWith(..., [:]T)](f: F, args: (..., [:]T)) -> auto {
  return f(..., [:]args);
}
```

```carbon
fn Zip[ElementTypes:! [type;]]
      (..., vectors: Vector([:]ElementTypes))
      -> Vector((..., [:]ElementTypes)) {
  var iters: auto = (..., vectors.Begin());
  var result: Vector((..., [:]ElementTypes));
  while (...and [:]iters != vectors.End()) {
    result.push_back((..., *[:]iters));
    ...{ ([:]iters)++; }
  }
  return result;
}
```

```carbon
// Toy example of mixing packs and values in a single parameter list.
// Takes an i64, any number of f64s, and then another i64.
fn MiddleVariadic(first: i64, ..., [:]middles: [f64;], last: i64);
```

```carbon
// Toy example of using the result of variadic type deduction.
fn TupleConcat[T1s: [type;], T2s: [type;]](
    t1: (..., [:]T1s), t2: (..., [:]T2s)) -> (..., [:]T1s, ..., [:]T2s) {
  return (..., [:]t1, ..., [:]t2);
}
```

## Details

FIXME consider moving this material to `docs/design`.

### Statically sized arrays

`[T; N]` is the type of a statically-sized array of `N` objects of type `T`, and
`[T;]` is a symbolic type expression (like `auto`) that deduces to the type
`[T; N]` for some `N`. Consequently, for purposes of symbolic evaluation and
typechecking, we will assume that all statically-sized array types have a size,
although that size may be a symbolic value rather than a constant.

An array can be initialized from a tuple, so long as the tuple has the right
number of elements, and all element types are convertible to the array element
type. We do not support deducing the element type of an array, as in
`fn F[T:! type](array: [T;]);`, because there is no way to deduce the type of an
array of size 0, and the variadic use cases we are focusing on do not give the
caller a way to bypass deduction with an explicit cast.

The rest of the design for statically-sized arrays is deferred to a separate
proposal, because it's not relevant to variadics.

### Syntax and semantics of variadics

`...,`, `...and`, and `...or` are prefix unary expression operators with the
same precedence as the corresponding non-pack operators. They are single tokens,
and may not contain internal whitespace. `...{` is an opening delimiter that
forms a balanced pair with `}`, and can contain any number of `;`-delimited
statements. An AST rooted at any of these operations is called a _pack
expansion_.

A pack expansion must contain one or more _expansion arguments_. These are
usually marked by the `[:]` operator, but can also be unmarked usages of names
that have pack types (which will be defined below). The _arity_ of an expansion
argument is a compile-time value representing the number of elements it
evaluates to. Every pack expansion must contain at least one expansion argument,
and all arguments of a given expansion must have the same arity (which we will
also refer to as the arity of the expansion). If any expansion argument is a
pattern, the entire pack expansion is a pattern. In particular, this means that
the expansion arguments of a `...{` expansion must be expressions.

Pack expansions can be nested only if the inner expansion is within one of the
outer expansion's arguments, although we may relax this restriction in the
future.

There are two complementary models for the meaning of pack expansions, the
_syntactic_ model and the _reified_ model. In the syntactic model, we treat a
pack expansion as being rewritten during monomorphization as a series of copies
of the pack expansion, where in each copy, each expansion argument is replaced
with one of its elements. In the reified model, we define the semantics in terms
of _pack values_, which are created by the `[:]` operator and consumed by
`...,`, `...and`, `...or`, and `...{`, and we generalize most non-variadic
operations to apply element-wise to packs.

Both models work well for run-time expression evaluation, and should be
equivalent in that context. The syntactic model provides a unified description
of run-time expression and statement semantics, but is difficult to apply to
symbolic computation, such as type checking and pattern matching. On the other
hand, the reified model works well for symbolic computation and expression
evaluation, but does not naturally extend to statement semantics.

We will rely primarily on the reified model, with two exceptions:

-   We will use the syntactic model to describe the run-time semantics of `...{`
    expansions, because the reified model can't easily describe the semantics of
    statements, and it's difficult to bridge between the two models within a
    single pack expansion.
-   We will sometimes use the syntactic model when describing the run-time
    semantics of expressions, because expressions inside `...{` expansions must
    use that model, and because run-time expressions in other expansions will
    likely be implemented using that model.

Type-checking and pattern-matching will always use the reified model, because
they are inherently symbolic.

### Syntactic semantics

In the syntactic model, the semantics of packs and pack expansions are specified
in terms of a procedure for rewriting an AST rooted at `...{`, `...,`, `...and`,
or `...or` to an equivalent AST that does not. This rewrite takes place at the
same time as monomorphization of generic functions, which means it takes place
after name resolution and typechecking.

A pack expansion with arity N is rewritten to N instances of the expansion,
where in the Kth instance, every expansion argument is replaced by the Kth
element of that argument. The details of the rewrite vary slightly depending on
the root node of the expansion:

-   In a `...{` expansion, each instance uses a `{` in place of the opening
    `...{`.
-   In a `...,`, `...and`, or `...or` expansion, each instance has the expansion
    operator removed, and the instances are joined using the corresponding
    non-expansion operator.

An `...and` expansion with arity 0 is rewritten to `true` and an `...or`
expansion with arity 0 is rewritten to `false` (the identities of the respective
logical operations). A `...,` expansion with arity 0 is rewritten to `,`, and
any `,` immediately before or after the expansion is removed.

### Reified semantics and pack values

Unlike syntactic semantics, the reified semantic model is used at compile time,
when values may be unknown, or contain unknowns. Crucially, that can include
pack arities, so our representation of packs must be able to accommodate that.

A _pack element_ represents a sequence of some definite or indefinite number of
values that all match a single value, which is called the _kernel_. During
symbolic evaluation, the kernel and the arity of the sequence are represented as
[symbolic values](/docs/design/README.md#value-categories-and-value-phases) (or
constants). The symbolic value representing the kernel may use special variables
called _representatives_, which represent the components of the kernel that can
vary across values in the sequence. Consequently, the scope of a representative
is the pack element it appears in, rather than some lexical scope. The arity of
a pack is represented as a sum of positive integer constants and symbolic
variables that are known to be non-negative. At run time, the kernel will a
non-symbolic value, and the arity will always be a constant. As their name
suggests, pack elements cannot occur on their own, but only as an element of an
enclosing pack.

> **TODO:** find a better term than "kernel", if possible.

A _pack_ is a value consisting of a sequence of pack elements. Pack values are
always assumed to be normalized, meaning that every element's arity is either a
symbolic variable name, or a constant 1. This is always possible because a pack
element arity is always a sum of symbolic variables names and positive
constants, so an element that doesn't fit this criterion can be split into a
sequence of elements with the same kernel that do. The _shape_ of a pack is
another pack, which is found by replacing each kernel with `()`. A _pack type_
is the type of a pack, and can be represented as a pack value whose kernels
match types. The type of a pack is found by replacing each of its kernels with
the kernel's type. Thus, the relationship between packs and pack types is much
the same as between tuples and tuple types.

During symbolic evaluation, a tuple value consists of a sequence of pack
elements, just like a pack. In other words, tuple types and pack types have the
same sets of values, and differ only in the operations they support. Name
bindings can have pack types, but only if they are local to a single function.
Note that by construction, bindings with pack types always have an explicit
`[:]` operator in the type expression:

```carbon
fn F(array: [i32;]) {
  // ✅ Allowed: `pack` is local to `F`.
  let (..., pack: [:][i32;]) = (..., [:]array);

  // ❌ Forbidden: `auto` can't deduce a pack type.
  let (..., pack: auto) = (..., [:]array);
}

// ❌ Forbidden: `pack` is not function-local.
let (..., pack: [:][i32;]) = (1, 2, 3);

// ✅ Allowed: `tuple` doesn't have a pack type.
let tuple: (..., [:][i32;]) = (1, 2, 3);
```

Most operations that are defined on scalar values are defined on packs as well,
with the following semantics: all operands that are packs must have the same
shape, and the result of the operation will itself have the same shape as the
operands. The kernels are computed by iterating through the input packs and
applying the non-pack version of the operation: the kernel of the k'th output
element is the result of replacing each input pack with the kernel of its k'th
element, and evaluating the resulting operation using the ordinary non-pack
rules.

If a tuple literal does not contain `...,`, its evaluation follows the rules for
arbitrary operations described earlier. If it does contain `...,`, the result is
a tuple value formed by iterating through the literal elements:

-   If the element is headed by `...,`, we evaluate its operand to produce a
    pack, and append its elements to the result tuple.
-   Otherwise, we evaluate the element expression to produce a value `V`, and
    append a pack element with kernel `V` and arity 1 to the result tuple.

The `[:]` operator transforms a tuple into a pack, or an unknown tuple value
into a pack of unknown values:

-   When the operand is a tuple value, the result is a pack value that's
    identical to the tuple value.
-   When the operand is a symbolic variable whose type is a tuple, the result is
    a pack with the same shape as the tuple. Each kernel is a representative
    whose type is the kernel of the corresponding element of the tuple.

For these purposes, an array type `[T; N]` is treated as a tuple type
`(..., [:][T; N])`, so:

-   When the operand is an array type `[T; N]`, the result is a pack consisting
    of a single pack element `..., [:][T; N]`
-   When the operand is a symbolic variable with type `[T; N]`, the result is a
    pack consisting of a single pack element whose kernel is a representative
    whose type is `T`.

An identifier expression that names a variable whose type is a pack type behaves
like a `[:]` expression whose operand is a variable of the corresponding tuple
type. No other leaf AST node can evaluate to a pack value.

A tuple cannot be indexed unless all of its pack elements have arity 1. There is
no syntax for indexing into a pack.

### Pattern semantics

Pack expansions can also appear in patterns. The semantics are chosen to follow
the general principle that pattern matching is the inverse of expression
evaluation, so for example if the pattern `(..., [:]x: String)` matches some
scrutinee value `s`, the expression `(..., [:]x)` should be equal to `s`. These
are run-time semantics, so any pack elements in the scrutinee value have arity
1, and all types are known constants.

There can be no more than one `...,` pattern in a tuple pattern. The N elements
of the pattern before the `...,` expansion are matched with the first N elements
of the scrutinee, and the M elements of the pattern after the `...,` expansion
are matched with the last M elements of the scrutinee. If the scrutinee does not
have at least N + M elements, the pattern does not match. The operand of the
`...,` pattern is matched with the sub-pack consisting of any remaining
scrutinee elements.

If a name binding pattern has a pack type, it is bound to a pack consisting of
the K scrutinee values that it is matched against. Otherwise, if the pattern is
inside a pack expansion, the program is ill-formed, because the name would be
bound multiple times. For example, in `(..., (foo: i32, bar: [:]Ts))`,
`foo: i32` is ill-formed because it would match a value like
`((1, "foo"), (2, "bar"), (3, "baz"))`, and bind the name `foo` to `1`, `2`, and
`3` simultaneously, which is nonsensical.

A _pack argument pattern_ consists of a `[:]` token and a single operand
pattern. The scrutinee must be a pack, and the pack argument pattern matches if
the operand pattern matches a tuple consisting of the elements of the scrutinee
pack.

Other kinds of patterns cannot have a pack type or pack-type operands, and
cannot match a pack scrutinee. Consequently, they are unchanged by this
proposal.

> **Future work:** It is probably possible to define a rule that generalizes
> other kinds of patterns to support variadics. However, we don't yet have
> motivating use cases for that, and it appears that in many if not most cases
> such patterns would be refutable, which substantially limits their usefulness.

### Typechecking

Variadic typechecking for expressions follows the reified model, but applied to
the types of expressions instead of the values of expressions. For example, for
most operations, if any of the operands have a pack type, all pack-type operands
must have the same shape, the type of the whole operation will have the same
shape, and the element types are found by iterating through the input pack types
element-wise, performing ordinary scalar type-checking for the operation.

Typechecking a variadic pattern is much like typechecking a variadic expression:
we proceed bottom-up, generalizing the scalar typechecking rules to apply
element-wise to variadics, and so forth. The most notable difference is that
patterns can contain name bindings, whose types are determined by symbolically
evaluating the type portion of the binding.

Variadic statements always use the syntactic model at run-time, but we cannot
use that model at typechecking time because the rewrites in that model haven't
happened yet. Instead, we generalize the rules for typechecking expressions to
support statements as well, by treating statements as having types, in a
restricted way: the type of a statement is either `()` or a pack where all
kernels are `()`. In other words, statements have types, but they only carry
information about pack shape.

With that in place, we can apply essentially the same rule: if any of the child
AST nodes has a pack type, all child nodes with pack type must have the same
shape. If the parent statement is a `...{}` block, it will have type `()` (and
there must be at least one child with a pack type), and otherwise its type will
be the shape of the pack-type children (or `()` if there are none).

#### Pattern matching

Typechecking for a pattern matching operation proceeds in three phases:

1. The pattern is typechecked, and assigned a type.
2. The scrutinee expression is typechecked, and assigned a type.
3. The scrutinee type is checked against the pattern type.

If the pattern appears in a context that requires it to be irrefutable, such as
the parameter list of a function declaration, phase 3 ensures that the pattern
can match _any_ possible value of the scrutinee expression. Otherwise, it
ensures that the pattern can match _some_ possible value of the scrutinee
expression. For simplicity, this proposal will focus on the rules for the first
case, since it's by far the most important for variadics.

FUTURE WORK: specify rules for refutable matching of variadics, for example to
support C++-style recursive variadics.

Phases 1 and 2 were described earlier, so we only need to describe phase 3. We
will focus on the forms of symbolic type that are introduced or modified in this
proposal: array types, tuple types, and pack types.

An array type pattern `[T; N]` matches an array type scrutinee `[U; M]` if `T`
matches `U` and `N` matches `M`. It can also match a tuple scrutinee type if the
tuple's pack element patterns all match `T`, and the sum of the tuple's pack
element arities matches `N`.

A tuple type pattern matches an array type scrutinee `[T; N]` if it matches the
corresponding tuple type `(..., [:][T; N])`. A tuple type pattern matches a
tuple type scrutinee if the corresponding pack types match.

Pack types only match with other pack types. In particular, `auto` never matches
a pack type, in order to ensure that named packs are always syntactically marked
at the point of declaration. Correctly matching one pack type to another is
difficult, because the packs may not have the same shape. As a consequence, we
don't necessarily know which pattern pack elements each scrutinee pack element
will match with, or the other way around. For example, consider the following
code:

```carbon
fn F(a: i32, ..., [:]b: [i32;], c: i32);

fn G(..., [:]x: [i32;]) {
  F(1, 2, ..., [:]x);
}
```

If `x` is empty, the `2` will match with `c`, and otherwise the `2` will match
with an element of `b`. Similarly, if `x` is not empty, its last element will
match `c`, and the remaining elements (if any) will match elements of `b`.
However, at type-checking time we don't know the size of `x` yet, so we don't
know which will occur. On the other hand, the `1` will always match `a`.

In general, we want type checking to fail if any possible monomorphization of
the generic code would fail to typecheck. In this case that means we want type
checking to fail if any of the potential argument-parameter mappings could fail
to typecheck after monomorphization. Furthermore, for reasons of readability as
well as efficiency, we want type checking to fail if any two potential mappings
would deduce inconsistent values for any deduced parameter. However, in general
this is intractable, because in the worst case the number of distinct ways to
map symbolic arguments to parameters is ${2n \choose n}$ for n variadic
arguments, which is only a factor of $\sqrt{n}$ away from exponential.

Introducing type deduction further complicates the situation. For example:

```carbon
fn H[Ts:! [type;]](a: i32, ..., [:]b: Ts, c: String) -> (..., [:]Ts);

external impl P as ImplicitAs(i32);
external impl Q as ImplicitAs(String);

fn I(x: [i32;], y: [f32;], z: [String;]) {
  var result: auto = H(..., [:]x, {} as P, ..., [:]y, {} as Q, ..., [:]z);
}
```

Here, the deduced type of `result` can have one of four different forms. The
most general case is
`(..., [:][i32;], P, ..., [:][f32;], Q, ..., [:][String;])`, and the other three
cases are formed by omitting the prefix ending with `P` and/or the suffix
starting with `Q` (corresponding to the cases where `x` and/or `z` are empty).
Extending the type system to support deduction that splits into multiple cases
would add a fearsome amount of complexity to the type system.

##### Identifying potential matchings

Our solution will rely on being able to identify which pattern pack elements can
potentially match which scrutinee pack elements. We can do so as follows:

We will refer to the elements of the pack pattern as "parameters", and the
elements of the scrutinee value as "symbolic arguments". We will use the term
"actual arguments" to refer to the elements of the scrutinee after
monomorphization, so a single symbolic argument may correspond to any number of
actual arguments, including zero (but only if the expression is variadic). We
will refer to arguments as "scalar" if they have arity 1, and "variadic" if they
have indeterminate arity (these are the only possibilities, because packs are
normalized). Similarly, we will refer to the `...,` parameter as "variadic" and
the other parameters as "scalar".

A pack pattern consists of $N$ leading scalar parameters, optionally followed by
a variadic parameter headed by the `...,` operator, and then $M$ trailing scalar
parameters. The scrutinee must have a pack type, and can have any number of
scalar and variadic elements, in any order.

There must be at least $N+M$ scalar symbolic arguments, because otherwise if all
variadic symbolic arguments are empty, there will not be enough actual arguments
to match all the scalar parameters. We will refer to the $N$'th scalar symbolic
argument and the symbolic arguments before it as "leading symbolic arguments".
Similarly, we will refer to the $M$'th-from-last scalar symbolic argument and
the symbolic arguments after it as "trailing symbolic arguments", and any
remaining symbolic arguments as "central symbolic arguments". A "leading actual
argument" is an argument that was produced by rewriting a leading symbolic
argument, and likewise for "central actual argument" and "trailing actual
argument". Note that if there is no variadic parameter, $M$ is 0, and so all
parameters, symbolic arguments, and actual arguments are leading.

By construction, there will always be at least $N$ leading actual arguments,
because there are $N$ scalar leading symbolic arguments. Likewise, there will
always be at least $M$ trailing actual arguments. As a result, a leading
parameter can only match a leading actual argument, and so it can only match a
leading symbolic argument, and likewise for trailing parameters. Consequently, a
leading symbolic argument cannot match a trailing parameter, a trailing symbolic
argument cannot match a leading parameter, and a central symbolic argument can
only match the variadic parameter.

Consider the $i$'th scalar leading symbolic argument $E$. If all the variadic
symbolic arguments before it are empty, $E$ will match the $i$'th leading
parameter, so $E$ cannot match any earlier parameter. If there are any earlier
variadic symbolic arguments, $E$ can be made to match any later leading
parameter or the variadic parameter, by making one of those earlier variadic
arguments large enough, but as observed above, $E$ cannot match a trailing
parameter. If there are no earlier variadic symbolic arguments, $E$ cannot be
made to match any later parameter, so it can only match the i'th leading
parameter.

Next, consider a variadic leading symbolic argument $E$ that comes before the
$i$'th scalar leading symbolic argument, but not before any earlier scalar
symbolic argument. If $E$'s rewritten arity is sufficiently large, and all
earlier variadic symbolic arguments are empty, it will simultaneously match the
$i$'th leading parameter, all leading parameters after it, and the variadic
parameter, but as before, it cannot match a trailing parameter.

The same reasoning can be applied to trailing symbolic arguments, but with
"before" and "after" reversed. And as noted earlier, central symbolic arguments
can only match the variadic parameter. In summary, we can identify the possible
matches for a symbolic argument $E$ as follows:

-   If $E$ is leading, let $i$ be one more than the number of earlier scalar
    symbolic arguments:
    -   If $E$ is scalar, and there are no earlier variadic argument
        expressions, then $E$ can only match the $i$'th leading parameter.
    -   Otherwise, $$ can match the $i$'th leading parameter, any later leading
        parameters, and the variadic parameter.
-   If $E$ is trailing, let $i$ be one more than the number of later scalar
    symbolic arguments:
    -   If $E$ is scalar, and there are no later variadic symbolic arguments,
        then $E$ can only match the i'th trailing parameter from the end.
    -   Otherwise, $E$ can match the $i$'th trailing parameter from the end, any
        earlier trailing parameters, and the variadic parameter.
-   Otherwise, $E$ can only match the variadic parameter.

##### The type-checking algorithm

In order to avoid type deduction that splits into multiple cases, we require
that if the variadic parameter's type involves a deduced value that is used in
more than one place (as `Ts` is in the earlier example of this problem), there
cannot be any leading or trailing variadic symbolic arguments (in the sense
defined in the previous section). This ensures that each symbolic argument can
only match one parameter, and so type deduction deterministically produces a
single result.

> **Open question:** Is that restriction too strict? If so, it may be possible
> to forbid only situations that would actually cause type deduction to split
> into multiple cases. As well as being much less restrictive, that would avoid
> the need to give special treatment to deduced arrays that are used only once.
> It would still disallow cases like the call to `H` above, but that call seems
> unnatural for reasons that seem closely related to the fact that its type
> splits into cases.

To avoid a combinatorial explosion, we will use a much more tractable
conservative approximation of the precise algorithm. We type-check each
parameter as follows:

-   If the parameter is variadic, we check it against the sub-pack consisting of
    all symbolic arguments that it could potentially match. The rule stated
    above ensures that this is safe: the concatenated type can only become
    visible outside this local type-check if all variadic arguments have a known
    arity, in which case that sub-pack is known to be exactly correct.
-   Otherwise:
    -   If there is only one argument it can match, which is also not variadic,
        we type-check the argument against the parameter in the ordinary way.
    -   Otherwise:
        -   If the parameter has a non-deduced type, we check each potential
            argument against that type.
        -   Otherwise, we check that all potential arguments have the same type,
            and then check that type against the parameter.

> **Open question:** When deducing a single type from a sequence of types, can
> and should we relax the requirement that all types in the sequence are the
> same? We can identify the common type of a pair of types using
> `CommonTypeWith`, but it is not clear whether or how we can generalize that to
> a sequence of types, since it might not be associative.

We believe that if the code type checks successfully under this algorithm, any
possible monomorphization can type check using the types deduced here, because
the restrictions imposed here are a superset of the restrictions that any
monomorphization needs to satisfy, and the information available to type
deduction here is a subset of the information that would be available after
monomorphization.

## Rationale

FIXME: How does this proposal effectively advance Carbon's goals? Rather than
re-stating the full motivation, this should connect that motivation back to
Carbon's stated goals and principles. This may evolve during review. Use links
to appropriate sections of [`/docs/project/goals.md`](/docs/project/goals.md),
and/or to documents in [`/docs/project/principles`](/docs/project/principles).
For example:

-   [Community and culture](/docs/project/goals.md#community-and-culture)
-   [Language tools and ecosystem](/docs/project/goals.md#language-tools-and-ecosystem)
-   [Performance-critical software](/docs/project/goals.md#performance-critical-software)
-   [Software and language evolution](/docs/project/goals.md#software-and-language-evolution)
-   [Code that is easy to read, understand, and write](/docs/project/goals.md#code-that-is-easy-to-read-understand-and-write)
-   [Practical safety and testing mechanisms](/docs/project/goals.md#practical-safety-and-testing-mechanisms)
-   [Fast and scalable development](/docs/project/goals.md#fast-and-scalable-development)
-   [Modern OS platforms, hardware architectures, and environments](/docs/project/goals.md#modern-os-platforms-hardware-architectures-and-environments)
-   [Interoperability with and migration from existing C++ code](/docs/project/goals.md#interoperability-with-and-migration-from-existing-c-code)

## Alternatives considered

FIXME: What alternative solutions have you considered?

-   Other array syntaxes (especially `[N; T]`)
-   Not depending on array syntax at all
-   Multiple `...,` patterns in a tuple

### Disallow named packs

This proposal allows user code to declare bindings that have pack types, but
only if they are function-local. That restriction can be loosened somewhat, but
probably not removed altogether. In particular, it seems critical for both
readability and implementability that it is locally syntactically obvious
whether a given name refers to a pack, which rules out things like pack-type
data members.

Even with the existing restrictions, named packs may create readability
problems. Consider this example from earlier:

```carbon
fn Zip[ElementTypes:! [type;]]
      (..., vectors: Vector([:]ElementTypes))
      -> Vector((..., [:]ElementTypes)) {
  var iters: auto = (..., vectors.Begin());
  var result: Vector((..., [:]ElementTypes));
  while (...and [:]iters != vectors.End()) {
    result.push_back((..., *[:]iters));
    ...{ ([:]iters)++; }
  }
  return result;
}
```

It may not be obvious to the reader that the `...and` expression has two
expansion arguments, because only one of them is syntactically marked within the
expression.

One solution to these problems would be to disallow named packs, requiring user
code to convert packs to/from tuples when they need to be given names. For
example, with this approach, the signature of `Zip` would instead have to be:

```carbon
fn Zip[ElementTypes:! [Type;]]
      (..., [:]vectors: (..., Vector([:]ElementTypes)))
      -> Vector((..., [:]ElementTypes))
```

With this signature, `vectors` is bound to a tuple rather than a pack, but in
order to do that we need to create a tuple for it to bind to, which makes the
signature more complex.

This approach would probably make variadic function bodies more readable, at the
cost of making variadic function signatures more complex, both to read and to
write. That seems likely to be a bad tradeoff -- readability of variadic
function signatures seems much more important than readability of variadic
function bodies, because the signatures will be read far more often, and by
programmers who have less familiarity with variadics.

This decision was made in
[leads issue #1162](https://github.com/carbon-language/carbon-lang/issues/1162).

### Use postfix instead of prefix operators

`...` is a postfix operator in C++, and `[:]` is a postfix operator in C++
proposal P1858R2. Furthermore, in both cases postfix position is arguably more
natural: postfix `...` aligns with the natural-language usage of "…", and
postfix `[:]` aligns with C++ and Carbon's subscripting syntax. So it would
probably be less surprising to make their Carbon counterparts postfix as well.
However, this turns out to be an awkward fit for Carbon. Consider this example:

```
fn SumInts(..., [:]params: [i64;]) -> i64
```

If `[:]` and `...,` were suffix operators, this would instead be:

```
fn SumInts(params: [i64;][:] ...,) -> i64
```

But this is ambiguous about whether the `[:]` operator applies to
`params: [i64;]` or just `[i64;]`, so we need to add a set of parentheses:

```
fn SumInts((params: [i64;])[:] ...,) -> i64
```

To state the point more generally: when an expression mixes prefix and suffix
operators, their order is determined by precedence and parentheses, which is
usually less readable than relying on the linear order of operators with the
same fixity. The binding operator `:` is effectively a prefix operator (because
its left-hand side is a single token), so if `[:]` is a suffix operator, code
that mixes the two will be somewhat harder to read. That's a particular problem
because, as our motivating examples illustrate, variadic function signatures
will often have those two operators in close conjunction, and readability is at
a premium in function signatures.

C solved a very similar problem with mixing prefix `*` and postfix `.` by
introducing a separate `->` operator. We could in principle solve this issue the
same way, introducing a separate "variadic binding operator" `$`, such that
`params$ [i64;]` is equivalent to `(params: [i64;])[:]`. However, this would
trade a readability problem for a teachability problem, by introducing more
syntax that programmers need to learn before they can even read variadic
function signatures.
