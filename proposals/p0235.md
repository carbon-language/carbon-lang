# Design guidance for safety checking syntax

<!--
Part of the Carbon Language project, under the Apache License v2.0 with LLVM
Exceptions. See /LICENSE for license information.
SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
-->

[Pull request](https://github.com/carbon-language/carbon-lang/pull/235)

<!-- toc -->

## Table of contents

-   [Problem](#problem)
-   [Background](#background)
    -   [Bounds checking](#bounds-checking)
    -   [Efficient safety for hardened builds](#efficient-safety-for-hardened-builds)
    -   ["assume" proposal for C++](#assume-proposal-for-c)
    -   [Rust safety](#rust-safety)
    -   [Related Carbon safety documentation](#related-carbon-safety-documentation)
    -   [Tentative `$` syntax](#tentative--syntax)
-   [Open question: what high-level approach is desired?](#open-question-what-high-level-approach-is-desired)
    -   [Base example code](#base-example-code)
    -   [Option: Use `@ifdef` to disable safety checks](#option-use-ifdef-to-disable-safety-checks)
    -   [Option: Require relocation of safety checks](#option-require-relocation-of-safety-checks)
        -   [Forwarding state across calls](#forwarding-state-across-calls)
        -   [Developers must write benchmarks](#developers-must-write-benchmarks)
        -   [Does the hardened build mode need to provide a path to peak performance?](#does-the-hardened-build-mode-need-to-provide-a-path-to-peak-performance)
        -   [Trade-offs](#trade-offs)
    -   [Option: Encourage multiple check-aware variants of functions](#option-encourage-multiple-check-aware-variants-of-functions)
        -   [Trade-offs](#trade-offs-1)
    -   [Option: Hybrid solution of `assume` and `checked`](#option-hybrid-solution-of-assume-and-checked)
        -   [Trade-offs](#trade-offs-2)
-   [Open question: Can Carbon have syntax that indicates code _must_ be optimized away?](#open-question-can-carbon-have-syntax-that-indicates-code-_must_-be-optimized-away)

<!-- tocstop -->

## Problem

[Bounds checking](https://en.wikipedia.org/wiki/Bounds_checking) is a common
form of spatial memory safety that we would like to provide in Carbon, in order
to prevent common bugs. We need to choose a syntax for implementing bounds
checking. This could either use existing syntax or a new syntax oriented towards
specialized needs of safety.

In other words:

1. There will be safety checks that, by default, add performance overhead.
2. Some applications may have code where it is _never_ acceptable to have that
   performance overhead, not even in debug or hardened builds.
3. Developers need a way to opt out of the respective safety behaviors.

This question is about what developers should do to opt out of safety behaviors
in, for example, hot-path code.

Given the options and discussion so far, the purpose of this proposal is to get
_guidance_ towards a design path, not to decide details.

## Background

### Bounds checking

Out-Of-Bounds (OOB) is a common programming error affecting application
security. See
[iSecCon-2018-12](https://github.com/google/sanitizers/blob/master/hwaddress-sanitizer/MTE-iSecCon-2018.pdf),
[BlueHat-2019-02](https://github.com/microsoft/MSRC-Security-Research/tree/master/presentations/2019_02_BlueHatIL)
(slide 11), and the
[Project Zero Findings](https://bugs.chromium.org/p/project-zero/issues/list?sort=-id&q=%22use%20after%20free%22&can=1).

The standard solution for out-of-bounds errors is
[bounds checking](https://en.wikipedia.org/wiki/Bounds_checking). Bounds
checking can be broken down into two categories:

-   Index checking, such as checking that an index into a 4-element array is
    between 0 and 3.
-   Range checking, such as checking that a value being assigned to a 16-bit
    integer fits within its capacity.

Note that bounds checks are not always trivial; for example, an
`utf8_print(String: message)` function may want to check that the message
contains only valid UTF-8 characters. This could be considered a range check,
because it's ensuring the contents of the message are within the range of UTF-8
characters.

### Efficient safety for hardened builds

Carbon aims to provide a hardened build with mitigations to prevent all possible
safety violations. This is expected to be a significant performance hit, and
while that may be acceptable for the debug build mode, programs using the
hardened build mode for releases may be more interested in recovering
performance, especially on hot-path code.

When considering syntax for safety, we should do so with the expectation that
developers will be interested in using it to recover performance within hardened
builds, even at greater development cost. As such, it should aim to build
something closer to compile-time provable safety guarantees.

### "assume" proposal for C++

The C++ proposal
"[Contracts have failed to provide a portable “assume”](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1773r0.pdf)"
could be considered to be related to this. Whereas that proposal is focused on
achieving optimizations, similar syntax could also aid in guiding optimizations
for safety checks.

A key nuance of "assume" in the context of safety is that while it may aid
developers in writing code that optimizes, the condition is not checked. As a
result, if used in conjunction with safety, safety should not be expected unless
other features are added.

### Rust safety

Rust safety is not about eliminating all bugs, just sources of undefined
behavior. This includes few specific forms of safety:

-   type-safety,
-   memory-safety (dangling pointer, use-after-free),
-   preventing data races.

There is other behavior that you would certainly want to avoid but is out of
scope for Rust safety, such as
[general race conditions](https://doc.rust-lang.org/nomicon/races.html), integer
overflow, deadlock. The specifics of what bad stuff we are trying to avoid with
a safety system will not be the focus of this document, and we can imagine that
Carbon might have a different list of bad stuff than Rust.

Furthermore, Rust is not aiming to be a completely safe language, where the
compiler ensures safety rules can never be violated. Instead it defines two
"modes": safe and unsafe. In safe mode, the compiler ensures that code is safe
by rejecting it if it doesn't follow certain rules. These rules are generally
sufficient to ensure safety, but not necessary, so you can switch to unsafe mode
to write code outside those rules. This can be for expressivity reasons, like
making a data structure, performance reasons, like avoiding a bounds check, or
to interoperate with code in another language (which the Rust compiler is not
going to validate follows its rules). Unsafe code has extra capabilities but has
to be trusted more since the compiler can't verify it doesn't misbehave. The
intent is that you minimize the amount of untrusted code and then scrutinize it
extra carefully. This safe/unsafe split is also present in other languages such
as C#.

The above is described in great detail in
[The Rustonomicon](https://doc.rust-lang.org/nomicon/), for example
[What Unsafe Can Do](https://doc.rust-lang.org/nomicon/what-unsafe-does.html).
For this document, we are more concerned with what it says about
[How Safe and Unsafe Interact](https://doc.rust-lang.org/nomicon/safe-unsafe-meaning.html):

    The `unsafe` keyword has two uses: to declare the existence of contracts the compiler can't check, and to declare that a programmer has checked that these contracts have been upheld.

Functions, traits, and code blocks may be marked `unsafe` in Rust. Unsafe
functions may only be called inside an unsafe code block. Adding an unsafe code
block makes your code less safe, but marking a function as unsafe should make it
safer, with one caveat. The caveat is that bodies of unsafe functions are
implicitly in an unsafe code block, even when only part of the function needs
it. They also
[extend to the module visibility boundary](https://www.ralfj.de/blog/2016/01/09/the-scope-of-unsafe.html),
which can be a teachability problem. This isn't an inherent part of the model
though.

Unsafe traits may only be implemented inside an `unsafe` code block. (Note: a
trait in Rust is like a protocol in Swift or an interface in Carbon.) A trait
will be marked `unsafe`, though, not because implementations of that trait may
need to access unsafe capabilities, but if it is _unsafe to implement_. Unsafe
code may need a trait not just to do something memory safe, but actually
implement the trait's contract _correctly_ to avoid invoking undefined behavior.
This is part of a general theme that code in an unsafe code block has to be
written very carefully, even when it calls safe code. Otherwise the unsafe code
compromises the safety of the entire system.

An API is _sound_ if all possible uses of it are safe. The goal when writing
code using `unsafe` is to still expose a sound API, but this often requires
careful reasoning. A bit more about soundness in practice in Rust
[here](https://docs.rs/dtolnay/0.0.9/dtolnay/macro._03__soundness_bugs.html).
However note that there are limits to Rust's safety, it does not defend against
actively malicious code. For example, even though `open()` is a safe function,
it won't prevent opening `"/proc/self/mem"` and overwriting the memory of the
process.

More background can be found in this paper:
[Understanding Memory and Thread Safety Practices and Issues in Real-World Rust Programs](https://cseweb.ucsd.edu/~yiying/RustStudy-PLDI20.pdf).

### Related Carbon safety documentation

-   [Carbon: Memory Safety](https://docs.google.com/document/d/1SXC55_hugGkGwmF_rLyPNfTmD9noGWUkooG9jhIfX8Q/edit)
-   [Carbon: Safer Unsafe](https://docs.google.com/document/d/1pvoX0HFkRwvtaRKxAwWrH-z9JWHTb4BciYdlpBNHAlw/edit)
    (integrated into this proposal)

### Tentative `$` syntax

`$` is used here as part of the convention of indicating tentative names. A
decision on a path is not approval of `$` syntax.

## Open question: what high-level approach is desired?

There are several ways that safety could be implemented in Carbon, a couple
which would not require safety-specific features to be added. In order to
establish early consensus among the core team, this proposal revolves around a
single question: what high-level approach is desired?

Some of this extends to a question of what problem we're trying to address; is
the goal of syntax to assist developers who want to _relocate_ safety checks, or
_disable_ safety checks?

This decision has effects on trade-offs between the degree of safety which
continues to be provided and the amount of developer effort to build/maintain
performance-related safety mitigations.

While this will primarily affect developers using the hardened build mode while
optimizing frequently-called functions, it may also affect developers using the
development build mode should they have code which is unexpectedly and severely
impacted by safety checks. For contrast, the performance build mode should
generally not be affected because checks won't be enabled there.

### Base example code

For consideration of this question, it can be helpful to consider code which
would invoke bounds checking in a loop. Conceptually, bounds checks in a loop is
less efficient than demonstrating that bounds will never be violated outside the
loop.

Examples will be based on this code:

```carbon
// Consider `Get` as a Carbon-provided library function.
fn Get(Array: array, Int: index) -> String inline {
  // This is the bounds check of performance interest.
  assert(index >= 0 && index < array.size);
  return array.data[index];
}

// Consider `CustomPrint` as a developer-provided function.
fn CustomPrint(Array: array, Int: index) inline {
  // Note that this operation triggers the above bounds check.
  PrintF("Array[%d]: %s\n", index, array.Get(index));
}

// Consider `CustomPrintAll` as a developer-provided function.
fn CustomPrintRange(Array: array, Int: start, Int: end) {
  for (var Int: i = start; i < end; ++i) {
    CustomPrint(array, i);
  }
}
```

In this example, although a developer may be able to figure out that `start` and
`end` are always between `0` and `array.size`, the optimizer may not. As a
result, the bounds check would still consistently execute. If this becomes a
performance problem, how should the performance problem be fixed?

### Option: Use `@ifdef` to disable safety checks

Developers could be required to use a `@ifdef` metaprogramming syntax. Defines
for `DEBUG_BUILD_MODE`, `PERFORMANCE_BUILD_MODE`, and `HARDENED_BUILD_MODE`
could be provided, and developers could be required to make explicit decisions
about whether code should do checks in particular build modes. This would
require libraries to provide "unchecked" versions of functions to be called from
within an `@ifdef`.

This is offered mainly as a basis for trade-offs of other options. However, some
form of the tools necessary for this approach will likely be present in Carbon
metaprogramming, regardless of whether the option is chosen for safety. This
means the approach could be added as an "escape hatch" for other options,
although that would still require `GetUnchecked` and equivalents to be provided
by Carbon libraries.

For example, a `GetUnchecked` function would be added and called by
`CustomPrint`. `Get` and `CustomPrintRange` would remain unchanged.

```carbon
// The "unchecked" variant of `Get` does no `assert`.
fn GetUnchecked(Array: array, Int: index) -> String inline {
  return array.data[index];
}

// Consider `CustomPrint` as a developer-provided function.
fn CustomPrint(Array: array, Int: index) inline {
  // Note the `@ifdef` only does the bounds check in the debug build mode.
  PrintF("Array[%d]: %s\n", index,
@ifdef DEBUG_BUILD_MODE
        array.Get(index)
@else
        array.GetUnchecked(index)
@endif
        );
}
```

### Option: Require relocation of safety checks

Carbon could require developers to relocate safety checks, and provide a proof
that the safety check has been relocated that can be verified by the compiler or
optimizer.

This can be considered using the
[`assume` syntax](http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1773r0.pdf).
The intent of the `assume` is to make it clearer for the optimizer that the user
is working to prove a later `assert`, which could then be optimized away.

For example:

```carbon
// Consider `CustomPrintAll` as a developer-provided function.
fn CustomPrintRange(Array: array, Int: start, Int: end) {
  assume(start >= 0 && start < array.size);
  assume(end >= 0 && end < array.size);
  for (var Int: i = start; i < end; ++i) {
    CustomPrint(array, i);
  }
}
```

#### Forwarding state across calls

An issue with this approach is how the `assume` is propagated across functions;
in the `CustomPrintRange` example, `CustomPrint` may prevent the `assume` from
being used to optimize away the `assert`s in `Get`. In order to address this,
it's possible that preconditions will need to be _explicitly_ marked in function
signatures, to allow the compiler to forward state.

This may result in an additional `precondition` syntax. This should be expected
to be seen in function signatures that may need to forward `assume` information.
Although this syntax may change based on implementation challenges, it would
need to be something that could easily be handled by the compiler and optimizer.

Extending the example:

```carbon
// Consider `Get` as a Carbon-provided library function.
fn Get(Array: array, Int: index) -> String inline precondition(index >= 0 && index < array.size) {
  // This is the bounds check of performance interest.
  assert(index >= 0 && index < array.size);
  return array.data[index];
}

// Consider `CustomPrint` as a developer-provided function.
fn CustomPrint(Array: array, Int: index) inline precondition(index >= 0 && index < array.size) {
  // Note that this operation triggers the above bounds check.
  PrintF("Array[%d]: %s\n", index, array.Get(index));
}
```

#### Developers must write benchmarks

With `assume` syntax, there is no guarantee that optimizations will occur. A few
issues to consider are:

-   The logic contained in the `assume`, `precondition`, and `assert` will
    likely differ slightly even in normal scenarios. Although optimizers may
    often be able to detect the differences and trigger appropriately, it would
    be difficult for the compiler to decisively determine whether the
    appropriate optimizers will late trigger, which would be necessary to
    produce an error about incorrect `assume` code.

-   Even if the compiler can detect that the `precondition` or `assert` is no
    longer needed, the logic may still need to fire if it cannot be proven to
    have no side-effects. For example, if logic for an `assert` calls a
    non-inline function, that non-inline function would still need to be called
    because it may have side-effects. As a result, even when some optimizations
    successfully trigger, there may still be performance loss from the safety
    check.

-   Optimizations are complex and may not reliably execute when in the presence
    of complex control flows and subtle interactions with other optimizers. Even
    if code is manually validated as successfully optimized once, ongoing
    compiler and optimizer changes may change the result.

When optimizing with `assume`, it will be the responsibility of developers to
write and maintain performance tests for their code.

#### Does the hardened build mode need to provide a path to peak performance?

The [performance goal](../docs/project/goals.md#performance-critical-software)
says that "developers should not need to leave the rules and structure of
Carbon, whether to gain control over performance problems or to gain access to
hardware facilities." Does this apply to the hardened build mode and, if so,
what should be planned if optimizations prove insufficient for addressing
performance problems caused by safety checks?

A couple options are:

-   Define the "hardened" build mode as fundamentally providing safety over
    performance, to the extent that the decisions for safety may force
    developers to stop writing idiomatic code in order to achieve safety. For
    example, instead of being able to use the provided safety-checked array
    type, developers may be required to write their own.

-   Combine the implementation of `assume` with one of the other options in this
    proposal that allow for disabling safety checks. For example, the standard
    array type could provide a `GetUnchecked` method for developers who cannot
    get `assume` to sufficiently optimize away bounds checks.

#### Trade-offs

(versus @ifdef)

Advantages:

-   The safety check still occurs in the hardened build mode. This extends the
    safety, even though additional syntax is necessary to optimize away the
    `assert`.

-   It's clear at the site of the `assume` what logic is occurring, and the
    rationale that developers are using to optimize the related safety check
    away.

-   The syntax has a level of conciseness because the `assume` and
    `precondition` may be ignored by callers.

-   If a function calls multiple functions with different `precondition`s, it
    should be able to compose the multiple `precondition`s into its own
    `precondition` list. Callers which can only prove a single set of
    `precondition`s could receive only the corresponding optimizations, without
    losing the safety of the other call.

Disadvantages:

-   Developers will be expected to rely on performance tests to prove that their
    `assume` is providing the desired optimization.

    -   Maintaining and debugging tests may prove difficult. For example, a 10%
        slowdown may be difficult to differentiate from routine noise in test
        execution. It may also be difficult to identify whether the slowdown is
        from the `assume` or some other segment of code.

    -   Teams interested in performance tests may already have them with C++,
        and these costs would exist there too. However, using them in tandem
        with providing a "hardened" mode while also advertising Carbon as a
        performance-critical language invites more such tests.

-   Optimizations may only occur where developers can provide an equivalent
    proof that is understandable by the compiler. More complex safety checks may
    not be provable or in this manner, or may invoke functions with potential
    side-effects that cannot be optimized.

-   Requires a decision about what to do with reaching peak performance in cases
    where the optimizer cannot remove the `assume`. This may include
    implementing one of the other approaches.

-   Only works with `inline` functions. Optimizations can't remove redundant
    code without `inline`. Thus, although generated code size may be smaller at
    some intermediate states, the output code size should be larger from
    inlining.

### Option: Encourage multiple check-aware variants of functions

The concept of a function having multiple variants could be integrated into
Carbon. That is, rather than requiring developers to write separate `Get` and
`GetUnchecked` functions, syntax could be provided such that multiple signatures
could be generated from a single implementation.

This could be implemented by adding a `checked` keyword to function signatures,
with placement similar to `inline`. The presence of `checked` would indicate
that two function signatures should be generated, one with and one without
safety checks. The logic of safety checks could be wrapped with metaprogramming
scopes `@checked_impl` and `@unchecked_impl` in order to indicate
variant-specific logic.

In order to invoke the appropriate variant of functions, an optional `!<char>`
syntax is proposed as an extension to function names that is optional at call
sites. The value of `<char>` may be one of `u` or `f`; other characters are
invalid as a way of reserving for future use. That is, given a function named
`Get`, it may be invoked as `Get(i)`, `Get!u(i)`, `Get!f(i)`. The syntax used
would decide which variant of the function is called:

-   `Get(i)` invokes the variant of `Get` with safety checks.
-   `Get!u(i)` (`u` for "unchecked") invokes the variant of `Get` with no safety
    checks.
-   `Get!f(i)` (`f` for "forward") invokes the variant of `Get` that matches the
    way the current `checked` function was called, and is only valid within the
    body of a `checked` function.

For example:

```carbon
// Consider `Get` as a Carbon-provided library function.
fn Get(Array: array, Int: index) -> String inline checked {
  // The use of a `@checked_impl` here indicates the contained code should only
  // included in the checked variant.
  @checked_impl {
    assert(index >= 0 && index < array.size);
  }
  return array.data[index];
}

// Consider `CustomPrint` as a developer-provided function.
fn CustomPrint(Array: array, Int: index) inline checked {
  // The use of `!f` invokes `Get` with checking equivalent to how `CustomPrint`
  // is called, allowing callers to decide whether to apply safety checks.
  PrintF!f("Array[%d]: %s\n", index, array.Get(index));
}

// Consider `CustomPrintAll` as a developer-provided function.
fn CustomPrintRange(Array: array, Int: start, Int: end) {
  for (var Int: i = start; i < end; ++i) {
    // The use of `!u` calls the unchecked version of `CustomPrint`, which in
    // turn calls the unchecked version of `Get`.
    CustomPrint!u(array, i);
  }
}
```

#### Trade-offs

(versus @ifdef)

Advantages:

-   Provides a more concise syntax for providing "unchecked" versions of
    functions.

-   The increased ease of maintaining multiple variants of a function

-   It's obvious at the call site when safety is being disabled, and this is
    easy to extend indirectly.

Disadvantages:

-   Similar to the `@ifdef` approach, this primarily supports _disabling_ safety
    checks.

-   The `checked` keyword generates two copies of a function, which may yield
    unexpected code size increases. The maintenance tax of having to manually
    duplicate logic for "unchecked" functions may be a preferred method for
    reducing such code size increases.

-   Whereas `@ifdef` relies on elements of Carbon that are likely to be added
    regardless, `checked` creates new syntax burdens for Carbon.

### Option: Hybrid solution of `assume` and `checked`

If Carbon needs _both_ the ability to support optimizing safety checks without
removing them, _and_ the ability to disable them entirely for performance, then
`assume` and `checked` syntax could be used in tandem. The syntaxes are
essentially complementary, with `checked` existing as an escape hatch where
`assume` is difficult to execute. For example, `Get` may look like:

```carbon
// Consider `Get` as a Carbon-provided library function.
fn Get(Array: array, Int: index) -> String inline checked
    precondition(index >= 0 && index < array.size) {
  // The use of a `@checked_impl` here indicates the contained code should only
  // included in the checked variant.
  @checked_impl {
    assert(index >= 0 && index < array.size);
  }
  return array.data[index];
}
```

#### Trade-offs

Advantages:

-   Versus either of the two options alone, this increases coverage of potential
    use-cases.

Disadvantages:

-   Combining the options yields correspondingly increased language complexity,
    with more syntax to implement.

-   Developers may misunderstand the differences of when to use `assume` and
    when to use `checked` syntax, resulting in unexpected safety or performance
    results.

## Open question: Can Carbon have syntax that indicates code _must_ be optimized away?

From a compiler and optimizer perspective, can Carbon have syntax that indicates
code _must_ be optimized away, and produce a reasonable error if that is not
achieved?

If such is possible, syntax could be added to enforce the idea that a given call
_requires_ optimization. While that may not assist the compiler in making the
optimizations, it would give a failure if optimizations fail to occur. This
could lower the maintenance costs in debugging performance tests, minimally by
ruling out possible sources of regressions.

This could be achieved with the `!<char>` call syntax by adding something like
`!o` to indicate that all `precondition`s listed _must_ be satisfied.
Alternately, there could be syntax for explicitly pairing a given `assume` to
one or more function calls.

Note though, this is not without costs: to the extent that optimizations are not
wholly reliable, this can also create a tooling evolution burden to avoid
breaking explicit optimization requirements. Alternately, the related syntax
could receive an explicit advertisement that it is unstable, and should only
ever be used by teams that are willing to invest into ongoing maintenance.
Breaking changes would still likely be poorly received by developers, even if
they were told to expect it.
