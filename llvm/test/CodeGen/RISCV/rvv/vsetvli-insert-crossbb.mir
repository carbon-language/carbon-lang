# NOTE: Assertions have been autogenerated by utils/update_mir_test_checks.py
# RUN: llc %s -o - -mtriple=riscv64 -mattr=v \
# RUN:     -run-pass=riscv-insert-vsetvli | FileCheck %s

--- |
  ; ModuleID = 'vsetvli-insert.ll'
  source_filename = "vsetvli-insert.ll"
  target datalayout = "e-m:e-p:64:64-i64:64-i128:128-n64-S128"
  target triple = "riscv64"

  define <vscale x 1 x i64> @load_add_or_sub(i8 zeroext %cond, <vscale x 1 x i64>* %0, <vscale x 1 x i64> %1, i64 %2) #0 {
  entry:
    %a = call <vscale x 1 x i64> @llvm.riscv.vle.nxv1i64.i64(<vscale x 1 x i64> undef, <vscale x 1 x i64>* %0, i64 %2)
    %tobool = icmp eq i8 %cond, 0
    br i1 %tobool, label %if.else, label %if.then

  if.then:                                          ; preds = %entry
    %b = call <vscale x 1 x i64> @llvm.riscv.vadd.nxv1i64.nxv1i64.i64(<vscale x 1 x i64> undef, <vscale x 1 x i64> %a, <vscale x 1 x i64> %1, i64 %2)
    br label %if.end

  if.else:                                          ; preds = %entry
    %c = call <vscale x 1 x i64> @llvm.riscv.vsub.nxv1i64.nxv1i64.i64(<vscale x 1 x i64> undef, <vscale x 1 x i64> %a, <vscale x 1 x i64> %1, i64 %2)
    br label %if.end

  if.end:                                           ; preds = %if.else, %if.then
    %d = phi <vscale x 1 x i64> [ %b, %if.then ], [ %c, %if.else ]
    ret <vscale x 1 x i64> %d
  }

  define void @load_zext_or_sext(i8 zeroext %cond, <vscale x 1 x i32>* %0, <vscale x 1 x i64>* %1, i64 %2) #0 {
  entry:
    %a = call <vscale x 1 x i32> @llvm.riscv.vle.nxv1i32.i64(<vscale x 1 x i32> undef, <vscale x 1 x i32>* %0, i64 %2)
    %tobool = icmp eq i8 %cond, 0
    br i1 %tobool, label %if.else, label %if.then

  if.then:                                          ; preds = %entry
    %b = call <vscale x 1 x i64> @llvm.riscv.vzext.nxv1i64.nxv1i32.i64(<vscale x 1 x i64> undef, <vscale x 1 x i32> %a, i64 %2)
    br label %if.end

  if.else:                                          ; preds = %entry
    %c = call <vscale x 1 x i64> @llvm.riscv.vsext.nxv1i64.nxv1i32.i64(<vscale x 1 x i64> undef, <vscale x 1 x i32> %a, i64 %2)
    br label %if.end

  if.end:                                           ; preds = %if.else, %if.then
    %d = phi <vscale x 1 x i64> [ %b, %if.then ], [ %c, %if.else ]
    call void @llvm.riscv.vse.nxv1i64.i64(<vscale x 1 x i64> %d, <vscale x 1 x i64>* %1, i64 %2)
    ret void
  }

  ; Function Attrs: nounwind readnone
  declare i64 @llvm.riscv.vmv.x.s.nxv1i64(<vscale x 1 x i64>) #1

  define i64 @vmv_x_s(i8 zeroext %cond, <vscale x 1 x i64> %0, <vscale x 1 x i64> %1, i64 %2) #0 {
  entry:
    %tobool = icmp eq i8 %cond, 0
    br i1 %tobool, label %if.else, label %if.then

  if.then:                                          ; preds = %entry
    %a = call <vscale x 1 x i64> @llvm.riscv.vadd.nxv1i64.nxv1i64.i64(<vscale x 1 x i64> undef, <vscale x 1 x i64> %0, <vscale x 1 x i64> %1, i64 %2)
    br label %if.end

  if.else:                                          ; preds = %entry
    %b = call <vscale x 1 x i64> @llvm.riscv.vsub.nxv1i64.nxv1i64.i64(<vscale x 1 x i64> undef, <vscale x 1 x i64> %1, <vscale x 1 x i64> %1, i64 %2)
    br label %if.end

  if.end:                                           ; preds = %if.else, %if.then
    %c = phi <vscale x 1 x i64> [ %a, %if.then ], [ %b, %if.else ]
    %d = call i64 @llvm.riscv.vmv.x.s.nxv1i64(<vscale x 1 x i64> %c)
    ret i64 %d
  }

  ; Function Attrs: nounwind
  declare i64 @llvm.riscv.vsetvli.i64(i64, i64 immarg, i64 immarg) #2

  define <vscale x 1 x i64> @vsetvli_add_or_sub(i8 zeroext %cond, <vscale x 1 x i64> %0, <vscale x 1 x i64> %1, i64 %avl) #0 {
  entry:
    %vl = call i64 @llvm.riscv.vsetvli.i64(i64 %avl, i64 3, i64 0)
    %tobool = icmp eq i8 %cond, 0
    br i1 %tobool, label %if.else, label %if.then

  if.then:                                          ; preds = %entry
    %b = call <vscale x 1 x i64> @llvm.riscv.vadd.nxv1i64.nxv1i64.i64(<vscale x 1 x i64> undef, <vscale x 1 x i64> %0, <vscale x 1 x i64> %1, i64 %vl)
    br label %if.end

  if.else:                                          ; preds = %entry
    %c = call <vscale x 1 x i64> @llvm.riscv.vsub.nxv1i64.nxv1i64.i64(<vscale x 1 x i64> undef, <vscale x 1 x i64> %0, <vscale x 1 x i64> %1, i64 %vl)
    br label %if.end

  if.end:                                           ; preds = %if.else, %if.then
    %d = phi <vscale x 1 x i64> [ %b, %if.then ], [ %c, %if.else ]
    ret <vscale x 1 x i64> %d
  }

  define void @vsetvli_vcpop() {
    ret void
  }

  define void @vsetvli_loop_store() {
    ret void
  }

  define void @redusum_loop(i32* nocapture noundef readonly %a, i32 noundef signext %n, i32* nocapture noundef writeonly %res) #0 {
  entry:
    br label %vector.body

  vector.body:                                      ; preds = %vector.body, %entry
    %lsr.iv1 = phi i32* [ %scevgep, %vector.body ], [ %a, %entry ]
    %lsr.iv = phi i64 [ %lsr.iv.next, %vector.body ], [ 2048, %entry ]
    %vec.phi = phi <4 x i32> [ zeroinitializer, %entry ], [ %0, %vector.body ]
    %lsr.iv12 = bitcast i32* %lsr.iv1 to <4 x i32>*
    %wide.load = load <4 x i32>, <4 x i32>* %lsr.iv12, align 4
    %0 = add <4 x i32> %wide.load, %vec.phi
    %lsr.iv.next = add nsw i64 %lsr.iv, -4
    %scevgep = getelementptr i32, i32* %lsr.iv1, i64 4
    %1 = icmp eq i64 %lsr.iv.next, 0
    br i1 %1, label %middle.block, label %vector.body

  middle.block:                                     ; preds = %vector.body
    %2 = call i32 @llvm.vector.reduce.add.v4i32(<4 x i32> %0)
    store i32 %2, i32* %res, align 4
    ret void
  }

  ; Function Attrs: nofree nosync nounwind readnone willreturn
  declare i32 @llvm.vector.reduce.add.v4i32(<4 x i32>)

  ; Function Attrs: nounwind readnone
  declare <vscale x 1 x i64> @llvm.riscv.vadd.nxv1i64.nxv1i64.i64(<vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, i64) #1

  ; Function Attrs: nounwind readnone
  declare <vscale x 1 x i64> @llvm.riscv.vsub.nxv1i64.nxv1i64.i64(<vscale x 1 x i64>, <vscale x 1 x i64>, <vscale x 1 x i64>, i64) #1

  ; Function Attrs: nounwind readonly
  declare <vscale x 1 x i64> @llvm.riscv.vle.nxv1i64.i64(<vscale x 1 x i64>, <vscale x 1 x i64>* nocapture, i64) #3

  ; Function Attrs: nounwind readonly
  declare <vscale x 1 x i32> @llvm.riscv.vle.nxv1i32.i64(<vscale x 1 x i32>, <vscale x 1 x i32>* nocapture, i64) #3

  ; Function Attrs: nounwind writeonly
  declare void @llvm.riscv.vse.nxv1i64.i64(<vscale x 1 x i64>, <vscale x 1 x i64>* nocapture, i64) #4

  ; Function Attrs: nounwind readnone
  declare <vscale x 1 x i64> @llvm.riscv.vzext.nxv1i64.nxv1i32.i64(<vscale x 1 x i64>, <vscale x 1 x i32>, i64) #1

  ; Function Attrs: nounwind readnone
  declare <vscale x 1 x i64> @llvm.riscv.vsext.nxv1i64.nxv1i32.i64(<vscale x 1 x i64>, <vscale x 1 x i32>, i64) #1

  attributes #0 = { "target-features"="+v" }
  attributes #1 = { nounwind readnone }
  attributes #2 = { nounwind }
  attributes #3 = { nounwind readonly }
  attributes #4 = { nounwind writeonly }

...
---
name:            load_add_or_sub
alignment:       4
tracksRegLiveness: true
registers:
  - { id: 0, class: vr }
  - { id: 1, class: vr }
  - { id: 2, class: vr }
  - { id: 3, class: vr }
  - { id: 4, class: gpr }
  - { id: 5, class: gpr }
  - { id: 6, class: vr }
  - { id: 7, class: gprnox0 }
  - { id: 8, class: gpr }
liveins:
  - { reg: '$x10', virtual-reg: '%4' }
  - { reg: '$x11', virtual-reg: '%5' }
  - { reg: '$v8', virtual-reg: '%6' }
  - { reg: '$x12', virtual-reg: '%7' }
frameInfo:
  maxAlignment:    1
machineFunctionInfo: {}
body:             |
  ; CHECK-LABEL: name: load_add_or_sub
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.2(0x30000000), %bb.1(0x50000000)
  ; CHECK-NEXT:   liveins: $x10, $x11, $v8, $x12
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gprnox0 = COPY $x12
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:vr = COPY $v8
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLI [[COPY]], 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVLE64_V_M1_:%[0-9]+]]:vr = PseudoVLE64_V_M1 [[COPY2]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT:   BEQ [[COPY3]], [[COPY4]], %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.if.then:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PseudoVADD_VV_M1_:%[0-9]+]]:vr = PseudoVADD_VV_M1 [[PseudoVLE64_V_M1_]], [[COPY1]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   PseudoBR %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.if.else:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PseudoVSUB_VV_M1_:%[0-9]+]]:vr = PseudoVSUB_VV_M1 [[PseudoVLE64_V_M1_]], [[COPY1]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.if.end:
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:vr = PHI [[PseudoVADD_VV_M1_]], %bb.1, [[PseudoVSUB_VV_M1_]], %bb.2
  ; CHECK-NEXT:   $v8 = COPY [[PHI]]
  ; CHECK-NEXT:   PseudoRET implicit $v8
  bb.0.entry:
    successors: %bb.2(0x30000000), %bb.1(0x50000000)
    liveins: $x10, $x11, $v8, $x12

    %7:gprnox0 = COPY $x12
    %6:vr = COPY $v8
    %5:gpr = COPY $x11
    %4:gpr = COPY $x10
    %0:vr = PseudoVLE64_V_M1 %5, %7, 6
    %8:gpr = COPY $x0
    BEQ %4, %8, %bb.2
    PseudoBR %bb.1

  bb.1.if.then:
    %1:vr = PseudoVADD_VV_M1 %0, %6, %7, 6
    PseudoBR %bb.3

  bb.2.if.else:
    %2:vr = PseudoVSUB_VV_M1 %0, %6, %7, 6

  bb.3.if.end:
    %3:vr = PHI %1, %bb.1, %2, %bb.2
    $v8 = COPY %3
    PseudoRET implicit $v8

...
---
name:            load_zext_or_sext
alignment:       4
tracksRegLiveness: true
registers:
  - { id: 0, class: vr }
  - { id: 1, class: vr }
  - { id: 2, class: vr }
  - { id: 3, class: vr }
  - { id: 4, class: gpr }
  - { id: 5, class: gpr }
  - { id: 6, class: gpr }
  - { id: 7, class: gprnox0 }
  - { id: 8, class: gpr }
liveins:
  - { reg: '$x10', virtual-reg: '%4' }
  - { reg: '$x11', virtual-reg: '%5' }
  - { reg: '$x12', virtual-reg: '%6' }
  - { reg: '$x13', virtual-reg: '%7' }
frameInfo:
  maxAlignment:    1
machineFunctionInfo: {}
body:             |
  ; CHECK-LABEL: name: load_zext_or_sext
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.2(0x30000000), %bb.1(0x50000000)
  ; CHECK-NEXT:   liveins: $x10, $x11, $x12, $x13
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gprnox0 = COPY $x13
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x12
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLI [[COPY]], 87 /* e32, mf2, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVLE32_V_MF2_:%[0-9]+]]:vr = PseudoVLE32_V_MF2 [[COPY2]], $noreg, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT:   BEQ [[COPY3]], [[COPY4]], %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.if.then:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLIX0 killed $x0, 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype, implicit $vl
  ; CHECK-NEXT:   early-clobber %1:vr = PseudoVZEXT_VF2_M1 [[PseudoVLE32_V_MF2_]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   PseudoBR %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.if.else:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLIX0 killed $x0, 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype, implicit $vl
  ; CHECK-NEXT:   early-clobber %2:vr = PseudoVSEXT_VF2_M1 [[PseudoVLE32_V_MF2_]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.if.end:
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:vr = PHI %1, %bb.1, %2, %bb.2
  ; CHECK-NEXT:   PseudoVSE64_V_M1 [[PHI]], [[COPY1]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   PseudoRET
  bb.0.entry:
    successors: %bb.2(0x30000000), %bb.1(0x50000000)
    liveins: $x10, $x11, $x12, $x13

    %7:gprnox0 = COPY $x13
    %6:gpr = COPY $x12
    %5:gpr = COPY $x11
    %4:gpr = COPY $x10
    %0:vr = PseudoVLE32_V_MF2 %5, %7, 5
    %8:gpr = COPY $x0
    BEQ %4, %8, %bb.2
    PseudoBR %bb.1

  bb.1.if.then:
    early-clobber %1:vr = PseudoVZEXT_VF2_M1 %0, %7, 6
    PseudoBR %bb.3

  bb.2.if.else:
    early-clobber %2:vr = PseudoVSEXT_VF2_M1 %0, %7, 6

  bb.3.if.end:
    %3:vr = PHI %1, %bb.1, %2, %bb.2
    PseudoVSE64_V_M1 %3, %6, %7, 6
    PseudoRET

...
---
name:            vmv_x_s
alignment:       4
tracksRegLiveness: true
registers:
  - { id: 0, class: vr }
  - { id: 1, class: vr }
  - { id: 2, class: vr }
  - { id: 3, class: gpr }
  - { id: 4, class: vr }
  - { id: 5, class: vr }
  - { id: 6, class: gprnox0 }
  - { id: 7, class: gpr }
  - { id: 8, class: gpr }
liveins:
  - { reg: '$x10', virtual-reg: '%3' }
  - { reg: '$v8', virtual-reg: '%4' }
  - { reg: '$v9', virtual-reg: '%5' }
  - { reg: '$x11', virtual-reg: '%6' }
frameInfo:
  maxAlignment:    1
machineFunctionInfo: {}
body:             |
  ; CHECK-LABEL: name: vmv_x_s
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.2(0x30000000), %bb.1(0x50000000)
  ; CHECK-NEXT:   liveins: $x10, $v8, $v9, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gprnox0 = COPY $x11
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:vr = COPY $v9
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:vr = COPY $v8
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT:   BEQ [[COPY3]], [[COPY4]], %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.if.then:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLI [[COPY]], 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVADD_VV_M1_:%[0-9]+]]:vr = PseudoVADD_VV_M1 [[COPY2]], [[COPY1]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   PseudoBR %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.if.else:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLI [[COPY]], 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVSUB_VV_M1_:%[0-9]+]]:vr = PseudoVSUB_VV_M1 [[COPY1]], [[COPY1]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.if.end:
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:vr = PHI [[PseudoVADD_VV_M1_]], %bb.1, [[PseudoVSUB_VV_M1_]], %bb.2
  ; CHECK-NEXT:   [[PseudoVMV_X_S_M1_:%[0-9]+]]:gpr = PseudoVMV_X_S_M1 [[PHI]], 6 /* e64 */, implicit $vtype
  ; CHECK-NEXT:   $x10 = COPY [[PseudoVMV_X_S_M1_]]
  ; CHECK-NEXT:   PseudoRET implicit $x10
  bb.0.entry:
    successors: %bb.2(0x30000000), %bb.1(0x50000000)
    liveins: $x10, $v8, $v9, $x11

    %6:gprnox0 = COPY $x11
    %5:vr = COPY $v9
    %4:vr = COPY $v8
    %3:gpr = COPY $x10
    %7:gpr = COPY $x0
    BEQ %3, %7, %bb.2
    PseudoBR %bb.1

  bb.1.if.then:
    %0:vr = PseudoVADD_VV_M1 %4, %5, %6, 6
    PseudoBR %bb.3

  bb.2.if.else:
    %1:vr = PseudoVSUB_VV_M1 %5, %5, %6, 6

  bb.3.if.end:
    %2:vr = PHI %0, %bb.1, %1, %bb.2
    %8:gpr = PseudoVMV_X_S_M1 %2, 6
    $x10 = COPY %8
    PseudoRET implicit $x10

...
---
name:            vsetvli_add_or_sub
alignment:       4
tracksRegLiveness: true
registers:
  - { id: 0, class: gprnox0 }
  - { id: 1, class: vr }
  - { id: 2, class: vr }
  - { id: 3, class: vr }
  - { id: 4, class: gpr }
  - { id: 5, class: vr }
  - { id: 6, class: vr }
  - { id: 7, class: gprnox0 }
  - { id: 8, class: gpr }
liveins:
  - { reg: '$x10', virtual-reg: '%4' }
  - { reg: '$v8', virtual-reg: '%5' }
  - { reg: '$v9', virtual-reg: '%6' }
  - { reg: '$x11', virtual-reg: '%7' }
frameInfo:
  maxAlignment:    1
machineFunctionInfo: {}
body:             |
  ; CHECK-LABEL: name: vsetvli_add_or_sub
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.2(0x30000000), %bb.1(0x50000000)
  ; CHECK-NEXT:   liveins: $x10, $v8, $v9, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gprnox0 = COPY $x11
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:vr = COPY $v9
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:vr = COPY $v8
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   [[PseudoVSETVLI:%[0-9]+]]:gprnox0 = PseudoVSETVLI [[COPY]], 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT:   BEQ [[COPY3]], [[COPY4]], %bb.2
  ; CHECK-NEXT:   PseudoBR %bb.1
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.if.then:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PseudoVADD_VV_M1_:%[0-9]+]]:vr = PseudoVADD_VV_M1 [[COPY2]], [[COPY1]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   PseudoBR %bb.3
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.if.else:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PseudoVSUB_VV_M1_:%[0-9]+]]:vr = PseudoVSUB_VV_M1 [[COPY2]], [[COPY1]], $noreg, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3.if.end:
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:vr = PHI [[PseudoVADD_VV_M1_]], %bb.1, [[PseudoVSUB_VV_M1_]], %bb.2
  ; CHECK-NEXT:   $v8 = COPY [[PHI]]
  ; CHECK-NEXT:   PseudoRET implicit $v8
  bb.0.entry:
    successors: %bb.2(0x30000000), %bb.1(0x50000000)
    liveins: $x10, $v8, $v9, $x11

    %7:gprnox0 = COPY $x11
    %6:vr = COPY $v9
    %5:vr = COPY $v8
    %4:gpr = COPY $x10
    %0:gprnox0 = PseudoVSETVLI %7, 88, implicit-def dead $vl, implicit-def dead $vtype
    %8:gpr = COPY $x0
    BEQ %4, %8, %bb.2
    PseudoBR %bb.1

  bb.1.if.then:
    %1:vr = PseudoVADD_VV_M1 %5, %6, %0, 6
    PseudoBR %bb.3

  bb.2.if.else:
    %2:vr = PseudoVSUB_VV_M1 %5, %6, %0, 6

  bb.3.if.end:
    %3:vr = PHI %1, %bb.1, %2, %bb.2
    $v8 = COPY %3
    PseudoRET implicit $v8

...
---
name:            vsetvli_vcpop
tracksRegLiveness: true
registers:
  - { id: 0, class: gpr, preferred-register: '' }
  - { id: 1, class: gpr, preferred-register: '' }
  - { id: 2, class: gpr, preferred-register: '' }
  - { id: 3, class: vr, preferred-register: '' }
  - { id: 4, class: vrnov0, preferred-register: '' }
  - { id: 5, class: vmv0, preferred-register: '' }
  - { id: 6, class: vrnov0, preferred-register: '' }
  - { id: 7, class: gpr, preferred-register: '' }
  - { id: 8, class: gpr, preferred-register: '' }
  - { id: 9, class: gpr, preferred-register: '' }
  - { id: 10, class: gpr, preferred-register: '' }
  - { id: 11, class: vr, preferred-register: '' }
body:             |
  ; CHECK-LABEL: name: vsetvli_vcpop
  ; CHECK: bb.0:
  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
  ; CHECK-NEXT:   liveins: $x10, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   [[DEF:%[0-9]+]]:gpr = IMPLICIT_DEF
  ; CHECK-NEXT:   dead %12:gpr = PseudoVSETVLIX0 $x0, 95 /* e64, mf2, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVID_V_MF2_:%[0-9]+]]:vr = PseudoVID_V_MF2 -1, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   dead %13:gpr = PseudoVSETVLIX0 $x0, 87 /* e32, mf2, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVMV_V_I_MF2_:%[0-9]+]]:vrnov0 = PseudoVMV_V_I_MF2 0, -1, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1:
  ; CHECK-NEXT:   successors: %bb.2(0x40000000), %bb.3(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PseudoVMSEQ_VI_MF2_:%[0-9]+]]:vmv0 = PseudoVMSEQ_VI_MF2 killed [[PseudoVID_V_MF2_]], 0, -1, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   $v0 = COPY [[PseudoVMSEQ_VI_MF2_]]
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLIX0 killed $x0, 23 /* e32, mf2, tu, mu */, implicit-def $vl, implicit-def $vtype, implicit $vl
  ; CHECK-NEXT:   [[PseudoVLE32_V_MF2_MASK:%[0-9]+]]:vrnov0 = PseudoVLE32_V_MF2_MASK [[PseudoVMV_V_I_MF2_]], killed [[COPY]], $v0, -1, 5 /* e32 */, 0, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLIX0 killed $x0, 69 /* e8, mf8, ta, mu */, implicit-def $vl, implicit-def $vtype, implicit $vl
  ; CHECK-NEXT:   [[PseudoVCPOP_M_B1_:%[0-9]+]]:gpr = PseudoVCPOP_M_B1 [[PseudoVMSEQ_VI_MF2_]], -1, 0 /* e8 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT:   BEQ killed [[PseudoVCPOP_M_B1_]], [[COPY2]], %bb.3
  ; CHECK-NEXT:   PseudoBR %bb.2
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   successors: %bb.3(0x80000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[LWU:%[0-9]+]]:gpr = LWU [[COPY1]], 0
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.3:
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:gpr = PHI [[DEF]], %bb.1, [[LWU]], %bb.2
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLIX0 killed $x0, 87 /* e32, mf2, ta, mu */, implicit-def $vl, implicit-def $vtype, implicit $vl
  ; CHECK-NEXT:   [[PseudoVADD_VX_MF2_:%[0-9]+]]:vr = nsw PseudoVADD_VX_MF2 [[PseudoVLE32_V_MF2_MASK]], [[PHI]], -1, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   $v0 = COPY [[PseudoVADD_VX_MF2_]]
  ; CHECK-NEXT:   PseudoRET implicit $v0
  bb.0:
    successors: %bb.1(0x80000000)
    liveins: $x10, $x11

    %0:gpr = COPY $x11
    %1:gpr = COPY $x10
    %2:gpr = IMPLICIT_DEF
    %3:vr = PseudoVID_V_MF2 -1, 6
    %4:vrnov0 = PseudoVMV_V_I_MF2 0, -1, 5

  bb.1:
    successors: %bb.2(0x40000000), %bb.3(0x40000000)

    %5:vmv0 = PseudoVMSEQ_VI_MF2 killed %3, 0, -1, 5
    $v0 = COPY %5
    %6:vrnov0 = PseudoVLE32_V_MF2_MASK %4, killed %0, $v0, -1, 5, 0
    %7:gpr = PseudoVCPOP_M_B1 %5, -1, 0
    %8:gpr = COPY $x0
    BEQ killed %7, %8, %bb.3
    PseudoBR %bb.2

  bb.2:
    successors: %bb.3(0x80000000)

    %9:gpr = LWU %1, 0

  bb.3:
    %10:gpr = PHI %2, %bb.1, %9, %bb.2
    %11:vr = nsw PseudoVADD_VX_MF2 %6, %10, -1, 5
    $v0 = COPY %11
    PseudoRET implicit $v0
...
---
name:            vsetvli_loop_store
tracksRegLiveness: true
registers:
  - { id: 0, class: gpr, preferred-register: '' }
  - { id: 1, class: gpr, preferred-register: '' }
  - { id: 2, class: gpr, preferred-register: '' }
  - { id: 3, class: gpr, preferred-register: '' }
  - { id: 4, class: vr,  preferred-register: '' }
  - { id: 5, class: gpr, preferred-register: '' }
  - { id: 6, class: gpr, preferred-register: '' }
  - { id: 7, class: vr,  preferred-register: '' }
  - { id: 8, class: gpr, preferred-register: '' }
  - { id: 9, class: gpr, preferred-register: '' }
  - { id: 10, class: gpr, preferred-register: '' }
body:             |
  ; CHECK-LABEL: name: vsetvli_loop_store
  ; CHECK: bb.0:
  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
  ; CHECK-NEXT:   liveins: $x10, $x11
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   [[PseudoReadVLENB:%[0-9]+]]:gpr = PseudoReadVLENB
  ; CHECK-NEXT:   [[SRLI:%[0-9]+]]:gpr = SRLI [[PseudoReadVLENB]], 3
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x11
  ; CHECK-NEXT:   dead %11:gpr = PseudoVSETVLIX0 $x0, 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVID_V_M1_:%[0-9]+]]:vr = PseudoVID_V_M1 -1, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1:
  ; CHECK-NEXT:   successors: %bb.1(0x40000000), %bb.2(0x40000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:gpr = PHI [[COPY2]], %bb.0, %10, %bb.1
  ; CHECK-NEXT:   [[PseudoVADD_VX_M1_:%[0-9]+]]:vr = PseudoVADD_VX_M1 [[PseudoVID_V_M1_]], [[PHI]], -1, 6 /* e64 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[MUL:%[0-9]+]]:gpr = MUL [[PHI]], [[SRLI]]
  ; CHECK-NEXT:   [[ADD:%[0-9]+]]:gpr = ADD [[COPY]], [[MUL]]
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLIX0 killed $x0, 87 /* e32, mf2, ta, mu */, implicit-def $vl, implicit-def $vtype, implicit $vl
  ; CHECK-NEXT:   PseudoVSE32_V_MF2 killed [[PseudoVADD_VX_M1_]], killed [[ADD]], -1, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[ADDI:%[0-9]+]]:gpr = ADDI [[PHI]], 1
  ; CHECK-NEXT:   dead $x0 = PseudoVSETVLIX0 killed $x0, 88 /* e64, m1, ta, mu */, implicit-def $vl, implicit-def $vtype, implicit $vl
  ; CHECK-NEXT:   BLTU [[ADDI]], [[COPY1]], %bb.1
  ; CHECK-NEXT:   PseudoBR %bb.2
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2:
  ; CHECK-NEXT:   PseudoRET
  bb.0:
    liveins: $x10, $x11
    %0:gpr = COPY $x10
    %1:gpr = PseudoReadVLENB
    %2:gpr = SRLI %1:gpr, 3
    %3:gpr = COPY $x11
    %4:vr = PseudoVID_V_M1 -1, 6
    %5:gpr = COPY $x0

  bb.1:
    successors: %bb.1, %bb.2

    %6:gpr = PHI %5:gpr, %bb.0, %10:gpr, %bb.1
    %7:vr = PseudoVADD_VX_M1 %4:vr, %6:gpr, -1, 6
    %8:gpr = MUL %6:gpr, %2:gpr
    %9:gpr = ADD %0:gpr, %8:gpr
    PseudoVSE32_V_MF2 killed %7:vr, killed %9:gpr, -1, 5
    %10:gpr = ADDI %6:gpr, 1
    BLTU %10:gpr, %3:gpr, %bb.1
    PseudoBR %bb.2

  bb.2:

    PseudoRET
...
---
name:            redusum_loop
alignment:       4
tracksRegLiveness: true
registers:
  - { id: 0, class: gpr }
  - { id: 1, class: gpr }
  - { id: 2, class: vr }
  - { id: 3, class: vr }
  - { id: 4, class: gpr }
  - { id: 5, class: gpr }
  - { id: 6, class: gpr }
  - { id: 7, class: gpr }
  - { id: 8, class: gpr }
  - { id: 9, class: gpr }
  - { id: 10, class: vr }
  - { id: 11, class: vr }
  - { id: 12, class: vr }
  - { id: 13, class: gpr }
  - { id: 14, class: vr }
  - { id: 15, class: vr }
  - { id: 16, class: vr }
  - { id: 17, class: vr }
  - { id: 18, class: gpr }
  - { id: 19, class: gpr }
  - { id: 20, class: vr }
  - { id: 21, class: vr }
  - { id: 22, class: vr }
  - { id: 23, class: vr }
  - { id: 24, class: vr }
liveins:
  - { reg: '$x10', virtual-reg: '%6' }
  - { reg: '$x12', virtual-reg: '%8' }
frameInfo:
  maxAlignment:    1
machineFunctionInfo: {}
body:             |
  ; CHECK-LABEL: name: redusum_loop
  ; CHECK: bb.0.entry:
  ; CHECK-NEXT:   successors: %bb.1(0x80000000)
  ; CHECK-NEXT:   liveins: $x10, $x12
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[COPY:%[0-9]+]]:gpr = COPY $x12
  ; CHECK-NEXT:   [[COPY1:%[0-9]+]]:gpr = COPY $x10
  ; CHECK-NEXT:   dead $x0 = PseudoVSETIVLI 4, 80 /* e32, m1, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   [[PseudoVMV_V_I_M1_:%[0-9]+]]:vr = PseudoVMV_V_I_M1 0, 4, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[COPY2:%[0-9]+]]:vr = COPY [[PseudoVMV_V_I_M1_]]
  ; CHECK-NEXT:   [[COPY3:%[0-9]+]]:vr = COPY [[COPY2]]
  ; CHECK-NEXT:   [[LUI:%[0-9]+]]:gpr = LUI 1
  ; CHECK-NEXT:   [[ADDIW:%[0-9]+]]:gpr = ADDIW killed [[LUI]], -2048
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.1.vector.body:
  ; CHECK-NEXT:   successors: %bb.2(0x04000000), %bb.1(0x7c000000)
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT:   [[PHI:%[0-9]+]]:gpr = PHI [[COPY1]], %bb.0, %5, %bb.1
  ; CHECK-NEXT:   [[PHI1:%[0-9]+]]:gpr = PHI [[ADDIW]], %bb.0, %4, %bb.1
  ; CHECK-NEXT:   [[PHI2:%[0-9]+]]:vr = PHI [[COPY3]], %bb.0, %16, %bb.1
  ; CHECK-NEXT:   [[PseudoVLE32_V_M1_:%[0-9]+]]:vr = PseudoVLE32_V_M1 [[PHI]], 4, 5 /* e32 */, implicit $vl, implicit $vtype :: (load (s128) from %ir.lsr.iv12, align 4)
  ; CHECK-NEXT:   [[PseudoVADD_VV_M1_:%[0-9]+]]:vr = PseudoVADD_VV_M1 killed [[PseudoVLE32_V_M1_]], [[PHI2]], 4, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[ADDI:%[0-9]+]]:gpr = nsw ADDI [[PHI1]], -4
  ; CHECK-NEXT:   [[ADDI1:%[0-9]+]]:gpr = ADDI [[PHI]], 16
  ; CHECK-NEXT:   [[COPY4:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT:   BNE [[ADDI]], [[COPY4]], %bb.1
  ; CHECK-NEXT:   PseudoBR %bb.2
  ; CHECK-NEXT: {{  $}}
  ; CHECK-NEXT: bb.2.middle.block:
  ; CHECK-NEXT:   [[COPY5:%[0-9]+]]:gpr = COPY $x0
  ; CHECK-NEXT:   [[DEF:%[0-9]+]]:vr = IMPLICIT_DEF
  ; CHECK-NEXT:   [[PseudoVMV_S_X_M1_:%[0-9]+]]:vr = PseudoVMV_S_X_M1 [[DEF]], [[COPY5]], 1, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   [[DEF1:%[0-9]+]]:vr = IMPLICIT_DEF
  ; CHECK-NEXT:   [[PseudoVREDSUM_VS_M1_:%[0-9]+]]:vr = PseudoVREDSUM_VS_M1 [[DEF1]], [[PseudoVADD_VV_M1_]], killed [[PseudoVMV_S_X_M1_]], 4, 5 /* e32 */, implicit $vl, implicit $vtype
  ; CHECK-NEXT:   dead $x0 = PseudoVSETIVLI 1, 80 /* e32, m1, ta, mu */, implicit-def $vl, implicit-def $vtype
  ; CHECK-NEXT:   PseudoVSE32_V_M1 killed [[PseudoVREDSUM_VS_M1_]], [[COPY]], 1, 5 /* e32 */, implicit $vl, implicit $vtype :: (store (s32) into %ir.res)
  ; CHECK-NEXT:   PseudoRET
  bb.0.entry:
    liveins: $x10, $x12

    %8:gpr = COPY $x12
    %6:gpr = COPY $x10
    %11:vr = PseudoVMV_V_I_M1 0, 4, 5
    %12:vr = COPY %11
    %10:vr = COPY %12
    %13:gpr = LUI 1
    %9:gpr = ADDIW killed %13, -2048

  bb.1.vector.body:
    successors: %bb.2(0x04000000), %bb.1(0x7c000000)

    %0:gpr = PHI %6, %bb.0, %5, %bb.1
    %1:gpr = PHI %9, %bb.0, %4, %bb.1
    %2:vr = PHI %10, %bb.0, %16, %bb.1
    %14:vr = PseudoVLE32_V_M1 %0, 4, 5 :: (load (s128) from %ir.lsr.iv12, align 4)
    %16:vr = PseudoVADD_VV_M1 killed %14, %2, 4, 5
    %4:gpr = nsw ADDI %1, -4
    %5:gpr = ADDI %0, 16
    %18:gpr = COPY $x0
    BNE %4, %18, %bb.1
    PseudoBR %bb.2

  bb.2.middle.block:
    %19:gpr = COPY $x0
    %21:vr = IMPLICIT_DEF
    %20:vr = PseudoVMV_S_X_M1 %21, %19, 1, 5
    %24:vr = IMPLICIT_DEF
    %23:vr = PseudoVREDSUM_VS_M1 %24, %16, killed %20, 4, 5
    PseudoVSE32_V_M1 killed %23, %8, 1, 5 :: (store (s32) into %ir.res)
    PseudoRET

...
