; NOTE: Assertions have been autogenerated by utils/update_test_checks.py
; NOTE: Assertions have been autogenerated by utils/update_llc_test_checks.py
; RUN: opt -S -mtriple=amdgcn-- -mcpu=tahiti -amdgpu-codegenprepare -amdgpu-bypass-slow-div=0 %s | FileCheck %s
; RUN: llc -mtriple=amdgcn-- -mcpu=tahiti -amdgpu-bypass-slow-div=0 < %s | FileCheck -check-prefix=GCN %s

define amdgpu_kernel void @udiv_i32(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @udiv_i32(
; CHECK-NEXT:    [[TMP1:%.*]] = uitofp i32 [[Y:%.*]] to float
; CHECK-NEXT:    [[TMP2:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = fmul fast float [[TMP2]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP4:%.*]] = fptoui float [[TMP3]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = zext i32 [[TMP4]] to i64
; CHECK-NEXT:    [[TMP6:%.*]] = zext i32 [[Y]] to i64
; CHECK-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP5]], [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = trunc i64 [[TMP7]] to i32
; CHECK-NEXT:    [[TMP9:%.*]] = lshr i64 [[TMP7]], 32
; CHECK-NEXT:    [[TMP10:%.*]] = trunc i64 [[TMP9]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = sub i32 0, [[TMP8]]
; CHECK-NEXT:    [[TMP12:%.*]] = icmp eq i32 [[TMP10]], 0
; CHECK-NEXT:    [[TMP13:%.*]] = select i1 [[TMP12]], i32 [[TMP11]], i32 [[TMP8]]
; CHECK-NEXT:    [[TMP14:%.*]] = zext i32 [[TMP13]] to i64
; CHECK-NEXT:    [[TMP15:%.*]] = zext i32 [[TMP4]] to i64
; CHECK-NEXT:    [[TMP16:%.*]] = mul i64 [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i64 [[TMP16]] to i32
; CHECK-NEXT:    [[TMP18:%.*]] = lshr i64 [[TMP16]], 32
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP4]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = sub i32 [[TMP4]], [[TMP19]]
; CHECK-NEXT:    [[TMP22:%.*]] = select i1 [[TMP12]], i32 [[TMP20]], i32 [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = zext i32 [[TMP22]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = zext i32 [[X:%.*]] to i64
; CHECK-NEXT:    [[TMP25:%.*]] = mul i64 [[TMP23]], [[TMP24]]
; CHECK-NEXT:    [[TMP26:%.*]] = trunc i64 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = lshr i64 [[TMP25]], 32
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = mul i32 [[TMP28]], [[Y]]
; CHECK-NEXT:    [[TMP30:%.*]] = sub i32 [[X]], [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = icmp uge i32 [[TMP30]], [[Y]]
; CHECK-NEXT:    [[TMP32:%.*]] = icmp uge i32 [[X]], [[TMP29]]
; CHECK-NEXT:    [[TMP33:%.*]] = and i1 [[TMP31]], [[TMP32]]
; CHECK-NEXT:    [[TMP34:%.*]] = add i32 [[TMP28]], 1
; CHECK-NEXT:    [[TMP35:%.*]] = sub i32 [[TMP28]], 1
; CHECK-NEXT:    [[TMP36:%.*]] = select i1 [[TMP33]], i32 [[TMP34]], i32 [[TMP28]]
; CHECK-NEXT:    [[TMP37:%.*]] = select i1 [[TMP32]], i32 [[TMP36]], i32 [[TMP35]]
; CHECK-NEXT:    store i32 [[TMP37]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s9
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    v_mul_f32_e32 v0, 0x4f800000, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s9
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s9
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[2:3], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s8
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s9
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v0
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v0
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s8, v1
; GCN-NEXT:    v_cmp_ge_u32_e32 vcc, s8, v1
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s9, v4
; GCN-NEXT:    s_and_b64 s[0:1], s[0:1], vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v3, v0, vcc
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i32 %x, %y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i32(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @urem_i32(
; CHECK-NEXT:    [[TMP1:%.*]] = uitofp i32 [[Y:%.*]] to float
; CHECK-NEXT:    [[TMP2:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP1]])
; CHECK-NEXT:    [[TMP3:%.*]] = fmul fast float [[TMP2]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP4:%.*]] = fptoui float [[TMP3]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = zext i32 [[TMP4]] to i64
; CHECK-NEXT:    [[TMP6:%.*]] = zext i32 [[Y]] to i64
; CHECK-NEXT:    [[TMP7:%.*]] = mul i64 [[TMP5]], [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = trunc i64 [[TMP7]] to i32
; CHECK-NEXT:    [[TMP9:%.*]] = lshr i64 [[TMP7]], 32
; CHECK-NEXT:    [[TMP10:%.*]] = trunc i64 [[TMP9]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = sub i32 0, [[TMP8]]
; CHECK-NEXT:    [[TMP12:%.*]] = icmp eq i32 [[TMP10]], 0
; CHECK-NEXT:    [[TMP13:%.*]] = select i1 [[TMP12]], i32 [[TMP11]], i32 [[TMP8]]
; CHECK-NEXT:    [[TMP14:%.*]] = zext i32 [[TMP13]] to i64
; CHECK-NEXT:    [[TMP15:%.*]] = zext i32 [[TMP4]] to i64
; CHECK-NEXT:    [[TMP16:%.*]] = mul i64 [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i64 [[TMP16]] to i32
; CHECK-NEXT:    [[TMP18:%.*]] = lshr i64 [[TMP16]], 32
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP4]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = sub i32 [[TMP4]], [[TMP19]]
; CHECK-NEXT:    [[TMP22:%.*]] = select i1 [[TMP12]], i32 [[TMP20]], i32 [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = zext i32 [[TMP22]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = zext i32 [[X:%.*]] to i64
; CHECK-NEXT:    [[TMP25:%.*]] = mul i64 [[TMP23]], [[TMP24]]
; CHECK-NEXT:    [[TMP26:%.*]] = trunc i64 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = lshr i64 [[TMP25]], 32
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = mul i32 [[TMP28]], [[Y]]
; CHECK-NEXT:    [[TMP30:%.*]] = sub i32 [[X]], [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = icmp uge i32 [[TMP30]], [[Y]]
; CHECK-NEXT:    [[TMP32:%.*]] = icmp uge i32 [[X]], [[TMP29]]
; CHECK-NEXT:    [[TMP33:%.*]] = and i1 [[TMP31]], [[TMP32]]
; CHECK-NEXT:    [[TMP34:%.*]] = sub i32 [[TMP30]], [[Y]]
; CHECK-NEXT:    [[TMP35:%.*]] = add i32 [[TMP30]], [[Y]]
; CHECK-NEXT:    [[TMP36:%.*]] = select i1 [[TMP33]], i32 [[TMP34]], i32 [[TMP30]]
; CHECK-NEXT:    [[TMP37:%.*]] = select i1 [[TMP32]], i32 [[TMP36]], i32 [[TMP35]]
; CHECK-NEXT:    store i32 [[TMP37]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s9
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    v_mul_f32_e32 v0, 0x4f800000, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s9
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s9
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[2:3], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s8
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s9
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s8, v0
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s8, v0
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s9, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, s9, v1
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s9, v1
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v2, v0, s[2:3]
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem i32 %x, %y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i32(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @sdiv_i32(
; CHECK-NEXT:    [[TMP1:%.*]] = ashr i32 [[X:%.*]], 31
; CHECK-NEXT:    [[TMP2:%.*]] = ashr i32 [[Y:%.*]], 31
; CHECK-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = add i32 [[X]], [[TMP1]]
; CHECK-NEXT:    [[TMP5:%.*]] = add i32 [[Y]], [[TMP2]]
; CHECK-NEXT:    [[TMP6:%.*]] = xor i32 [[TMP4]], [[TMP1]]
; CHECK-NEXT:    [[TMP7:%.*]] = xor i32 [[TMP5]], [[TMP2]]
; CHECK-NEXT:    [[TMP8:%.*]] = uitofp i32 [[TMP7]] to float
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = fmul fast float [[TMP9]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP11:%.*]] = fptoui float [[TMP10]] to i32
; CHECK-NEXT:    [[TMP12:%.*]] = zext i32 [[TMP11]] to i64
; CHECK-NEXT:    [[TMP13:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[TMP14:%.*]] = mul i64 [[TMP12]], [[TMP13]]
; CHECK-NEXT:    [[TMP15:%.*]] = trunc i64 [[TMP14]] to i32
; CHECK-NEXT:    [[TMP16:%.*]] = lshr i64 [[TMP14]], 32
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i64 [[TMP16]] to i32
; CHECK-NEXT:    [[TMP18:%.*]] = sub i32 0, [[TMP15]]
; CHECK-NEXT:    [[TMP19:%.*]] = icmp eq i32 [[TMP17]], 0
; CHECK-NEXT:    [[TMP20:%.*]] = select i1 [[TMP19]], i32 [[TMP18]], i32 [[TMP15]]
; CHECK-NEXT:    [[TMP21:%.*]] = zext i32 [[TMP20]] to i64
; CHECK-NEXT:    [[TMP22:%.*]] = zext i32 [[TMP11]] to i64
; CHECK-NEXT:    [[TMP23:%.*]] = mul i64 [[TMP21]], [[TMP22]]
; CHECK-NEXT:    [[TMP24:%.*]] = trunc i64 [[TMP23]] to i32
; CHECK-NEXT:    [[TMP25:%.*]] = lshr i64 [[TMP23]], 32
; CHECK-NEXT:    [[TMP26:%.*]] = trunc i64 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = add i32 [[TMP11]], [[TMP26]]
; CHECK-NEXT:    [[TMP28:%.*]] = sub i32 [[TMP11]], [[TMP26]]
; CHECK-NEXT:    [[TMP29:%.*]] = select i1 [[TMP19]], i32 [[TMP27]], i32 [[TMP28]]
; CHECK-NEXT:    [[TMP30:%.*]] = zext i32 [[TMP29]] to i64
; CHECK-NEXT:    [[TMP31:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP32:%.*]] = mul i64 [[TMP30]], [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = trunc i64 [[TMP32]] to i32
; CHECK-NEXT:    [[TMP34:%.*]] = lshr i64 [[TMP32]], 32
; CHECK-NEXT:    [[TMP35:%.*]] = trunc i64 [[TMP34]] to i32
; CHECK-NEXT:    [[TMP36:%.*]] = mul i32 [[TMP35]], [[TMP7]]
; CHECK-NEXT:    [[TMP37:%.*]] = sub i32 [[TMP6]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = icmp uge i32 [[TMP37]], [[TMP7]]
; CHECK-NEXT:    [[TMP39:%.*]] = icmp uge i32 [[TMP6]], [[TMP36]]
; CHECK-NEXT:    [[TMP40:%.*]] = and i1 [[TMP38]], [[TMP39]]
; CHECK-NEXT:    [[TMP41:%.*]] = add i32 [[TMP35]], 1
; CHECK-NEXT:    [[TMP42:%.*]] = sub i32 [[TMP35]], 1
; CHECK-NEXT:    [[TMP43:%.*]] = select i1 [[TMP40]], i32 [[TMP41]], i32 [[TMP35]]
; CHECK-NEXT:    [[TMP44:%.*]] = select i1 [[TMP39]], i32 [[TMP43]], i32 [[TMP42]]
; CHECK-NEXT:    [[TMP45:%.*]] = xor i32 [[TMP44]], [[TMP3]]
; CHECK-NEXT:    [[TMP46:%.*]] = sub i32 [[TMP45]], [[TMP3]]
; CHECK-NEXT:    store i32 [[TMP46]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s8, s3, 31
; GCN-NEXT:    s_add_i32 s3, s3, s8
; GCN-NEXT:    s_xor_b32 s9, s3, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s9
; GCN-NEXT:    s_ashr_i32 s3, s2, 31
; GCN-NEXT:    s_add_i32 s2, s2, s3
; GCN-NEXT:    s_xor_b32 s2, s2, s3
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_xor_b32 s3, s3, s8
; GCN-NEXT:    v_mul_f32_e32 v0, 0x4f800000, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s9
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s9
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s2
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s9
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v0
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v0
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s2, v1
; GCN-NEXT:    v_cmp_ge_u32_e32 vcc, s2, v1
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s9, v4
; GCN-NEXT:    s_and_b64 s[0:1], s[0:1], vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v3, v0, vcc
; GCN-NEXT:    v_xor_b32_e32 v0, s3, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s3, v0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i32 %x, %y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i32(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @srem_i32(
; CHECK-NEXT:    [[TMP1:%.*]] = ashr i32 [[X:%.*]], 31
; CHECK-NEXT:    [[TMP2:%.*]] = ashr i32 [[Y:%.*]], 31
; CHECK-NEXT:    [[TMP3:%.*]] = add i32 [[X]], [[TMP1]]
; CHECK-NEXT:    [[TMP4:%.*]] = add i32 [[Y]], [[TMP2]]
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP1]]
; CHECK-NEXT:    [[TMP6:%.*]] = xor i32 [[TMP4]], [[TMP2]]
; CHECK-NEXT:    [[TMP7:%.*]] = uitofp i32 [[TMP6]] to float
; CHECK-NEXT:    [[TMP8:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = fmul fast float [[TMP8]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP10:%.*]] = fptoui float [[TMP9]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = zext i32 [[TMP10]] to i64
; CHECK-NEXT:    [[TMP12:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP13:%.*]] = mul i64 [[TMP11]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = trunc i64 [[TMP13]] to i32
; CHECK-NEXT:    [[TMP15:%.*]] = lshr i64 [[TMP13]], 32
; CHECK-NEXT:    [[TMP16:%.*]] = trunc i64 [[TMP15]] to i32
; CHECK-NEXT:    [[TMP17:%.*]] = sub i32 0, [[TMP14]]
; CHECK-NEXT:    [[TMP18:%.*]] = icmp eq i32 [[TMP16]], 0
; CHECK-NEXT:    [[TMP19:%.*]] = select i1 [[TMP18]], i32 [[TMP17]], i32 [[TMP14]]
; CHECK-NEXT:    [[TMP20:%.*]] = zext i32 [[TMP19]] to i64
; CHECK-NEXT:    [[TMP21:%.*]] = zext i32 [[TMP10]] to i64
; CHECK-NEXT:    [[TMP22:%.*]] = mul i64 [[TMP20]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = trunc i64 [[TMP22]] to i32
; CHECK-NEXT:    [[TMP24:%.*]] = lshr i64 [[TMP22]], 32
; CHECK-NEXT:    [[TMP25:%.*]] = trunc i64 [[TMP24]] to i32
; CHECK-NEXT:    [[TMP26:%.*]] = add i32 [[TMP10]], [[TMP25]]
; CHECK-NEXT:    [[TMP27:%.*]] = sub i32 [[TMP10]], [[TMP25]]
; CHECK-NEXT:    [[TMP28:%.*]] = select i1 [[TMP18]], i32 [[TMP26]], i32 [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = zext i32 [[TMP28]] to i64
; CHECK-NEXT:    [[TMP30:%.*]] = zext i32 [[TMP5]] to i64
; CHECK-NEXT:    [[TMP31:%.*]] = mul i64 [[TMP29]], [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = trunc i64 [[TMP31]] to i32
; CHECK-NEXT:    [[TMP33:%.*]] = lshr i64 [[TMP31]], 32
; CHECK-NEXT:    [[TMP34:%.*]] = trunc i64 [[TMP33]] to i32
; CHECK-NEXT:    [[TMP35:%.*]] = mul i32 [[TMP34]], [[TMP6]]
; CHECK-NEXT:    [[TMP36:%.*]] = sub i32 [[TMP5]], [[TMP35]]
; CHECK-NEXT:    [[TMP37:%.*]] = icmp uge i32 [[TMP36]], [[TMP6]]
; CHECK-NEXT:    [[TMP38:%.*]] = icmp uge i32 [[TMP5]], [[TMP35]]
; CHECK-NEXT:    [[TMP39:%.*]] = and i1 [[TMP37]], [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = sub i32 [[TMP36]], [[TMP6]]
; CHECK-NEXT:    [[TMP41:%.*]] = add i32 [[TMP36]], [[TMP6]]
; CHECK-NEXT:    [[TMP42:%.*]] = select i1 [[TMP39]], i32 [[TMP40]], i32 [[TMP36]]
; CHECK-NEXT:    [[TMP43:%.*]] = select i1 [[TMP38]], i32 [[TMP42]], i32 [[TMP41]]
; CHECK-NEXT:    [[TMP44:%.*]] = xor i32 [[TMP43]], [[TMP1]]
; CHECK-NEXT:    [[TMP45:%.*]] = sub i32 [[TMP44]], [[TMP1]]
; CHECK-NEXT:    store i32 [[TMP45]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s2, s5, 31
; GCN-NEXT:    s_add_i32 s3, s5, s2
; GCN-NEXT:    s_xor_b32 s10, s3, s2
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s10
; GCN-NEXT:    s_ashr_i32 s8, s4, 31
; GCN-NEXT:    s_add_i32 s4, s4, s8
; GCN-NEXT:    s_xor_b32 s9, s4, s8
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    v_mul_f32_e32 v0, 0x4f800000, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s10
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s10
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[2:3], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s9
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s10
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s9, v0
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s9, v0
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s10, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, s10, v1
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s10, v1
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v2, v0, s[2:3]
; GCN-NEXT:    v_xor_b32_e32 v0, s8, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s8, v0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem i32 %x, %y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i16(i16 addrspace(1)* %out, i16 %x, i16 %y) {
; CHECK-LABEL: @udiv_i16(
; CHECK-NEXT:    [[TMP1:%.*]] = zext i16 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = zext i16 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP5:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP6:%.*]] = fmul fast float [[TMP3]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.trunc.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fneg fast float [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP8]], float [[TMP4]], float [[TMP3]])
; CHECK-NEXT:    [[TMP10:%.*]] = fptoui float [[TMP7]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.fabs.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP13:%.*]] = fcmp fast oge float [[TMP11]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = select i1 [[TMP13]], i32 1, i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = add i32 [[TMP10]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = and i32 [[TMP15]], 65535
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i32 [[TMP16]] to i16
; CHECK-NEXT:    store i16 [[TMP17]], i16 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dword s2, s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshr_b32 s3, s2, 16
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s3
; GCN-NEXT:    s_and_b32 s2, s2, 0xffff
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s2
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v3, vcc
; GCN-NEXT:    buffer_store_short v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i16 %x, %y
  store i16 %r, i16 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i16(i16 addrspace(1)* %out, i16 %x, i16 %y) {
; CHECK-LABEL: @urem_i16(
; CHECK-NEXT:    [[TMP1:%.*]] = zext i16 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = zext i16 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP5:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP6:%.*]] = fmul fast float [[TMP3]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.trunc.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fneg fast float [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP8]], float [[TMP4]], float [[TMP3]])
; CHECK-NEXT:    [[TMP10:%.*]] = fptoui float [[TMP7]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.fabs.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP13:%.*]] = fcmp fast oge float [[TMP11]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = select i1 [[TMP13]], i32 1, i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = add i32 [[TMP10]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = mul i32 [[TMP15]], [[TMP2]]
; CHECK-NEXT:    [[TMP17:%.*]] = sub i32 [[TMP1]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 65535
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i32 [[TMP18]] to i16
; CHECK-NEXT:    store i16 [[TMP19]], i16 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dword s4, s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshr_b32 s2, s4, 16
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s2
; GCN-NEXT:    s_and_b32 s3, s4, 0xffff
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s3
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v3, vcc
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s2
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s4, v0
; GCN-NEXT:    buffer_store_short v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = urem i16 %x, %y
  store i16 %r, i16 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i16(i16 addrspace(1)* %out, i16 %x, i16 %y) {
; CHECK-LABEL: @sdiv_i16(
; CHECK-NEXT:    [[TMP1:%.*]] = sext i16 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = sext i16 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP3]], 30
; CHECK-NEXT:    [[TMP5:%.*]] = or i32 [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = sitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = sitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP8:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = fmul fast float [[TMP6]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.trunc.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fneg fast float [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP11]], float [[TMP7]], float [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = fptosi float [[TMP10]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP12]])
; CHECK-NEXT:    [[TMP15:%.*]] = call fast float @llvm.fabs.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP16:%.*]] = fcmp fast oge float [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], i32 [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP18:%.*]] = add i32 [[TMP13]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = shl i32 [[TMP18]], 16
; CHECK-NEXT:    [[TMP20:%.*]] = ashr i32 [[TMP19]], 16
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i32 [[TMP20]] to i16
; CHECK-NEXT:    store i16 [[TMP21]], i16 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s1, s0, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s1
; GCN-NEXT:    s_sext_i32_i16 s0, s0
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s0
; GCN-NEXT:    s_xor_b32 s0, s0, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s2, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s2, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v2
; GCN-NEXT:    buffer_store_short v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i16 %x, %y
  store i16 %r, i16 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i16(i16 addrspace(1)* %out, i16 %x, i16 %y) {
; CHECK-LABEL: @srem_i16(
; CHECK-NEXT:    [[TMP1:%.*]] = sext i16 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = sext i16 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP3]], 30
; CHECK-NEXT:    [[TMP5:%.*]] = or i32 [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = sitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = sitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP8:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = fmul fast float [[TMP6]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.trunc.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fneg fast float [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP11]], float [[TMP7]], float [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = fptosi float [[TMP10]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP12]])
; CHECK-NEXT:    [[TMP15:%.*]] = call fast float @llvm.fabs.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP16:%.*]] = fcmp fast oge float [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], i32 [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP18:%.*]] = add i32 [[TMP13]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = mul i32 [[TMP18]], [[TMP2]]
; CHECK-NEXT:    [[TMP20:%.*]] = sub i32 [[TMP1]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = shl i32 [[TMP20]], 16
; CHECK-NEXT:    [[TMP22:%.*]] = ashr i32 [[TMP21]], 16
; CHECK-NEXT:    [[TMP23:%.*]] = trunc i32 [[TMP22]] to i16
; CHECK-NEXT:    store i16 [[TMP23]], i16 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dword s4, s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s5, s4, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s5
; GCN-NEXT:    s_sext_i32_i16 s2, s4
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s2
; GCN-NEXT:    s_xor_b32 s2, s2, s5
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s2, s2, 30
; GCN-NEXT:    s_or_b32 s6, s2, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[2:3], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[2:3], 0
; GCN-NEXT:    s_cselect_b32 s2, s6, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s2, v2
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s5
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s4, v0
; GCN-NEXT:    buffer_store_short v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = srem i16 %x, %y
  store i16 %r, i16 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i8(i8 addrspace(1)* %out, i8 %x, i8 %y) {
; CHECK-LABEL: @udiv_i8(
; CHECK-NEXT:    [[TMP1:%.*]] = zext i8 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = zext i8 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP5:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP6:%.*]] = fmul fast float [[TMP3]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.trunc.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fneg fast float [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP8]], float [[TMP4]], float [[TMP3]])
; CHECK-NEXT:    [[TMP10:%.*]] = fptoui float [[TMP7]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.fabs.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP13:%.*]] = fcmp fast oge float [[TMP11]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = select i1 [[TMP13]], i32 1, i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = add i32 [[TMP10]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = and i32 [[TMP15]], 255
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i32 [[TMP16]] to i8
; CHECK-NEXT:    store i8 [[TMP17]], i8 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i8:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cvt_f32_ubyte1_e32 v0, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v0
; GCN-NEXT:    v_cvt_f32_ubyte0_e32 v2, s0
; GCN-NEXT:    v_mul_f32_e32 v1, v2, v1
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v1
; GCN-NEXT:    v_mad_f32 v1, -v1, v0, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v3, vcc
; GCN-NEXT:    buffer_store_byte v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i8 %x, %y
  store i8 %r, i8 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i8(i8 addrspace(1)* %out, i8 %x, i8 %y) {
; CHECK-LABEL: @urem_i8(
; CHECK-NEXT:    [[TMP1:%.*]] = zext i8 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = zext i8 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP5:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP6:%.*]] = fmul fast float [[TMP3]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.trunc.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fneg fast float [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP8]], float [[TMP4]], float [[TMP3]])
; CHECK-NEXT:    [[TMP10:%.*]] = fptoui float [[TMP7]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.fabs.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP13:%.*]] = fcmp fast oge float [[TMP11]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = select i1 [[TMP13]], i32 1, i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = add i32 [[TMP10]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = mul i32 [[TMP15]], [[TMP2]]
; CHECK-NEXT:    [[TMP17:%.*]] = sub i32 [[TMP1]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 255
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i32 [[TMP18]] to i8
; CHECK-NEXT:    store i8 [[TMP19]], i8 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i8:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dword s4, s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cvt_f32_ubyte1_e32 v0, s4
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v0
; GCN-NEXT:    v_cvt_f32_ubyte0_e32 v2, s4
; GCN-NEXT:    s_lshr_b32 s2, s4, 8
; GCN-NEXT:    v_mul_f32_e32 v1, v2, v1
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v1
; GCN-NEXT:    v_mad_f32 v1, -v1, v0, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v3, vcc
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s2
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s4, v0
; GCN-NEXT:    buffer_store_byte v0, off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = urem i8 %x, %y
  store i8 %r, i8 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i8(i8 addrspace(1)* %out, i8 %x, i8 %y) {
; CHECK-LABEL: @sdiv_i8(
; CHECK-NEXT:    [[TMP1:%.*]] = sext i8 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = sext i8 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP3]], 30
; CHECK-NEXT:    [[TMP5:%.*]] = or i32 [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = sitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = sitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP8:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = fmul fast float [[TMP6]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.trunc.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fneg fast float [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP11]], float [[TMP7]], float [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = fptosi float [[TMP10]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP12]])
; CHECK-NEXT:    [[TMP15:%.*]] = call fast float @llvm.fabs.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP16:%.*]] = fcmp fast oge float [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], i32 [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP18:%.*]] = add i32 [[TMP13]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = shl i32 [[TMP18]], 24
; CHECK-NEXT:    [[TMP20:%.*]] = ashr i32 [[TMP19]], 24
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i32 [[TMP20]] to i8
; CHECK-NEXT:    store i8 [[TMP21]], i8 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i8:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_bfe_i32 s1, s0, 0x80008
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s1
; GCN-NEXT:    s_sext_i32_i8 s0, s0
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s0
; GCN-NEXT:    s_xor_b32 s0, s0, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s2, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s2, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v2
; GCN-NEXT:    buffer_store_byte v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i8 %x, %y
  store i8 %r, i8 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i8(i8 addrspace(1)* %out, i8 %x, i8 %y) {
; CHECK-LABEL: @srem_i8(
; CHECK-NEXT:    [[TMP1:%.*]] = sext i8 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = sext i8 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP3]], 30
; CHECK-NEXT:    [[TMP5:%.*]] = or i32 [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = sitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = sitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP8:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = fmul fast float [[TMP6]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.trunc.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fneg fast float [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP11]], float [[TMP7]], float [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = fptosi float [[TMP10]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP12]])
; CHECK-NEXT:    [[TMP15:%.*]] = call fast float @llvm.fabs.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP16:%.*]] = fcmp fast oge float [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], i32 [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP18:%.*]] = add i32 [[TMP13]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = mul i32 [[TMP18]], [[TMP2]]
; CHECK-NEXT:    [[TMP20:%.*]] = sub i32 [[TMP1]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = shl i32 [[TMP20]], 24
; CHECK-NEXT:    [[TMP22:%.*]] = ashr i32 [[TMP21]], 24
; CHECK-NEXT:    [[TMP23:%.*]] = trunc i32 [[TMP22]] to i8
; CHECK-NEXT:    store i8 [[TMP23]], i8 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i8:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s2, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_bfe_i32 s0, s2, 0x80008
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s0
; GCN-NEXT:    s_sext_i32_i8 s1, s2
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s1
; GCN-NEXT:    s_xor_b32 s0, s1, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_lshr_b32 s3, s2, 8
; GCN-NEXT:    s_or_b32 s6, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s6, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v2
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s3
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s2, v0
; GCN-NEXT:    buffer_store_byte v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem i8 %x, %y
  store i8 %r, i8 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v4i32(<4 x i32> addrspace(1)* %out, <4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: @udiv_v4i32(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i32> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP3]])
; CHECK-NEXT:    [[TMP5:%.*]] = fmul fast float [[TMP4]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP6:%.*]] = fptoui float [[TMP5]] to i32
; CHECK-NEXT:    [[TMP7:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP2]] to i64
; CHECK-NEXT:    [[TMP9:%.*]] = mul i64 [[TMP7]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = trunc i64 [[TMP9]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = lshr i64 [[TMP9]], 32
; CHECK-NEXT:    [[TMP12:%.*]] = trunc i64 [[TMP11]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = sub i32 0, [[TMP10]]
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], 0
; CHECK-NEXT:    [[TMP15:%.*]] = select i1 [[TMP14]], i32 [[TMP13]], i32 [[TMP10]]
; CHECK-NEXT:    [[TMP16:%.*]] = zext i32 [[TMP15]] to i64
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP18:%.*]] = mul i64 [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = lshr i64 [[TMP18]], 32
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i64 [[TMP20]] to i32
; CHECK-NEXT:    [[TMP22:%.*]] = add i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = sub i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP24:%.*]] = select i1 [[TMP14]], i32 [[TMP22]], i32 [[TMP23]]
; CHECK-NEXT:    [[TMP25:%.*]] = zext i32 [[TMP24]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    [[TMP27:%.*]] = mul i64 [[TMP25]], [[TMP26]]
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = lshr i64 [[TMP27]], 32
; CHECK-NEXT:    [[TMP30:%.*]] = trunc i64 [[TMP29]] to i32
; CHECK-NEXT:    [[TMP31:%.*]] = mul i32 [[TMP30]], [[TMP2]]
; CHECK-NEXT:    [[TMP32:%.*]] = sub i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = icmp uge i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP34:%.*]] = icmp uge i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP35:%.*]] = and i1 [[TMP33]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = add i32 [[TMP30]], 1
; CHECK-NEXT:    [[TMP37:%.*]] = sub i32 [[TMP30]], 1
; CHECK-NEXT:    [[TMP38:%.*]] = select i1 [[TMP35]], i32 [[TMP36]], i32 [[TMP30]]
; CHECK-NEXT:    [[TMP39:%.*]] = select i1 [[TMP34]], i32 [[TMP38]], i32 [[TMP37]]
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <4 x i32> undef, i32 [[TMP39]], i64 0
; CHECK-NEXT:    [[TMP41:%.*]] = extractelement <4 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <4 x i32> [[Y]], i64 1
; CHECK-NEXT:    [[TMP43:%.*]] = uitofp i32 [[TMP42]] to float
; CHECK-NEXT:    [[TMP44:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP43]])
; CHECK-NEXT:    [[TMP45:%.*]] = fmul fast float [[TMP44]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP46:%.*]] = fptoui float [[TMP45]] to i32
; CHECK-NEXT:    [[TMP47:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP48:%.*]] = zext i32 [[TMP42]] to i64
; CHECK-NEXT:    [[TMP49:%.*]] = mul i64 [[TMP47]], [[TMP48]]
; CHECK-NEXT:    [[TMP50:%.*]] = trunc i64 [[TMP49]] to i32
; CHECK-NEXT:    [[TMP51:%.*]] = lshr i64 [[TMP49]], 32
; CHECK-NEXT:    [[TMP52:%.*]] = trunc i64 [[TMP51]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = sub i32 0, [[TMP50]]
; CHECK-NEXT:    [[TMP54:%.*]] = icmp eq i32 [[TMP52]], 0
; CHECK-NEXT:    [[TMP55:%.*]] = select i1 [[TMP54]], i32 [[TMP53]], i32 [[TMP50]]
; CHECK-NEXT:    [[TMP56:%.*]] = zext i32 [[TMP55]] to i64
; CHECK-NEXT:    [[TMP57:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP58:%.*]] = mul i64 [[TMP56]], [[TMP57]]
; CHECK-NEXT:    [[TMP59:%.*]] = trunc i64 [[TMP58]] to i32
; CHECK-NEXT:    [[TMP60:%.*]] = lshr i64 [[TMP58]], 32
; CHECK-NEXT:    [[TMP61:%.*]] = trunc i64 [[TMP60]] to i32
; CHECK-NEXT:    [[TMP62:%.*]] = add i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP64:%.*]] = select i1 [[TMP54]], i32 [[TMP62]], i32 [[TMP63]]
; CHECK-NEXT:    [[TMP65:%.*]] = zext i32 [[TMP64]] to i64
; CHECK-NEXT:    [[TMP66:%.*]] = zext i32 [[TMP41]] to i64
; CHECK-NEXT:    [[TMP67:%.*]] = mul i64 [[TMP65]], [[TMP66]]
; CHECK-NEXT:    [[TMP68:%.*]] = trunc i64 [[TMP67]] to i32
; CHECK-NEXT:    [[TMP69:%.*]] = lshr i64 [[TMP67]], 32
; CHECK-NEXT:    [[TMP70:%.*]] = trunc i64 [[TMP69]] to i32
; CHECK-NEXT:    [[TMP71:%.*]] = mul i32 [[TMP70]], [[TMP42]]
; CHECK-NEXT:    [[TMP72:%.*]] = sub i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = icmp uge i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP74:%.*]] = icmp uge i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP75:%.*]] = and i1 [[TMP73]], [[TMP74]]
; CHECK-NEXT:    [[TMP76:%.*]] = add i32 [[TMP70]], 1
; CHECK-NEXT:    [[TMP77:%.*]] = sub i32 [[TMP70]], 1
; CHECK-NEXT:    [[TMP78:%.*]] = select i1 [[TMP75]], i32 [[TMP76]], i32 [[TMP70]]
; CHECK-NEXT:    [[TMP79:%.*]] = select i1 [[TMP74]], i32 [[TMP78]], i32 [[TMP77]]
; CHECK-NEXT:    [[TMP80:%.*]] = insertelement <4 x i32> [[TMP40]], i32 [[TMP79]], i64 1
; CHECK-NEXT:    [[TMP81:%.*]] = extractelement <4 x i32> [[X]], i64 2
; CHECK-NEXT:    [[TMP82:%.*]] = extractelement <4 x i32> [[Y]], i64 2
; CHECK-NEXT:    [[TMP83:%.*]] = uitofp i32 [[TMP82]] to float
; CHECK-NEXT:    [[TMP84:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP83]])
; CHECK-NEXT:    [[TMP85:%.*]] = fmul fast float [[TMP84]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP86:%.*]] = fptoui float [[TMP85]] to i32
; CHECK-NEXT:    [[TMP87:%.*]] = zext i32 [[TMP86]] to i64
; CHECK-NEXT:    [[TMP88:%.*]] = zext i32 [[TMP82]] to i64
; CHECK-NEXT:    [[TMP89:%.*]] = mul i64 [[TMP87]], [[TMP88]]
; CHECK-NEXT:    [[TMP90:%.*]] = trunc i64 [[TMP89]] to i32
; CHECK-NEXT:    [[TMP91:%.*]] = lshr i64 [[TMP89]], 32
; CHECK-NEXT:    [[TMP92:%.*]] = trunc i64 [[TMP91]] to i32
; CHECK-NEXT:    [[TMP93:%.*]] = sub i32 0, [[TMP90]]
; CHECK-NEXT:    [[TMP94:%.*]] = icmp eq i32 [[TMP92]], 0
; CHECK-NEXT:    [[TMP95:%.*]] = select i1 [[TMP94]], i32 [[TMP93]], i32 [[TMP90]]
; CHECK-NEXT:    [[TMP96:%.*]] = zext i32 [[TMP95]] to i64
; CHECK-NEXT:    [[TMP97:%.*]] = zext i32 [[TMP86]] to i64
; CHECK-NEXT:    [[TMP98:%.*]] = mul i64 [[TMP96]], [[TMP97]]
; CHECK-NEXT:    [[TMP99:%.*]] = trunc i64 [[TMP98]] to i32
; CHECK-NEXT:    [[TMP100:%.*]] = lshr i64 [[TMP98]], 32
; CHECK-NEXT:    [[TMP101:%.*]] = trunc i64 [[TMP100]] to i32
; CHECK-NEXT:    [[TMP102:%.*]] = add i32 [[TMP86]], [[TMP101]]
; CHECK-NEXT:    [[TMP103:%.*]] = sub i32 [[TMP86]], [[TMP101]]
; CHECK-NEXT:    [[TMP104:%.*]] = select i1 [[TMP94]], i32 [[TMP102]], i32 [[TMP103]]
; CHECK-NEXT:    [[TMP105:%.*]] = zext i32 [[TMP104]] to i64
; CHECK-NEXT:    [[TMP106:%.*]] = zext i32 [[TMP81]] to i64
; CHECK-NEXT:    [[TMP107:%.*]] = mul i64 [[TMP105]], [[TMP106]]
; CHECK-NEXT:    [[TMP108:%.*]] = trunc i64 [[TMP107]] to i32
; CHECK-NEXT:    [[TMP109:%.*]] = lshr i64 [[TMP107]], 32
; CHECK-NEXT:    [[TMP110:%.*]] = trunc i64 [[TMP109]] to i32
; CHECK-NEXT:    [[TMP111:%.*]] = mul i32 [[TMP110]], [[TMP82]]
; CHECK-NEXT:    [[TMP112:%.*]] = sub i32 [[TMP81]], [[TMP111]]
; CHECK-NEXT:    [[TMP113:%.*]] = icmp uge i32 [[TMP112]], [[TMP82]]
; CHECK-NEXT:    [[TMP114:%.*]] = icmp uge i32 [[TMP81]], [[TMP111]]
; CHECK-NEXT:    [[TMP115:%.*]] = and i1 [[TMP113]], [[TMP114]]
; CHECK-NEXT:    [[TMP116:%.*]] = add i32 [[TMP110]], 1
; CHECK-NEXT:    [[TMP117:%.*]] = sub i32 [[TMP110]], 1
; CHECK-NEXT:    [[TMP118:%.*]] = select i1 [[TMP115]], i32 [[TMP116]], i32 [[TMP110]]
; CHECK-NEXT:    [[TMP119:%.*]] = select i1 [[TMP114]], i32 [[TMP118]], i32 [[TMP117]]
; CHECK-NEXT:    [[TMP120:%.*]] = insertelement <4 x i32> [[TMP80]], i32 [[TMP119]], i64 2
; CHECK-NEXT:    [[TMP121:%.*]] = extractelement <4 x i32> [[X]], i64 3
; CHECK-NEXT:    [[TMP122:%.*]] = extractelement <4 x i32> [[Y]], i64 3
; CHECK-NEXT:    [[TMP123:%.*]] = uitofp i32 [[TMP122]] to float
; CHECK-NEXT:    [[TMP124:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP123]])
; CHECK-NEXT:    [[TMP125:%.*]] = fmul fast float [[TMP124]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP126:%.*]] = fptoui float [[TMP125]] to i32
; CHECK-NEXT:    [[TMP127:%.*]] = zext i32 [[TMP126]] to i64
; CHECK-NEXT:    [[TMP128:%.*]] = zext i32 [[TMP122]] to i64
; CHECK-NEXT:    [[TMP129:%.*]] = mul i64 [[TMP127]], [[TMP128]]
; CHECK-NEXT:    [[TMP130:%.*]] = trunc i64 [[TMP129]] to i32
; CHECK-NEXT:    [[TMP131:%.*]] = lshr i64 [[TMP129]], 32
; CHECK-NEXT:    [[TMP132:%.*]] = trunc i64 [[TMP131]] to i32
; CHECK-NEXT:    [[TMP133:%.*]] = sub i32 0, [[TMP130]]
; CHECK-NEXT:    [[TMP134:%.*]] = icmp eq i32 [[TMP132]], 0
; CHECK-NEXT:    [[TMP135:%.*]] = select i1 [[TMP134]], i32 [[TMP133]], i32 [[TMP130]]
; CHECK-NEXT:    [[TMP136:%.*]] = zext i32 [[TMP135]] to i64
; CHECK-NEXT:    [[TMP137:%.*]] = zext i32 [[TMP126]] to i64
; CHECK-NEXT:    [[TMP138:%.*]] = mul i64 [[TMP136]], [[TMP137]]
; CHECK-NEXT:    [[TMP139:%.*]] = trunc i64 [[TMP138]] to i32
; CHECK-NEXT:    [[TMP140:%.*]] = lshr i64 [[TMP138]], 32
; CHECK-NEXT:    [[TMP141:%.*]] = trunc i64 [[TMP140]] to i32
; CHECK-NEXT:    [[TMP142:%.*]] = add i32 [[TMP126]], [[TMP141]]
; CHECK-NEXT:    [[TMP143:%.*]] = sub i32 [[TMP126]], [[TMP141]]
; CHECK-NEXT:    [[TMP144:%.*]] = select i1 [[TMP134]], i32 [[TMP142]], i32 [[TMP143]]
; CHECK-NEXT:    [[TMP145:%.*]] = zext i32 [[TMP144]] to i64
; CHECK-NEXT:    [[TMP146:%.*]] = zext i32 [[TMP121]] to i64
; CHECK-NEXT:    [[TMP147:%.*]] = mul i64 [[TMP145]], [[TMP146]]
; CHECK-NEXT:    [[TMP148:%.*]] = trunc i64 [[TMP147]] to i32
; CHECK-NEXT:    [[TMP149:%.*]] = lshr i64 [[TMP147]], 32
; CHECK-NEXT:    [[TMP150:%.*]] = trunc i64 [[TMP149]] to i32
; CHECK-NEXT:    [[TMP151:%.*]] = mul i32 [[TMP150]], [[TMP122]]
; CHECK-NEXT:    [[TMP152:%.*]] = sub i32 [[TMP121]], [[TMP151]]
; CHECK-NEXT:    [[TMP153:%.*]] = icmp uge i32 [[TMP152]], [[TMP122]]
; CHECK-NEXT:    [[TMP154:%.*]] = icmp uge i32 [[TMP121]], [[TMP151]]
; CHECK-NEXT:    [[TMP155:%.*]] = and i1 [[TMP153]], [[TMP154]]
; CHECK-NEXT:    [[TMP156:%.*]] = add i32 [[TMP150]], 1
; CHECK-NEXT:    [[TMP157:%.*]] = sub i32 [[TMP150]], 1
; CHECK-NEXT:    [[TMP158:%.*]] = select i1 [[TMP155]], i32 [[TMP156]], i32 [[TMP150]]
; CHECK-NEXT:    [[TMP159:%.*]] = select i1 [[TMP154]], i32 [[TMP158]], i32 [[TMP157]]
; CHECK-NEXT:    [[TMP160:%.*]] = insertelement <4 x i32> [[TMP120]], i32 [[TMP159]], i64 3
; CHECK-NEXT:    store <4 x i32> [[TMP160]], <4 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v4i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx8 s[8:15], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s6, 0x4f800000
; GCN-NEXT:    s_load_dwordx2 s[16:17], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s19, 0xf000
; GCN-NEXT:    s_mov_b32 s18, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s12
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s13
; GCN-NEXT:    v_cvt_f32_u32_e32 v7, s15
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v1
; GCN-NEXT:    v_mul_f32_e32 v0, s6, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_f32_e32 v1, s6, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s12
; GCN-NEXT:    v_mul_lo_u32 v3, v0, s12
; GCN-NEXT:    v_mul_hi_u32 v4, v1, s13
; GCN-NEXT:    v_mul_lo_u32 v5, v1, s13
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_sub_i32_e32 v6, vcc, 0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v2, v3, v6, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v0
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v5
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v2, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v2, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v6, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s8
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v4
; GCN-NEXT:    v_cndmask_b32_e64 v2, v5, v3, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v1
; GCN-NEXT:    v_mul_lo_u32 v3, v0, s12
; GCN-NEXT:    v_add_i32_e32 v4, vcc, -1, v0
; GCN-NEXT:    v_sub_i32_e32 v5, vcc, s8, v3
; GCN-NEXT:    v_cmp_le_u32_e64 s[4:5], s12, v5
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v2, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s14
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v5, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s9
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s8, v3
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, 1, v0
; GCN-NEXT:    s_and_b64 vcc, s[4:5], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v3, vcc
; GCN-NEXT:    v_mul_f32_e32 v2, s6, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v2
; GCN-NEXT:    v_mul_lo_u32 v3, v1, s13
; GCN-NEXT:    v_cndmask_b32_e64 v0, v4, v0, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v6, v2, s14
; GCN-NEXT:    v_mul_lo_u32 v5, v2, s14
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s9, v3
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s9, v3
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v6
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v5
; GCN-NEXT:    v_cndmask_b32_e64 v3, v5, v3, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v3, v3, v2
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s13, v4
; GCN-NEXT:    v_add_i32_e32 v4, vcc, -1, v1
; GCN-NEXT:    v_add_i32_e32 v5, vcc, 1, v1
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v3, v2
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_rcp_iflag_f32_e32 v3, v7
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v6, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, s10
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_mul_f32_e32 v3, s6, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v3
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, v2, s14
; GCN-NEXT:    v_cndmask_b32_e64 v1, v4, v1, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v7, v3, s15
; GCN-NEXT:    v_mul_lo_u32 v6, v3, s15
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s10, v5
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s14, v4
; GCN-NEXT:    v_cmp_eq_u32_e64 s[2:3], 0, v7
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v6
; GCN-NEXT:    v_cndmask_b32_e64 v4, v6, v4, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v4, v4, v3
; GCN-NEXT:    v_add_i32_e32 v6, vcc, -1, v2
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v4, v3
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, v3, v7, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v3, v3, s11
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s10, v5
; GCN-NEXT:    v_add_i32_e32 v4, vcc, 1, v2
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v5, v3, s15
; GCN-NEXT:    v_cndmask_b32_e32 v2, v2, v4, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v6, v2, s[2:3]
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s11, v5
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s15, v4
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s11, v5
; GCN-NEXT:    v_add_i32_e32 v4, vcc, -1, v3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, 1, v3
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v3, v3, v5, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v3, v4, v3, s[2:3]
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[16:19], 0
; GCN-NEXT:    s_endpgm
  %r = udiv <4 x i32> %x, %y
  store <4 x i32> %r, <4 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v4i32(<4 x i32> addrspace(1)* %out, <4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: @urem_v4i32(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i32> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP3]])
; CHECK-NEXT:    [[TMP5:%.*]] = fmul fast float [[TMP4]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP6:%.*]] = fptoui float [[TMP5]] to i32
; CHECK-NEXT:    [[TMP7:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP2]] to i64
; CHECK-NEXT:    [[TMP9:%.*]] = mul i64 [[TMP7]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = trunc i64 [[TMP9]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = lshr i64 [[TMP9]], 32
; CHECK-NEXT:    [[TMP12:%.*]] = trunc i64 [[TMP11]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = sub i32 0, [[TMP10]]
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], 0
; CHECK-NEXT:    [[TMP15:%.*]] = select i1 [[TMP14]], i32 [[TMP13]], i32 [[TMP10]]
; CHECK-NEXT:    [[TMP16:%.*]] = zext i32 [[TMP15]] to i64
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP18:%.*]] = mul i64 [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = lshr i64 [[TMP18]], 32
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i64 [[TMP20]] to i32
; CHECK-NEXT:    [[TMP22:%.*]] = add i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = sub i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP24:%.*]] = select i1 [[TMP14]], i32 [[TMP22]], i32 [[TMP23]]
; CHECK-NEXT:    [[TMP25:%.*]] = zext i32 [[TMP24]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    [[TMP27:%.*]] = mul i64 [[TMP25]], [[TMP26]]
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = lshr i64 [[TMP27]], 32
; CHECK-NEXT:    [[TMP30:%.*]] = trunc i64 [[TMP29]] to i32
; CHECK-NEXT:    [[TMP31:%.*]] = mul i32 [[TMP30]], [[TMP2]]
; CHECK-NEXT:    [[TMP32:%.*]] = sub i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = icmp uge i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP34:%.*]] = icmp uge i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP35:%.*]] = and i1 [[TMP33]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = sub i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP37:%.*]] = add i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP38:%.*]] = select i1 [[TMP35]], i32 [[TMP36]], i32 [[TMP32]]
; CHECK-NEXT:    [[TMP39:%.*]] = select i1 [[TMP34]], i32 [[TMP38]], i32 [[TMP37]]
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <4 x i32> undef, i32 [[TMP39]], i64 0
; CHECK-NEXT:    [[TMP41:%.*]] = extractelement <4 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <4 x i32> [[Y]], i64 1
; CHECK-NEXT:    [[TMP43:%.*]] = uitofp i32 [[TMP42]] to float
; CHECK-NEXT:    [[TMP44:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP43]])
; CHECK-NEXT:    [[TMP45:%.*]] = fmul fast float [[TMP44]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP46:%.*]] = fptoui float [[TMP45]] to i32
; CHECK-NEXT:    [[TMP47:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP48:%.*]] = zext i32 [[TMP42]] to i64
; CHECK-NEXT:    [[TMP49:%.*]] = mul i64 [[TMP47]], [[TMP48]]
; CHECK-NEXT:    [[TMP50:%.*]] = trunc i64 [[TMP49]] to i32
; CHECK-NEXT:    [[TMP51:%.*]] = lshr i64 [[TMP49]], 32
; CHECK-NEXT:    [[TMP52:%.*]] = trunc i64 [[TMP51]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = sub i32 0, [[TMP50]]
; CHECK-NEXT:    [[TMP54:%.*]] = icmp eq i32 [[TMP52]], 0
; CHECK-NEXT:    [[TMP55:%.*]] = select i1 [[TMP54]], i32 [[TMP53]], i32 [[TMP50]]
; CHECK-NEXT:    [[TMP56:%.*]] = zext i32 [[TMP55]] to i64
; CHECK-NEXT:    [[TMP57:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP58:%.*]] = mul i64 [[TMP56]], [[TMP57]]
; CHECK-NEXT:    [[TMP59:%.*]] = trunc i64 [[TMP58]] to i32
; CHECK-NEXT:    [[TMP60:%.*]] = lshr i64 [[TMP58]], 32
; CHECK-NEXT:    [[TMP61:%.*]] = trunc i64 [[TMP60]] to i32
; CHECK-NEXT:    [[TMP62:%.*]] = add i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP64:%.*]] = select i1 [[TMP54]], i32 [[TMP62]], i32 [[TMP63]]
; CHECK-NEXT:    [[TMP65:%.*]] = zext i32 [[TMP64]] to i64
; CHECK-NEXT:    [[TMP66:%.*]] = zext i32 [[TMP41]] to i64
; CHECK-NEXT:    [[TMP67:%.*]] = mul i64 [[TMP65]], [[TMP66]]
; CHECK-NEXT:    [[TMP68:%.*]] = trunc i64 [[TMP67]] to i32
; CHECK-NEXT:    [[TMP69:%.*]] = lshr i64 [[TMP67]], 32
; CHECK-NEXT:    [[TMP70:%.*]] = trunc i64 [[TMP69]] to i32
; CHECK-NEXT:    [[TMP71:%.*]] = mul i32 [[TMP70]], [[TMP42]]
; CHECK-NEXT:    [[TMP72:%.*]] = sub i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = icmp uge i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP74:%.*]] = icmp uge i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP75:%.*]] = and i1 [[TMP73]], [[TMP74]]
; CHECK-NEXT:    [[TMP76:%.*]] = sub i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP77:%.*]] = add i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP78:%.*]] = select i1 [[TMP75]], i32 [[TMP76]], i32 [[TMP72]]
; CHECK-NEXT:    [[TMP79:%.*]] = select i1 [[TMP74]], i32 [[TMP78]], i32 [[TMP77]]
; CHECK-NEXT:    [[TMP80:%.*]] = insertelement <4 x i32> [[TMP40]], i32 [[TMP79]], i64 1
; CHECK-NEXT:    [[TMP81:%.*]] = extractelement <4 x i32> [[X]], i64 2
; CHECK-NEXT:    [[TMP82:%.*]] = extractelement <4 x i32> [[Y]], i64 2
; CHECK-NEXT:    [[TMP83:%.*]] = uitofp i32 [[TMP82]] to float
; CHECK-NEXT:    [[TMP84:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP83]])
; CHECK-NEXT:    [[TMP85:%.*]] = fmul fast float [[TMP84]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP86:%.*]] = fptoui float [[TMP85]] to i32
; CHECK-NEXT:    [[TMP87:%.*]] = zext i32 [[TMP86]] to i64
; CHECK-NEXT:    [[TMP88:%.*]] = zext i32 [[TMP82]] to i64
; CHECK-NEXT:    [[TMP89:%.*]] = mul i64 [[TMP87]], [[TMP88]]
; CHECK-NEXT:    [[TMP90:%.*]] = trunc i64 [[TMP89]] to i32
; CHECK-NEXT:    [[TMP91:%.*]] = lshr i64 [[TMP89]], 32
; CHECK-NEXT:    [[TMP92:%.*]] = trunc i64 [[TMP91]] to i32
; CHECK-NEXT:    [[TMP93:%.*]] = sub i32 0, [[TMP90]]
; CHECK-NEXT:    [[TMP94:%.*]] = icmp eq i32 [[TMP92]], 0
; CHECK-NEXT:    [[TMP95:%.*]] = select i1 [[TMP94]], i32 [[TMP93]], i32 [[TMP90]]
; CHECK-NEXT:    [[TMP96:%.*]] = zext i32 [[TMP95]] to i64
; CHECK-NEXT:    [[TMP97:%.*]] = zext i32 [[TMP86]] to i64
; CHECK-NEXT:    [[TMP98:%.*]] = mul i64 [[TMP96]], [[TMP97]]
; CHECK-NEXT:    [[TMP99:%.*]] = trunc i64 [[TMP98]] to i32
; CHECK-NEXT:    [[TMP100:%.*]] = lshr i64 [[TMP98]], 32
; CHECK-NEXT:    [[TMP101:%.*]] = trunc i64 [[TMP100]] to i32
; CHECK-NEXT:    [[TMP102:%.*]] = add i32 [[TMP86]], [[TMP101]]
; CHECK-NEXT:    [[TMP103:%.*]] = sub i32 [[TMP86]], [[TMP101]]
; CHECK-NEXT:    [[TMP104:%.*]] = select i1 [[TMP94]], i32 [[TMP102]], i32 [[TMP103]]
; CHECK-NEXT:    [[TMP105:%.*]] = zext i32 [[TMP104]] to i64
; CHECK-NEXT:    [[TMP106:%.*]] = zext i32 [[TMP81]] to i64
; CHECK-NEXT:    [[TMP107:%.*]] = mul i64 [[TMP105]], [[TMP106]]
; CHECK-NEXT:    [[TMP108:%.*]] = trunc i64 [[TMP107]] to i32
; CHECK-NEXT:    [[TMP109:%.*]] = lshr i64 [[TMP107]], 32
; CHECK-NEXT:    [[TMP110:%.*]] = trunc i64 [[TMP109]] to i32
; CHECK-NEXT:    [[TMP111:%.*]] = mul i32 [[TMP110]], [[TMP82]]
; CHECK-NEXT:    [[TMP112:%.*]] = sub i32 [[TMP81]], [[TMP111]]
; CHECK-NEXT:    [[TMP113:%.*]] = icmp uge i32 [[TMP112]], [[TMP82]]
; CHECK-NEXT:    [[TMP114:%.*]] = icmp uge i32 [[TMP81]], [[TMP111]]
; CHECK-NEXT:    [[TMP115:%.*]] = and i1 [[TMP113]], [[TMP114]]
; CHECK-NEXT:    [[TMP116:%.*]] = sub i32 [[TMP112]], [[TMP82]]
; CHECK-NEXT:    [[TMP117:%.*]] = add i32 [[TMP112]], [[TMP82]]
; CHECK-NEXT:    [[TMP118:%.*]] = select i1 [[TMP115]], i32 [[TMP116]], i32 [[TMP112]]
; CHECK-NEXT:    [[TMP119:%.*]] = select i1 [[TMP114]], i32 [[TMP118]], i32 [[TMP117]]
; CHECK-NEXT:    [[TMP120:%.*]] = insertelement <4 x i32> [[TMP80]], i32 [[TMP119]], i64 2
; CHECK-NEXT:    [[TMP121:%.*]] = extractelement <4 x i32> [[X]], i64 3
; CHECK-NEXT:    [[TMP122:%.*]] = extractelement <4 x i32> [[Y]], i64 3
; CHECK-NEXT:    [[TMP123:%.*]] = uitofp i32 [[TMP122]] to float
; CHECK-NEXT:    [[TMP124:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP123]])
; CHECK-NEXT:    [[TMP125:%.*]] = fmul fast float [[TMP124]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP126:%.*]] = fptoui float [[TMP125]] to i32
; CHECK-NEXT:    [[TMP127:%.*]] = zext i32 [[TMP126]] to i64
; CHECK-NEXT:    [[TMP128:%.*]] = zext i32 [[TMP122]] to i64
; CHECK-NEXT:    [[TMP129:%.*]] = mul i64 [[TMP127]], [[TMP128]]
; CHECK-NEXT:    [[TMP130:%.*]] = trunc i64 [[TMP129]] to i32
; CHECK-NEXT:    [[TMP131:%.*]] = lshr i64 [[TMP129]], 32
; CHECK-NEXT:    [[TMP132:%.*]] = trunc i64 [[TMP131]] to i32
; CHECK-NEXT:    [[TMP133:%.*]] = sub i32 0, [[TMP130]]
; CHECK-NEXT:    [[TMP134:%.*]] = icmp eq i32 [[TMP132]], 0
; CHECK-NEXT:    [[TMP135:%.*]] = select i1 [[TMP134]], i32 [[TMP133]], i32 [[TMP130]]
; CHECK-NEXT:    [[TMP136:%.*]] = zext i32 [[TMP135]] to i64
; CHECK-NEXT:    [[TMP137:%.*]] = zext i32 [[TMP126]] to i64
; CHECK-NEXT:    [[TMP138:%.*]] = mul i64 [[TMP136]], [[TMP137]]
; CHECK-NEXT:    [[TMP139:%.*]] = trunc i64 [[TMP138]] to i32
; CHECK-NEXT:    [[TMP140:%.*]] = lshr i64 [[TMP138]], 32
; CHECK-NEXT:    [[TMP141:%.*]] = trunc i64 [[TMP140]] to i32
; CHECK-NEXT:    [[TMP142:%.*]] = add i32 [[TMP126]], [[TMP141]]
; CHECK-NEXT:    [[TMP143:%.*]] = sub i32 [[TMP126]], [[TMP141]]
; CHECK-NEXT:    [[TMP144:%.*]] = select i1 [[TMP134]], i32 [[TMP142]], i32 [[TMP143]]
; CHECK-NEXT:    [[TMP145:%.*]] = zext i32 [[TMP144]] to i64
; CHECK-NEXT:    [[TMP146:%.*]] = zext i32 [[TMP121]] to i64
; CHECK-NEXT:    [[TMP147:%.*]] = mul i64 [[TMP145]], [[TMP146]]
; CHECK-NEXT:    [[TMP148:%.*]] = trunc i64 [[TMP147]] to i32
; CHECK-NEXT:    [[TMP149:%.*]] = lshr i64 [[TMP147]], 32
; CHECK-NEXT:    [[TMP150:%.*]] = trunc i64 [[TMP149]] to i32
; CHECK-NEXT:    [[TMP151:%.*]] = mul i32 [[TMP150]], [[TMP122]]
; CHECK-NEXT:    [[TMP152:%.*]] = sub i32 [[TMP121]], [[TMP151]]
; CHECK-NEXT:    [[TMP153:%.*]] = icmp uge i32 [[TMP152]], [[TMP122]]
; CHECK-NEXT:    [[TMP154:%.*]] = icmp uge i32 [[TMP121]], [[TMP151]]
; CHECK-NEXT:    [[TMP155:%.*]] = and i1 [[TMP153]], [[TMP154]]
; CHECK-NEXT:    [[TMP156:%.*]] = sub i32 [[TMP152]], [[TMP122]]
; CHECK-NEXT:    [[TMP157:%.*]] = add i32 [[TMP152]], [[TMP122]]
; CHECK-NEXT:    [[TMP158:%.*]] = select i1 [[TMP155]], i32 [[TMP156]], i32 [[TMP152]]
; CHECK-NEXT:    [[TMP159:%.*]] = select i1 [[TMP154]], i32 [[TMP158]], i32 [[TMP157]]
; CHECK-NEXT:    [[TMP160:%.*]] = insertelement <4 x i32> [[TMP120]], i32 [[TMP159]], i64 3
; CHECK-NEXT:    store <4 x i32> [[TMP160]], <4 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v4i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx8 s[8:15], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s6, 0x4f800000
; GCN-NEXT:    s_load_dwordx2 s[16:17], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s19, 0xf000
; GCN-NEXT:    s_mov_b32 s18, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s12
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s13
; GCN-NEXT:    v_cvt_f32_u32_e32 v7, s15
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v1
; GCN-NEXT:    v_mul_f32_e32 v0, s6, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_f32_e32 v1, s6, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s12
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s12
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v2
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v0
; GCN-NEXT:    v_mul_lo_u32 v3, v1, s13
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v2, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v2, v0
; GCN-NEXT:    v_mul_hi_u32 v2, v1, s13
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v4, s[0:1]
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v3
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s8
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v3, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v1
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s12
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v2, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s14
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v5, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s9
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s8, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_u32_e64 s[4:5], s8, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s13
; GCN-NEXT:    v_cmp_le_u32_e64 s[2:3], s12, v3
; GCN-NEXT:    v_mul_f32_e32 v2, s6, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v2
; GCN-NEXT:    v_add_i32_e32 v4, vcc, s12, v3
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s12, v3
; GCN-NEXT:    s_and_b64 vcc, s[2:3], s[4:5]
; GCN-NEXT:    v_mul_lo_u32 v5, v2, s14
; GCN-NEXT:    v_mul_hi_u32 v6, v2, s14
; GCN-NEXT:    v_cndmask_b32_e32 v0, v3, v0, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v4, v0, s[4:5]
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s9, v1
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s9, v1
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, 0, v5
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v6
; GCN-NEXT:    v_cndmask_b32_e64 v1, v5, v1, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v2
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s13, v3
; GCN-NEXT:    v_add_i32_e32 v4, vcc, s13, v3
; GCN-NEXT:    v_subrev_i32_e32 v5, vcc, s13, v3
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v1, v2
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v1, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v6, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s10
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v7
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v3, v3, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, v1, s14
; GCN-NEXT:    v_mul_f32_e32 v1, s6, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v1
; GCN-NEXT:    v_cndmask_b32_e64 v1, v4, v3, s[2:3]
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s10, v5
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s14, v3
; GCN-NEXT:    v_mul_lo_u32 v4, v2, s15
; GCN-NEXT:    v_mul_hi_u32 v6, v2, s15
; GCN-NEXT:    v_sub_i32_e32 v7, vcc, 0, v4
; GCN-NEXT:    v_cmp_eq_u32_e64 s[2:3], 0, v6
; GCN-NEXT:    v_cndmask_b32_e64 v4, v4, v7, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v4, v4, v2
; GCN-NEXT:    v_add_i32_e32 v6, vcc, s14, v3
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v4, v2
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, v4, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v7, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, s11
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s10, v5
; GCN-NEXT:    v_subrev_i32_e32 v4, vcc, s14, v3
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v5, v2, s15
; GCN-NEXT:    v_cndmask_b32_e32 v2, v3, v4, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v6, v2, s[2:3]
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s11, v5
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s11, v5
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s15, v3
; GCN-NEXT:    v_add_i32_e32 v4, vcc, s15, v3
; GCN-NEXT:    v_subrev_i32_e32 v5, vcc, s15, v3
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v3, v3, v5, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v3, v4, v3, s[2:3]
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[16:19], 0
; GCN-NEXT:    s_endpgm
  %r = urem <4 x i32> %x, %y
  store <4 x i32> %r, <4 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v4i32(<4 x i32> addrspace(1)* %out, <4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: @sdiv_v4i32(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i32> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = ashr i32 [[TMP1]], 31
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP2]], 31
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = add i32 [[TMP1]], [[TMP3]]
; CHECK-NEXT:    [[TMP7:%.*]] = add i32 [[TMP2]], [[TMP4]]
; CHECK-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP3]]
; CHECK-NEXT:    [[TMP9:%.*]] = xor i32 [[TMP7]], [[TMP4]]
; CHECK-NEXT:    [[TMP10:%.*]] = uitofp i32 [[TMP9]] to float
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP10]])
; CHECK-NEXT:    [[TMP12:%.*]] = fmul fast float [[TMP11]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP13:%.*]] = fptoui float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = zext i32 [[TMP13]] to i64
; CHECK-NEXT:    [[TMP15:%.*]] = zext i32 [[TMP9]] to i64
; CHECK-NEXT:    [[TMP16:%.*]] = mul i64 [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i64 [[TMP16]] to i32
; CHECK-NEXT:    [[TMP18:%.*]] = lshr i64 [[TMP16]], 32
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = sub i32 0, [[TMP17]]
; CHECK-NEXT:    [[TMP21:%.*]] = icmp eq i32 [[TMP19]], 0
; CHECK-NEXT:    [[TMP22:%.*]] = select i1 [[TMP21]], i32 [[TMP20]], i32 [[TMP17]]
; CHECK-NEXT:    [[TMP23:%.*]] = zext i32 [[TMP22]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = zext i32 [[TMP13]] to i64
; CHECK-NEXT:    [[TMP25:%.*]] = mul i64 [[TMP23]], [[TMP24]]
; CHECK-NEXT:    [[TMP26:%.*]] = trunc i64 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = lshr i64 [[TMP25]], 32
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = add i32 [[TMP13]], [[TMP28]]
; CHECK-NEXT:    [[TMP30:%.*]] = sub i32 [[TMP13]], [[TMP28]]
; CHECK-NEXT:    [[TMP31:%.*]] = select i1 [[TMP21]], i32 [[TMP29]], i32 [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = zext i32 [[TMP31]] to i64
; CHECK-NEXT:    [[TMP33:%.*]] = zext i32 [[TMP8]] to i64
; CHECK-NEXT:    [[TMP34:%.*]] = mul i64 [[TMP32]], [[TMP33]]
; CHECK-NEXT:    [[TMP35:%.*]] = trunc i64 [[TMP34]] to i32
; CHECK-NEXT:    [[TMP36:%.*]] = lshr i64 [[TMP34]], 32
; CHECK-NEXT:    [[TMP37:%.*]] = trunc i64 [[TMP36]] to i32
; CHECK-NEXT:    [[TMP38:%.*]] = mul i32 [[TMP37]], [[TMP9]]
; CHECK-NEXT:    [[TMP39:%.*]] = sub i32 [[TMP8]], [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = icmp uge i32 [[TMP39]], [[TMP9]]
; CHECK-NEXT:    [[TMP41:%.*]] = icmp uge i32 [[TMP8]], [[TMP38]]
; CHECK-NEXT:    [[TMP42:%.*]] = and i1 [[TMP40]], [[TMP41]]
; CHECK-NEXT:    [[TMP43:%.*]] = add i32 [[TMP37]], 1
; CHECK-NEXT:    [[TMP44:%.*]] = sub i32 [[TMP37]], 1
; CHECK-NEXT:    [[TMP45:%.*]] = select i1 [[TMP42]], i32 [[TMP43]], i32 [[TMP37]]
; CHECK-NEXT:    [[TMP46:%.*]] = select i1 [[TMP41]], i32 [[TMP45]], i32 [[TMP44]]
; CHECK-NEXT:    [[TMP47:%.*]] = xor i32 [[TMP46]], [[TMP5]]
; CHECK-NEXT:    [[TMP48:%.*]] = sub i32 [[TMP47]], [[TMP5]]
; CHECK-NEXT:    [[TMP49:%.*]] = insertelement <4 x i32> undef, i32 [[TMP48]], i64 0
; CHECK-NEXT:    [[TMP50:%.*]] = extractelement <4 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP51:%.*]] = extractelement <4 x i32> [[Y]], i64 1
; CHECK-NEXT:    [[TMP52:%.*]] = ashr i32 [[TMP50]], 31
; CHECK-NEXT:    [[TMP53:%.*]] = ashr i32 [[TMP51]], 31
; CHECK-NEXT:    [[TMP54:%.*]] = xor i32 [[TMP52]], [[TMP53]]
; CHECK-NEXT:    [[TMP55:%.*]] = add i32 [[TMP50]], [[TMP52]]
; CHECK-NEXT:    [[TMP56:%.*]] = add i32 [[TMP51]], [[TMP53]]
; CHECK-NEXT:    [[TMP57:%.*]] = xor i32 [[TMP55]], [[TMP52]]
; CHECK-NEXT:    [[TMP58:%.*]] = xor i32 [[TMP56]], [[TMP53]]
; CHECK-NEXT:    [[TMP59:%.*]] = uitofp i32 [[TMP58]] to float
; CHECK-NEXT:    [[TMP60:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP59]])
; CHECK-NEXT:    [[TMP61:%.*]] = fmul fast float [[TMP60]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP62:%.*]] = fptoui float [[TMP61]] to i32
; CHECK-NEXT:    [[TMP63:%.*]] = zext i32 [[TMP62]] to i64
; CHECK-NEXT:    [[TMP64:%.*]] = zext i32 [[TMP58]] to i64
; CHECK-NEXT:    [[TMP65:%.*]] = mul i64 [[TMP63]], [[TMP64]]
; CHECK-NEXT:    [[TMP66:%.*]] = trunc i64 [[TMP65]] to i32
; CHECK-NEXT:    [[TMP67:%.*]] = lshr i64 [[TMP65]], 32
; CHECK-NEXT:    [[TMP68:%.*]] = trunc i64 [[TMP67]] to i32
; CHECK-NEXT:    [[TMP69:%.*]] = sub i32 0, [[TMP66]]
; CHECK-NEXT:    [[TMP70:%.*]] = icmp eq i32 [[TMP68]], 0
; CHECK-NEXT:    [[TMP71:%.*]] = select i1 [[TMP70]], i32 [[TMP69]], i32 [[TMP66]]
; CHECK-NEXT:    [[TMP72:%.*]] = zext i32 [[TMP71]] to i64
; CHECK-NEXT:    [[TMP73:%.*]] = zext i32 [[TMP62]] to i64
; CHECK-NEXT:    [[TMP74:%.*]] = mul i64 [[TMP72]], [[TMP73]]
; CHECK-NEXT:    [[TMP75:%.*]] = trunc i64 [[TMP74]] to i32
; CHECK-NEXT:    [[TMP76:%.*]] = lshr i64 [[TMP74]], 32
; CHECK-NEXT:    [[TMP77:%.*]] = trunc i64 [[TMP76]] to i32
; CHECK-NEXT:    [[TMP78:%.*]] = add i32 [[TMP62]], [[TMP77]]
; CHECK-NEXT:    [[TMP79:%.*]] = sub i32 [[TMP62]], [[TMP77]]
; CHECK-NEXT:    [[TMP80:%.*]] = select i1 [[TMP70]], i32 [[TMP78]], i32 [[TMP79]]
; CHECK-NEXT:    [[TMP81:%.*]] = zext i32 [[TMP80]] to i64
; CHECK-NEXT:    [[TMP82:%.*]] = zext i32 [[TMP57]] to i64
; CHECK-NEXT:    [[TMP83:%.*]] = mul i64 [[TMP81]], [[TMP82]]
; CHECK-NEXT:    [[TMP84:%.*]] = trunc i64 [[TMP83]] to i32
; CHECK-NEXT:    [[TMP85:%.*]] = lshr i64 [[TMP83]], 32
; CHECK-NEXT:    [[TMP86:%.*]] = trunc i64 [[TMP85]] to i32
; CHECK-NEXT:    [[TMP87:%.*]] = mul i32 [[TMP86]], [[TMP58]]
; CHECK-NEXT:    [[TMP88:%.*]] = sub i32 [[TMP57]], [[TMP87]]
; CHECK-NEXT:    [[TMP89:%.*]] = icmp uge i32 [[TMP88]], [[TMP58]]
; CHECK-NEXT:    [[TMP90:%.*]] = icmp uge i32 [[TMP57]], [[TMP87]]
; CHECK-NEXT:    [[TMP91:%.*]] = and i1 [[TMP89]], [[TMP90]]
; CHECK-NEXT:    [[TMP92:%.*]] = add i32 [[TMP86]], 1
; CHECK-NEXT:    [[TMP93:%.*]] = sub i32 [[TMP86]], 1
; CHECK-NEXT:    [[TMP94:%.*]] = select i1 [[TMP91]], i32 [[TMP92]], i32 [[TMP86]]
; CHECK-NEXT:    [[TMP95:%.*]] = select i1 [[TMP90]], i32 [[TMP94]], i32 [[TMP93]]
; CHECK-NEXT:    [[TMP96:%.*]] = xor i32 [[TMP95]], [[TMP54]]
; CHECK-NEXT:    [[TMP97:%.*]] = sub i32 [[TMP96]], [[TMP54]]
; CHECK-NEXT:    [[TMP98:%.*]] = insertelement <4 x i32> [[TMP49]], i32 [[TMP97]], i64 1
; CHECK-NEXT:    [[TMP99:%.*]] = extractelement <4 x i32> [[X]], i64 2
; CHECK-NEXT:    [[TMP100:%.*]] = extractelement <4 x i32> [[Y]], i64 2
; CHECK-NEXT:    [[TMP101:%.*]] = ashr i32 [[TMP99]], 31
; CHECK-NEXT:    [[TMP102:%.*]] = ashr i32 [[TMP100]], 31
; CHECK-NEXT:    [[TMP103:%.*]] = xor i32 [[TMP101]], [[TMP102]]
; CHECK-NEXT:    [[TMP104:%.*]] = add i32 [[TMP99]], [[TMP101]]
; CHECK-NEXT:    [[TMP105:%.*]] = add i32 [[TMP100]], [[TMP102]]
; CHECK-NEXT:    [[TMP106:%.*]] = xor i32 [[TMP104]], [[TMP101]]
; CHECK-NEXT:    [[TMP107:%.*]] = xor i32 [[TMP105]], [[TMP102]]
; CHECK-NEXT:    [[TMP108:%.*]] = uitofp i32 [[TMP107]] to float
; CHECK-NEXT:    [[TMP109:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP108]])
; CHECK-NEXT:    [[TMP110:%.*]] = fmul fast float [[TMP109]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP111:%.*]] = fptoui float [[TMP110]] to i32
; CHECK-NEXT:    [[TMP112:%.*]] = zext i32 [[TMP111]] to i64
; CHECK-NEXT:    [[TMP113:%.*]] = zext i32 [[TMP107]] to i64
; CHECK-NEXT:    [[TMP114:%.*]] = mul i64 [[TMP112]], [[TMP113]]
; CHECK-NEXT:    [[TMP115:%.*]] = trunc i64 [[TMP114]] to i32
; CHECK-NEXT:    [[TMP116:%.*]] = lshr i64 [[TMP114]], 32
; CHECK-NEXT:    [[TMP117:%.*]] = trunc i64 [[TMP116]] to i32
; CHECK-NEXT:    [[TMP118:%.*]] = sub i32 0, [[TMP115]]
; CHECK-NEXT:    [[TMP119:%.*]] = icmp eq i32 [[TMP117]], 0
; CHECK-NEXT:    [[TMP120:%.*]] = select i1 [[TMP119]], i32 [[TMP118]], i32 [[TMP115]]
; CHECK-NEXT:    [[TMP121:%.*]] = zext i32 [[TMP120]] to i64
; CHECK-NEXT:    [[TMP122:%.*]] = zext i32 [[TMP111]] to i64
; CHECK-NEXT:    [[TMP123:%.*]] = mul i64 [[TMP121]], [[TMP122]]
; CHECK-NEXT:    [[TMP124:%.*]] = trunc i64 [[TMP123]] to i32
; CHECK-NEXT:    [[TMP125:%.*]] = lshr i64 [[TMP123]], 32
; CHECK-NEXT:    [[TMP126:%.*]] = trunc i64 [[TMP125]] to i32
; CHECK-NEXT:    [[TMP127:%.*]] = add i32 [[TMP111]], [[TMP126]]
; CHECK-NEXT:    [[TMP128:%.*]] = sub i32 [[TMP111]], [[TMP126]]
; CHECK-NEXT:    [[TMP129:%.*]] = select i1 [[TMP119]], i32 [[TMP127]], i32 [[TMP128]]
; CHECK-NEXT:    [[TMP130:%.*]] = zext i32 [[TMP129]] to i64
; CHECK-NEXT:    [[TMP131:%.*]] = zext i32 [[TMP106]] to i64
; CHECK-NEXT:    [[TMP132:%.*]] = mul i64 [[TMP130]], [[TMP131]]
; CHECK-NEXT:    [[TMP133:%.*]] = trunc i64 [[TMP132]] to i32
; CHECK-NEXT:    [[TMP134:%.*]] = lshr i64 [[TMP132]], 32
; CHECK-NEXT:    [[TMP135:%.*]] = trunc i64 [[TMP134]] to i32
; CHECK-NEXT:    [[TMP136:%.*]] = mul i32 [[TMP135]], [[TMP107]]
; CHECK-NEXT:    [[TMP137:%.*]] = sub i32 [[TMP106]], [[TMP136]]
; CHECK-NEXT:    [[TMP138:%.*]] = icmp uge i32 [[TMP137]], [[TMP107]]
; CHECK-NEXT:    [[TMP139:%.*]] = icmp uge i32 [[TMP106]], [[TMP136]]
; CHECK-NEXT:    [[TMP140:%.*]] = and i1 [[TMP138]], [[TMP139]]
; CHECK-NEXT:    [[TMP141:%.*]] = add i32 [[TMP135]], 1
; CHECK-NEXT:    [[TMP142:%.*]] = sub i32 [[TMP135]], 1
; CHECK-NEXT:    [[TMP143:%.*]] = select i1 [[TMP140]], i32 [[TMP141]], i32 [[TMP135]]
; CHECK-NEXT:    [[TMP144:%.*]] = select i1 [[TMP139]], i32 [[TMP143]], i32 [[TMP142]]
; CHECK-NEXT:    [[TMP145:%.*]] = xor i32 [[TMP144]], [[TMP103]]
; CHECK-NEXT:    [[TMP146:%.*]] = sub i32 [[TMP145]], [[TMP103]]
; CHECK-NEXT:    [[TMP147:%.*]] = insertelement <4 x i32> [[TMP98]], i32 [[TMP146]], i64 2
; CHECK-NEXT:    [[TMP148:%.*]] = extractelement <4 x i32> [[X]], i64 3
; CHECK-NEXT:    [[TMP149:%.*]] = extractelement <4 x i32> [[Y]], i64 3
; CHECK-NEXT:    [[TMP150:%.*]] = ashr i32 [[TMP148]], 31
; CHECK-NEXT:    [[TMP151:%.*]] = ashr i32 [[TMP149]], 31
; CHECK-NEXT:    [[TMP152:%.*]] = xor i32 [[TMP150]], [[TMP151]]
; CHECK-NEXT:    [[TMP153:%.*]] = add i32 [[TMP148]], [[TMP150]]
; CHECK-NEXT:    [[TMP154:%.*]] = add i32 [[TMP149]], [[TMP151]]
; CHECK-NEXT:    [[TMP155:%.*]] = xor i32 [[TMP153]], [[TMP150]]
; CHECK-NEXT:    [[TMP156:%.*]] = xor i32 [[TMP154]], [[TMP151]]
; CHECK-NEXT:    [[TMP157:%.*]] = uitofp i32 [[TMP156]] to float
; CHECK-NEXT:    [[TMP158:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP157]])
; CHECK-NEXT:    [[TMP159:%.*]] = fmul fast float [[TMP158]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP160:%.*]] = fptoui float [[TMP159]] to i32
; CHECK-NEXT:    [[TMP161:%.*]] = zext i32 [[TMP160]] to i64
; CHECK-NEXT:    [[TMP162:%.*]] = zext i32 [[TMP156]] to i64
; CHECK-NEXT:    [[TMP163:%.*]] = mul i64 [[TMP161]], [[TMP162]]
; CHECK-NEXT:    [[TMP164:%.*]] = trunc i64 [[TMP163]] to i32
; CHECK-NEXT:    [[TMP165:%.*]] = lshr i64 [[TMP163]], 32
; CHECK-NEXT:    [[TMP166:%.*]] = trunc i64 [[TMP165]] to i32
; CHECK-NEXT:    [[TMP167:%.*]] = sub i32 0, [[TMP164]]
; CHECK-NEXT:    [[TMP168:%.*]] = icmp eq i32 [[TMP166]], 0
; CHECK-NEXT:    [[TMP169:%.*]] = select i1 [[TMP168]], i32 [[TMP167]], i32 [[TMP164]]
; CHECK-NEXT:    [[TMP170:%.*]] = zext i32 [[TMP169]] to i64
; CHECK-NEXT:    [[TMP171:%.*]] = zext i32 [[TMP160]] to i64
; CHECK-NEXT:    [[TMP172:%.*]] = mul i64 [[TMP170]], [[TMP171]]
; CHECK-NEXT:    [[TMP173:%.*]] = trunc i64 [[TMP172]] to i32
; CHECK-NEXT:    [[TMP174:%.*]] = lshr i64 [[TMP172]], 32
; CHECK-NEXT:    [[TMP175:%.*]] = trunc i64 [[TMP174]] to i32
; CHECK-NEXT:    [[TMP176:%.*]] = add i32 [[TMP160]], [[TMP175]]
; CHECK-NEXT:    [[TMP177:%.*]] = sub i32 [[TMP160]], [[TMP175]]
; CHECK-NEXT:    [[TMP178:%.*]] = select i1 [[TMP168]], i32 [[TMP176]], i32 [[TMP177]]
; CHECK-NEXT:    [[TMP179:%.*]] = zext i32 [[TMP178]] to i64
; CHECK-NEXT:    [[TMP180:%.*]] = zext i32 [[TMP155]] to i64
; CHECK-NEXT:    [[TMP181:%.*]] = mul i64 [[TMP179]], [[TMP180]]
; CHECK-NEXT:    [[TMP182:%.*]] = trunc i64 [[TMP181]] to i32
; CHECK-NEXT:    [[TMP183:%.*]] = lshr i64 [[TMP181]], 32
; CHECK-NEXT:    [[TMP184:%.*]] = trunc i64 [[TMP183]] to i32
; CHECK-NEXT:    [[TMP185:%.*]] = mul i32 [[TMP184]], [[TMP156]]
; CHECK-NEXT:    [[TMP186:%.*]] = sub i32 [[TMP155]], [[TMP185]]
; CHECK-NEXT:    [[TMP187:%.*]] = icmp uge i32 [[TMP186]], [[TMP156]]
; CHECK-NEXT:    [[TMP188:%.*]] = icmp uge i32 [[TMP155]], [[TMP185]]
; CHECK-NEXT:    [[TMP189:%.*]] = and i1 [[TMP187]], [[TMP188]]
; CHECK-NEXT:    [[TMP190:%.*]] = add i32 [[TMP184]], 1
; CHECK-NEXT:    [[TMP191:%.*]] = sub i32 [[TMP184]], 1
; CHECK-NEXT:    [[TMP192:%.*]] = select i1 [[TMP189]], i32 [[TMP190]], i32 [[TMP184]]
; CHECK-NEXT:    [[TMP193:%.*]] = select i1 [[TMP188]], i32 [[TMP192]], i32 [[TMP191]]
; CHECK-NEXT:    [[TMP194:%.*]] = xor i32 [[TMP193]], [[TMP152]]
; CHECK-NEXT:    [[TMP195:%.*]] = sub i32 [[TMP194]], [[TMP152]]
; CHECK-NEXT:    [[TMP196:%.*]] = insertelement <4 x i32> [[TMP147]], i32 [[TMP195]], i64 3
; CHECK-NEXT:    store <4 x i32> [[TMP196]], <4 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v4i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx8 s[12:19], s[0:1], 0xd
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    s_mov_b32 s10, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s2, s16, 31
; GCN-NEXT:    s_add_i32 s3, s16, s2
; GCN-NEXT:    s_xor_b32 s5, s3, s2
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s5
; GCN-NEXT:    s_mov_b32 s16, 0x4f800000
; GCN-NEXT:    s_ashr_i32 s6, s17, 31
; GCN-NEXT:    s_add_i32 s0, s17, s6
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_xor_b32 s17, s0, s6
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s17
; GCN-NEXT:    s_ashr_i32 s3, s12, 31
; GCN-NEXT:    v_mul_f32_e32 v0, s16, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    s_add_i32 s4, s12, s3
; GCN-NEXT:    s_xor_b32 s4, s4, s3
; GCN-NEXT:    s_xor_b32 s7, s3, s2
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s5
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s5
; GCN-NEXT:    s_ashr_i32 s12, s13, 31
; GCN-NEXT:    s_add_i32 s13, s13, s12
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v3
; GCN-NEXT:    s_xor_b32 s13, s13, s12
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v3, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s4
; GCN-NEXT:    v_mul_f32_e32 v1, s16, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s5
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v0
; GCN-NEXT:    v_mul_hi_u32 v5, v1, s17
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s4, v2
; GCN-NEXT:    v_cmp_le_u32_e64 s[2:3], s5, v4
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s17
; GCN-NEXT:    v_cmp_ge_u32_e64 s[0:1], s4, v2
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v5
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v0
; GCN-NEXT:    v_sub_i32_e32 v6, vcc, 0, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, v4, v6, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v4, v4, v1
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v4, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v4, v1
; GCN-NEXT:    s_and_b64 vcc, s[2:3], s[0:1]
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v5, s[4:5]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    s_ashr_i32 s5, s18, 31
; GCN-NEXT:    v_cndmask_b32_e64 v0, v3, v0, s[0:1]
; GCN-NEXT:    s_add_i32 s0, s18, s5
; GCN-NEXT:    s_xor_b32 s4, s12, s6
; GCN-NEXT:    s_xor_b32 s12, s0, s5
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s12
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s13
; GCN-NEXT:    v_xor_b32_e32 v0, s7, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s7, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v4
; GCN-NEXT:    v_mul_lo_u32 v2, v1, s17
; GCN-NEXT:    s_ashr_i32 s6, s19, 31
; GCN-NEXT:    v_mul_f32_e32 v4, s16, v4
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s13, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v4, v4
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s17, v3
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s13, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v1
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v1, v3, v1, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v2, v4, s12
; GCN-NEXT:    v_mul_hi_u32 v3, v4, s12
; GCN-NEXT:    s_ashr_i32 s2, s14, 31
; GCN-NEXT:    s_add_i32 s3, s14, s2
; GCN-NEXT:    v_sub_i32_e32 v5, vcc, 0, v2
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v5, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v4
; GCN-NEXT:    s_xor_b32 s3, s3, s2
; GCN-NEXT:    v_xor_b32_e32 v1, s4, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, s4, v1
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v2, v4
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, v2, v4
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v3, s[0:1]
; GCN-NEXT:    s_add_i32 s0, s19, s6
; GCN-NEXT:    s_xor_b32 s14, s0, s6
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s14
; GCN-NEXT:    v_mul_hi_u32 v2, v2, s3
; GCN-NEXT:    s_xor_b32 s7, s2, s5
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v4
; GCN-NEXT:    v_mul_lo_u32 v3, v2, s12
; GCN-NEXT:    v_mul_f32_e32 v4, s16, v4
; GCN-NEXT:    v_cvt_u32_f32_e32 v4, v4
; GCN-NEXT:    v_sub_i32_e32 v5, vcc, s3, v3
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s12, v5
; GCN-NEXT:    s_ashr_i32 s12, s15, 31
; GCN-NEXT:    v_mul_lo_u32 v6, v4, s14
; GCN-NEXT:    v_mul_hi_u32 v7, v4, s14
; GCN-NEXT:    s_add_i32 s13, s15, s12
; GCN-NEXT:    s_xor_b32 s13, s13, s12
; GCN-NEXT:    v_sub_i32_e32 v8, vcc, 0, v6
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v7
; GCN-NEXT:    v_cndmask_b32_e64 v6, v6, v8, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v6, v6, v4
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s3, v3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, -1, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, 1, v2
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v6, v4
; GCN-NEXT:    v_subrev_i32_e32 v4, vcc, v6, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, v4, v7, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v4, v4, s13
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v2, v2, v3, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v5, v2, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v3, v4, s14
; GCN-NEXT:    v_xor_b32_e32 v2, s7, v2
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, s7, v2
; GCN-NEXT:    s_xor_b32 s4, s12, s6
; GCN-NEXT:    v_sub_i32_e32 v5, vcc, s13, v3
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s14, v5
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s13, v3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, -1, v4
; GCN-NEXT:    v_add_i32_e32 v3, vcc, 1, v4
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v3, v4, v3, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v3, v5, v3, s[2:3]
; GCN-NEXT:    v_xor_b32_e32 v3, s4, v3
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s4, v3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[8:11], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv <4 x i32> %x, %y
  store <4 x i32> %r, <4 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v4i32(<4 x i32> addrspace(1)* %out, <4 x i32> %x, <4 x i32> %y) {
; CHECK-LABEL: @srem_v4i32(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i32> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = ashr i32 [[TMP1]], 31
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP2]], 31
; CHECK-NEXT:    [[TMP5:%.*]] = add i32 [[TMP1]], [[TMP3]]
; CHECK-NEXT:    [[TMP6:%.*]] = add i32 [[TMP2]], [[TMP4]]
; CHECK-NEXT:    [[TMP7:%.*]] = xor i32 [[TMP5]], [[TMP3]]
; CHECK-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP4]]
; CHECK-NEXT:    [[TMP9:%.*]] = uitofp i32 [[TMP8]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP10]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP11]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = zext i32 [[TMP12]] to i64
; CHECK-NEXT:    [[TMP14:%.*]] = zext i32 [[TMP8]] to i64
; CHECK-NEXT:    [[TMP15:%.*]] = mul i64 [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = trunc i64 [[TMP15]] to i32
; CHECK-NEXT:    [[TMP17:%.*]] = lshr i64 [[TMP15]], 32
; CHECK-NEXT:    [[TMP18:%.*]] = trunc i64 [[TMP17]] to i32
; CHECK-NEXT:    [[TMP19:%.*]] = sub i32 0, [[TMP16]]
; CHECK-NEXT:    [[TMP20:%.*]] = icmp eq i32 [[TMP18]], 0
; CHECK-NEXT:    [[TMP21:%.*]] = select i1 [[TMP20]], i32 [[TMP19]], i32 [[TMP16]]
; CHECK-NEXT:    [[TMP22:%.*]] = zext i32 [[TMP21]] to i64
; CHECK-NEXT:    [[TMP23:%.*]] = zext i32 [[TMP12]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = mul i64 [[TMP22]], [[TMP23]]
; CHECK-NEXT:    [[TMP25:%.*]] = trunc i64 [[TMP24]] to i32
; CHECK-NEXT:    [[TMP26:%.*]] = lshr i64 [[TMP24]], 32
; CHECK-NEXT:    [[TMP27:%.*]] = trunc i64 [[TMP26]] to i32
; CHECK-NEXT:    [[TMP28:%.*]] = add i32 [[TMP12]], [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = sub i32 [[TMP12]], [[TMP27]]
; CHECK-NEXT:    [[TMP30:%.*]] = select i1 [[TMP20]], i32 [[TMP28]], i32 [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = zext i32 [[TMP30]] to i64
; CHECK-NEXT:    [[TMP32:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[TMP33:%.*]] = mul i64 [[TMP31]], [[TMP32]]
; CHECK-NEXT:    [[TMP34:%.*]] = trunc i64 [[TMP33]] to i32
; CHECK-NEXT:    [[TMP35:%.*]] = lshr i64 [[TMP33]], 32
; CHECK-NEXT:    [[TMP36:%.*]] = trunc i64 [[TMP35]] to i32
; CHECK-NEXT:    [[TMP37:%.*]] = mul i32 [[TMP36]], [[TMP8]]
; CHECK-NEXT:    [[TMP38:%.*]] = sub i32 [[TMP7]], [[TMP37]]
; CHECK-NEXT:    [[TMP39:%.*]] = icmp uge i32 [[TMP38]], [[TMP8]]
; CHECK-NEXT:    [[TMP40:%.*]] = icmp uge i32 [[TMP7]], [[TMP37]]
; CHECK-NEXT:    [[TMP41:%.*]] = and i1 [[TMP39]], [[TMP40]]
; CHECK-NEXT:    [[TMP42:%.*]] = sub i32 [[TMP38]], [[TMP8]]
; CHECK-NEXT:    [[TMP43:%.*]] = add i32 [[TMP38]], [[TMP8]]
; CHECK-NEXT:    [[TMP44:%.*]] = select i1 [[TMP41]], i32 [[TMP42]], i32 [[TMP38]]
; CHECK-NEXT:    [[TMP45:%.*]] = select i1 [[TMP40]], i32 [[TMP44]], i32 [[TMP43]]
; CHECK-NEXT:    [[TMP46:%.*]] = xor i32 [[TMP45]], [[TMP3]]
; CHECK-NEXT:    [[TMP47:%.*]] = sub i32 [[TMP46]], [[TMP3]]
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <4 x i32> undef, i32 [[TMP47]], i64 0
; CHECK-NEXT:    [[TMP49:%.*]] = extractelement <4 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP50:%.*]] = extractelement <4 x i32> [[Y]], i64 1
; CHECK-NEXT:    [[TMP51:%.*]] = ashr i32 [[TMP49]], 31
; CHECK-NEXT:    [[TMP52:%.*]] = ashr i32 [[TMP50]], 31
; CHECK-NEXT:    [[TMP53:%.*]] = add i32 [[TMP49]], [[TMP51]]
; CHECK-NEXT:    [[TMP54:%.*]] = add i32 [[TMP50]], [[TMP52]]
; CHECK-NEXT:    [[TMP55:%.*]] = xor i32 [[TMP53]], [[TMP51]]
; CHECK-NEXT:    [[TMP56:%.*]] = xor i32 [[TMP54]], [[TMP52]]
; CHECK-NEXT:    [[TMP57:%.*]] = uitofp i32 [[TMP56]] to float
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP59:%.*]] = fmul fast float [[TMP58]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP60:%.*]] = fptoui float [[TMP59]] to i32
; CHECK-NEXT:    [[TMP61:%.*]] = zext i32 [[TMP60]] to i64
; CHECK-NEXT:    [[TMP62:%.*]] = zext i32 [[TMP56]] to i64
; CHECK-NEXT:    [[TMP63:%.*]] = mul i64 [[TMP61]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = trunc i64 [[TMP63]] to i32
; CHECK-NEXT:    [[TMP65:%.*]] = lshr i64 [[TMP63]], 32
; CHECK-NEXT:    [[TMP66:%.*]] = trunc i64 [[TMP65]] to i32
; CHECK-NEXT:    [[TMP67:%.*]] = sub i32 0, [[TMP64]]
; CHECK-NEXT:    [[TMP68:%.*]] = icmp eq i32 [[TMP66]], 0
; CHECK-NEXT:    [[TMP69:%.*]] = select i1 [[TMP68]], i32 [[TMP67]], i32 [[TMP64]]
; CHECK-NEXT:    [[TMP70:%.*]] = zext i32 [[TMP69]] to i64
; CHECK-NEXT:    [[TMP71:%.*]] = zext i32 [[TMP60]] to i64
; CHECK-NEXT:    [[TMP72:%.*]] = mul i64 [[TMP70]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = trunc i64 [[TMP72]] to i32
; CHECK-NEXT:    [[TMP74:%.*]] = lshr i64 [[TMP72]], 32
; CHECK-NEXT:    [[TMP75:%.*]] = trunc i64 [[TMP74]] to i32
; CHECK-NEXT:    [[TMP76:%.*]] = add i32 [[TMP60]], [[TMP75]]
; CHECK-NEXT:    [[TMP77:%.*]] = sub i32 [[TMP60]], [[TMP75]]
; CHECK-NEXT:    [[TMP78:%.*]] = select i1 [[TMP68]], i32 [[TMP76]], i32 [[TMP77]]
; CHECK-NEXT:    [[TMP79:%.*]] = zext i32 [[TMP78]] to i64
; CHECK-NEXT:    [[TMP80:%.*]] = zext i32 [[TMP55]] to i64
; CHECK-NEXT:    [[TMP81:%.*]] = mul i64 [[TMP79]], [[TMP80]]
; CHECK-NEXT:    [[TMP82:%.*]] = trunc i64 [[TMP81]] to i32
; CHECK-NEXT:    [[TMP83:%.*]] = lshr i64 [[TMP81]], 32
; CHECK-NEXT:    [[TMP84:%.*]] = trunc i64 [[TMP83]] to i32
; CHECK-NEXT:    [[TMP85:%.*]] = mul i32 [[TMP84]], [[TMP56]]
; CHECK-NEXT:    [[TMP86:%.*]] = sub i32 [[TMP55]], [[TMP85]]
; CHECK-NEXT:    [[TMP87:%.*]] = icmp uge i32 [[TMP86]], [[TMP56]]
; CHECK-NEXT:    [[TMP88:%.*]] = icmp uge i32 [[TMP55]], [[TMP85]]
; CHECK-NEXT:    [[TMP89:%.*]] = and i1 [[TMP87]], [[TMP88]]
; CHECK-NEXT:    [[TMP90:%.*]] = sub i32 [[TMP86]], [[TMP56]]
; CHECK-NEXT:    [[TMP91:%.*]] = add i32 [[TMP86]], [[TMP56]]
; CHECK-NEXT:    [[TMP92:%.*]] = select i1 [[TMP89]], i32 [[TMP90]], i32 [[TMP86]]
; CHECK-NEXT:    [[TMP93:%.*]] = select i1 [[TMP88]], i32 [[TMP92]], i32 [[TMP91]]
; CHECK-NEXT:    [[TMP94:%.*]] = xor i32 [[TMP93]], [[TMP51]]
; CHECK-NEXT:    [[TMP95:%.*]] = sub i32 [[TMP94]], [[TMP51]]
; CHECK-NEXT:    [[TMP96:%.*]] = insertelement <4 x i32> [[TMP48]], i32 [[TMP95]], i64 1
; CHECK-NEXT:    [[TMP97:%.*]] = extractelement <4 x i32> [[X]], i64 2
; CHECK-NEXT:    [[TMP98:%.*]] = extractelement <4 x i32> [[Y]], i64 2
; CHECK-NEXT:    [[TMP99:%.*]] = ashr i32 [[TMP97]], 31
; CHECK-NEXT:    [[TMP100:%.*]] = ashr i32 [[TMP98]], 31
; CHECK-NEXT:    [[TMP101:%.*]] = add i32 [[TMP97]], [[TMP99]]
; CHECK-NEXT:    [[TMP102:%.*]] = add i32 [[TMP98]], [[TMP100]]
; CHECK-NEXT:    [[TMP103:%.*]] = xor i32 [[TMP101]], [[TMP99]]
; CHECK-NEXT:    [[TMP104:%.*]] = xor i32 [[TMP102]], [[TMP100]]
; CHECK-NEXT:    [[TMP105:%.*]] = uitofp i32 [[TMP104]] to float
; CHECK-NEXT:    [[TMP106:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP105]])
; CHECK-NEXT:    [[TMP107:%.*]] = fmul fast float [[TMP106]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP108:%.*]] = fptoui float [[TMP107]] to i32
; CHECK-NEXT:    [[TMP109:%.*]] = zext i32 [[TMP108]] to i64
; CHECK-NEXT:    [[TMP110:%.*]] = zext i32 [[TMP104]] to i64
; CHECK-NEXT:    [[TMP111:%.*]] = mul i64 [[TMP109]], [[TMP110]]
; CHECK-NEXT:    [[TMP112:%.*]] = trunc i64 [[TMP111]] to i32
; CHECK-NEXT:    [[TMP113:%.*]] = lshr i64 [[TMP111]], 32
; CHECK-NEXT:    [[TMP114:%.*]] = trunc i64 [[TMP113]] to i32
; CHECK-NEXT:    [[TMP115:%.*]] = sub i32 0, [[TMP112]]
; CHECK-NEXT:    [[TMP116:%.*]] = icmp eq i32 [[TMP114]], 0
; CHECK-NEXT:    [[TMP117:%.*]] = select i1 [[TMP116]], i32 [[TMP115]], i32 [[TMP112]]
; CHECK-NEXT:    [[TMP118:%.*]] = zext i32 [[TMP117]] to i64
; CHECK-NEXT:    [[TMP119:%.*]] = zext i32 [[TMP108]] to i64
; CHECK-NEXT:    [[TMP120:%.*]] = mul i64 [[TMP118]], [[TMP119]]
; CHECK-NEXT:    [[TMP121:%.*]] = trunc i64 [[TMP120]] to i32
; CHECK-NEXT:    [[TMP122:%.*]] = lshr i64 [[TMP120]], 32
; CHECK-NEXT:    [[TMP123:%.*]] = trunc i64 [[TMP122]] to i32
; CHECK-NEXT:    [[TMP124:%.*]] = add i32 [[TMP108]], [[TMP123]]
; CHECK-NEXT:    [[TMP125:%.*]] = sub i32 [[TMP108]], [[TMP123]]
; CHECK-NEXT:    [[TMP126:%.*]] = select i1 [[TMP116]], i32 [[TMP124]], i32 [[TMP125]]
; CHECK-NEXT:    [[TMP127:%.*]] = zext i32 [[TMP126]] to i64
; CHECK-NEXT:    [[TMP128:%.*]] = zext i32 [[TMP103]] to i64
; CHECK-NEXT:    [[TMP129:%.*]] = mul i64 [[TMP127]], [[TMP128]]
; CHECK-NEXT:    [[TMP130:%.*]] = trunc i64 [[TMP129]] to i32
; CHECK-NEXT:    [[TMP131:%.*]] = lshr i64 [[TMP129]], 32
; CHECK-NEXT:    [[TMP132:%.*]] = trunc i64 [[TMP131]] to i32
; CHECK-NEXT:    [[TMP133:%.*]] = mul i32 [[TMP132]], [[TMP104]]
; CHECK-NEXT:    [[TMP134:%.*]] = sub i32 [[TMP103]], [[TMP133]]
; CHECK-NEXT:    [[TMP135:%.*]] = icmp uge i32 [[TMP134]], [[TMP104]]
; CHECK-NEXT:    [[TMP136:%.*]] = icmp uge i32 [[TMP103]], [[TMP133]]
; CHECK-NEXT:    [[TMP137:%.*]] = and i1 [[TMP135]], [[TMP136]]
; CHECK-NEXT:    [[TMP138:%.*]] = sub i32 [[TMP134]], [[TMP104]]
; CHECK-NEXT:    [[TMP139:%.*]] = add i32 [[TMP134]], [[TMP104]]
; CHECK-NEXT:    [[TMP140:%.*]] = select i1 [[TMP137]], i32 [[TMP138]], i32 [[TMP134]]
; CHECK-NEXT:    [[TMP141:%.*]] = select i1 [[TMP136]], i32 [[TMP140]], i32 [[TMP139]]
; CHECK-NEXT:    [[TMP142:%.*]] = xor i32 [[TMP141]], [[TMP99]]
; CHECK-NEXT:    [[TMP143:%.*]] = sub i32 [[TMP142]], [[TMP99]]
; CHECK-NEXT:    [[TMP144:%.*]] = insertelement <4 x i32> [[TMP96]], i32 [[TMP143]], i64 2
; CHECK-NEXT:    [[TMP145:%.*]] = extractelement <4 x i32> [[X]], i64 3
; CHECK-NEXT:    [[TMP146:%.*]] = extractelement <4 x i32> [[Y]], i64 3
; CHECK-NEXT:    [[TMP147:%.*]] = ashr i32 [[TMP145]], 31
; CHECK-NEXT:    [[TMP148:%.*]] = ashr i32 [[TMP146]], 31
; CHECK-NEXT:    [[TMP149:%.*]] = add i32 [[TMP145]], [[TMP147]]
; CHECK-NEXT:    [[TMP150:%.*]] = add i32 [[TMP146]], [[TMP148]]
; CHECK-NEXT:    [[TMP151:%.*]] = xor i32 [[TMP149]], [[TMP147]]
; CHECK-NEXT:    [[TMP152:%.*]] = xor i32 [[TMP150]], [[TMP148]]
; CHECK-NEXT:    [[TMP153:%.*]] = uitofp i32 [[TMP152]] to float
; CHECK-NEXT:    [[TMP154:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP153]])
; CHECK-NEXT:    [[TMP155:%.*]] = fmul fast float [[TMP154]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP156:%.*]] = fptoui float [[TMP155]] to i32
; CHECK-NEXT:    [[TMP157:%.*]] = zext i32 [[TMP156]] to i64
; CHECK-NEXT:    [[TMP158:%.*]] = zext i32 [[TMP152]] to i64
; CHECK-NEXT:    [[TMP159:%.*]] = mul i64 [[TMP157]], [[TMP158]]
; CHECK-NEXT:    [[TMP160:%.*]] = trunc i64 [[TMP159]] to i32
; CHECK-NEXT:    [[TMP161:%.*]] = lshr i64 [[TMP159]], 32
; CHECK-NEXT:    [[TMP162:%.*]] = trunc i64 [[TMP161]] to i32
; CHECK-NEXT:    [[TMP163:%.*]] = sub i32 0, [[TMP160]]
; CHECK-NEXT:    [[TMP164:%.*]] = icmp eq i32 [[TMP162]], 0
; CHECK-NEXT:    [[TMP165:%.*]] = select i1 [[TMP164]], i32 [[TMP163]], i32 [[TMP160]]
; CHECK-NEXT:    [[TMP166:%.*]] = zext i32 [[TMP165]] to i64
; CHECK-NEXT:    [[TMP167:%.*]] = zext i32 [[TMP156]] to i64
; CHECK-NEXT:    [[TMP168:%.*]] = mul i64 [[TMP166]], [[TMP167]]
; CHECK-NEXT:    [[TMP169:%.*]] = trunc i64 [[TMP168]] to i32
; CHECK-NEXT:    [[TMP170:%.*]] = lshr i64 [[TMP168]], 32
; CHECK-NEXT:    [[TMP171:%.*]] = trunc i64 [[TMP170]] to i32
; CHECK-NEXT:    [[TMP172:%.*]] = add i32 [[TMP156]], [[TMP171]]
; CHECK-NEXT:    [[TMP173:%.*]] = sub i32 [[TMP156]], [[TMP171]]
; CHECK-NEXT:    [[TMP174:%.*]] = select i1 [[TMP164]], i32 [[TMP172]], i32 [[TMP173]]
; CHECK-NEXT:    [[TMP175:%.*]] = zext i32 [[TMP174]] to i64
; CHECK-NEXT:    [[TMP176:%.*]] = zext i32 [[TMP151]] to i64
; CHECK-NEXT:    [[TMP177:%.*]] = mul i64 [[TMP175]], [[TMP176]]
; CHECK-NEXT:    [[TMP178:%.*]] = trunc i64 [[TMP177]] to i32
; CHECK-NEXT:    [[TMP179:%.*]] = lshr i64 [[TMP177]], 32
; CHECK-NEXT:    [[TMP180:%.*]] = trunc i64 [[TMP179]] to i32
; CHECK-NEXT:    [[TMP181:%.*]] = mul i32 [[TMP180]], [[TMP152]]
; CHECK-NEXT:    [[TMP182:%.*]] = sub i32 [[TMP151]], [[TMP181]]
; CHECK-NEXT:    [[TMP183:%.*]] = icmp uge i32 [[TMP182]], [[TMP152]]
; CHECK-NEXT:    [[TMP184:%.*]] = icmp uge i32 [[TMP151]], [[TMP181]]
; CHECK-NEXT:    [[TMP185:%.*]] = and i1 [[TMP183]], [[TMP184]]
; CHECK-NEXT:    [[TMP186:%.*]] = sub i32 [[TMP182]], [[TMP152]]
; CHECK-NEXT:    [[TMP187:%.*]] = add i32 [[TMP182]], [[TMP152]]
; CHECK-NEXT:    [[TMP188:%.*]] = select i1 [[TMP185]], i32 [[TMP186]], i32 [[TMP182]]
; CHECK-NEXT:    [[TMP189:%.*]] = select i1 [[TMP184]], i32 [[TMP188]], i32 [[TMP187]]
; CHECK-NEXT:    [[TMP190:%.*]] = xor i32 [[TMP189]], [[TMP147]]
; CHECK-NEXT:    [[TMP191:%.*]] = sub i32 [[TMP190]], [[TMP147]]
; CHECK-NEXT:    [[TMP192:%.*]] = insertelement <4 x i32> [[TMP144]], i32 [[TMP191]], i64 3
; CHECK-NEXT:    store <4 x i32> [[TMP192]], <4 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v4i32:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx8 s[12:19], s[0:1], 0xd
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    s_mov_b32 s10, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s2, s16, 31
; GCN-NEXT:    s_add_i32 s3, s16, s2
; GCN-NEXT:    s_xor_b32 s5, s3, s2
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s5
; GCN-NEXT:    s_mov_b32 s16, 0x4f800000
; GCN-NEXT:    s_ashr_i32 s6, s12, 31
; GCN-NEXT:    s_ashr_i32 s2, s17, 31
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_add_i32 s0, s12, s6
; GCN-NEXT:    s_add_i32 s3, s17, s2
; GCN-NEXT:    s_xor_b32 s4, s0, s6
; GCN-NEXT:    v_mul_f32_e32 v0, s16, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    s_xor_b32 s17, s3, s2
; GCN-NEXT:    s_ashr_i32 s7, s13, 31
; GCN-NEXT:    s_add_i32 s12, s13, s7
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s5
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s5
; GCN-NEXT:    s_xor_b32 s12, s12, s7
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s17
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v3, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s4
; GCN-NEXT:    v_mul_f32_e32 v1, s16, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s5
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s17
; GCN-NEXT:    v_mul_hi_u32 v5, v1, s17
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s4, v0
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s4, v0
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s5, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s5, v2
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s5, v2
; GCN-NEXT:    v_sub_i32_e32 v6, vcc, 0, v4
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v5
; GCN-NEXT:    v_cndmask_b32_e64 v4, v4, v6, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v4, v4, v1
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v4, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v4, v1
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    s_ashr_i32 s0, s18, 31
; GCN-NEXT:    s_add_i32 s1, s18, s0
; GCN-NEXT:    s_xor_b32 s13, s1, s0
; GCN-NEXT:    v_cndmask_b32_e32 v0, v2, v0, vcc
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s13
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v5, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s12
; GCN-NEXT:    v_cndmask_b32_e64 v0, v3, v0, s[2:3]
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v2
; GCN-NEXT:    v_xor_b32_e32 v0, s6, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s17
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s6, v0
; GCN-NEXT:    v_mul_f32_e32 v2, s16, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v2
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s12, v1
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s12, v1
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s17, v3
; GCN-NEXT:    v_mul_lo_u32 v5, v2, s13
; GCN-NEXT:    v_mul_hi_u32 v6, v2, s13
; GCN-NEXT:    v_add_i32_e32 v4, vcc, s17, v3
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, s17, v3
; GCN-NEXT:    v_sub_i32_e32 v7, vcc, 0, v5
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v6
; GCN-NEXT:    v_cndmask_b32_e64 v5, v5, v7, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v5, v5, v2
; GCN-NEXT:    s_ashr_i32 s6, s14, 31
; GCN-NEXT:    s_add_i32 s12, s14, s6
; GCN-NEXT:    s_xor_b32 s12, s12, s6
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v5, v2
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    s_ashr_i32 s0, s19, 31
; GCN-NEXT:    s_add_i32 s1, s19, s0
; GCN-NEXT:    s_xor_b32 s14, s1, s0
; GCN-NEXT:    v_cndmask_b32_e32 v1, v3, v1, vcc
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s14
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v6, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, s12
; GCN-NEXT:    v_cndmask_b32_e64 v1, v4, v1, s[2:3]
; GCN-NEXT:    v_rcp_iflag_f32_e32 v3, v3
; GCN-NEXT:    v_xor_b32_e32 v1, s7, v1
; GCN-NEXT:    v_mul_lo_u32 v2, v2, s13
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, s7, v1
; GCN-NEXT:    v_mul_f32_e32 v3, s16, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v3
; GCN-NEXT:    s_ashr_i32 s7, s15, 31
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s12, v2
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s12, v2
; GCN-NEXT:    v_mul_lo_u32 v6, v3, s14
; GCN-NEXT:    v_mul_hi_u32 v7, v3, s14
; GCN-NEXT:    s_add_i32 s12, s15, s7
; GCN-NEXT:    s_xor_b32 s12, s12, s7
; GCN-NEXT:    v_sub_i32_e32 v8, vcc, 0, v6
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v7
; GCN-NEXT:    v_cndmask_b32_e64 v6, v6, v8, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v6, v6, v3
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s13, v4
; GCN-NEXT:    v_add_i32_e32 v5, vcc, s13, v4
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, s13, v4
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v6, v3
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, v3, v7, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v3, v3, s12
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v2, v4, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v5, v2, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v3, v3, s14
; GCN-NEXT:    v_xor_b32_e32 v2, s6, v2
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, s6, v2
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s12, v3
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s12, v3
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s14, v4
; GCN-NEXT:    v_add_i32_e32 v5, vcc, s14, v4
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s14, v4
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v3, v4, v3, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v3, v5, v3, s[2:3]
; GCN-NEXT:    v_xor_b32_e32 v3, s7, v3
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s7, v3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[8:11], 0
; GCN-NEXT:    s_endpgm
  %r = srem <4 x i32> %x, %y
  store <4 x i32> %r, <4 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v4i16(<4 x i16> addrspace(1)* %out, <4 x i16> %x, <4 x i16> %y) {
; CHECK-LABEL: @udiv_v4i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = zext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = zext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = uitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP6:%.*]] = uitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fmul fast float [[TMP5]], [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.trunc.f32(float [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = fneg fast float [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP10]], float [[TMP6]], float [[TMP5]])
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP9]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = call fast float @llvm.fabs.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP15:%.*]] = fcmp fast oge float [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = select i1 [[TMP15]], i32 1, i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = add i32 [[TMP12]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 65535
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i32 [[TMP18]] to i16
; CHECK-NEXT:    [[TMP20:%.*]] = insertelement <4 x i16> undef, i16 [[TMP19]], i64 0
; CHECK-NEXT:    [[TMP21:%.*]] = extractelement <4 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP22:%.*]] = extractelement <4 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP23:%.*]] = zext i16 [[TMP21]] to i32
; CHECK-NEXT:    [[TMP24:%.*]] = zext i16 [[TMP22]] to i32
; CHECK-NEXT:    [[TMP25:%.*]] = uitofp i32 [[TMP23]] to float
; CHECK-NEXT:    [[TMP26:%.*]] = uitofp i32 [[TMP24]] to float
; CHECK-NEXT:    [[TMP27:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP26]])
; CHECK-NEXT:    [[TMP28:%.*]] = fmul fast float [[TMP25]], [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = call fast float @llvm.trunc.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP30:%.*]] = fneg fast float [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP30]], float [[TMP26]], float [[TMP25]])
; CHECK-NEXT:    [[TMP32:%.*]] = fptoui float [[TMP29]] to i32
; CHECK-NEXT:    [[TMP33:%.*]] = call fast float @llvm.fabs.f32(float [[TMP31]])
; CHECK-NEXT:    [[TMP34:%.*]] = call fast float @llvm.fabs.f32(float [[TMP26]])
; CHECK-NEXT:    [[TMP35:%.*]] = fcmp fast oge float [[TMP33]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = select i1 [[TMP35]], i32 1, i32 0
; CHECK-NEXT:    [[TMP37:%.*]] = add i32 [[TMP32]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = and i32 [[TMP37]], 65535
; CHECK-NEXT:    [[TMP39:%.*]] = trunc i32 [[TMP38]] to i16
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <4 x i16> [[TMP20]], i16 [[TMP39]], i64 1
; CHECK-NEXT:    [[TMP41:%.*]] = extractelement <4 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <4 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP43:%.*]] = zext i16 [[TMP41]] to i32
; CHECK-NEXT:    [[TMP44:%.*]] = zext i16 [[TMP42]] to i32
; CHECK-NEXT:    [[TMP45:%.*]] = uitofp i32 [[TMP43]] to float
; CHECK-NEXT:    [[TMP46:%.*]] = uitofp i32 [[TMP44]] to float
; CHECK-NEXT:    [[TMP47:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP46]])
; CHECK-NEXT:    [[TMP48:%.*]] = fmul fast float [[TMP45]], [[TMP47]]
; CHECK-NEXT:    [[TMP49:%.*]] = call fast float @llvm.trunc.f32(float [[TMP48]])
; CHECK-NEXT:    [[TMP50:%.*]] = fneg fast float [[TMP49]]
; CHECK-NEXT:    [[TMP51:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP50]], float [[TMP46]], float [[TMP45]])
; CHECK-NEXT:    [[TMP52:%.*]] = fptoui float [[TMP49]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = call fast float @llvm.fabs.f32(float [[TMP51]])
; CHECK-NEXT:    [[TMP54:%.*]] = call fast float @llvm.fabs.f32(float [[TMP46]])
; CHECK-NEXT:    [[TMP55:%.*]] = fcmp fast oge float [[TMP53]], [[TMP54]]
; CHECK-NEXT:    [[TMP56:%.*]] = select i1 [[TMP55]], i32 1, i32 0
; CHECK-NEXT:    [[TMP57:%.*]] = add i32 [[TMP52]], [[TMP56]]
; CHECK-NEXT:    [[TMP58:%.*]] = and i32 [[TMP57]], 65535
; CHECK-NEXT:    [[TMP59:%.*]] = trunc i32 [[TMP58]] to i16
; CHECK-NEXT:    [[TMP60:%.*]] = insertelement <4 x i16> [[TMP40]], i16 [[TMP59]], i64 2
; CHECK-NEXT:    [[TMP61:%.*]] = extractelement <4 x i16> [[X]], i64 3
; CHECK-NEXT:    [[TMP62:%.*]] = extractelement <4 x i16> [[Y]], i64 3
; CHECK-NEXT:    [[TMP63:%.*]] = zext i16 [[TMP61]] to i32
; CHECK-NEXT:    [[TMP64:%.*]] = zext i16 [[TMP62]] to i32
; CHECK-NEXT:    [[TMP65:%.*]] = uitofp i32 [[TMP63]] to float
; CHECK-NEXT:    [[TMP66:%.*]] = uitofp i32 [[TMP64]] to float
; CHECK-NEXT:    [[TMP67:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP66]])
; CHECK-NEXT:    [[TMP68:%.*]] = fmul fast float [[TMP65]], [[TMP67]]
; CHECK-NEXT:    [[TMP69:%.*]] = call fast float @llvm.trunc.f32(float [[TMP68]])
; CHECK-NEXT:    [[TMP70:%.*]] = fneg fast float [[TMP69]]
; CHECK-NEXT:    [[TMP71:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP70]], float [[TMP66]], float [[TMP65]])
; CHECK-NEXT:    [[TMP72:%.*]] = fptoui float [[TMP69]] to i32
; CHECK-NEXT:    [[TMP73:%.*]] = call fast float @llvm.fabs.f32(float [[TMP71]])
; CHECK-NEXT:    [[TMP74:%.*]] = call fast float @llvm.fabs.f32(float [[TMP66]])
; CHECK-NEXT:    [[TMP75:%.*]] = fcmp fast oge float [[TMP73]], [[TMP74]]
; CHECK-NEXT:    [[TMP76:%.*]] = select i1 [[TMP75]], i32 1, i32 0
; CHECK-NEXT:    [[TMP77:%.*]] = add i32 [[TMP72]], [[TMP76]]
; CHECK-NEXT:    [[TMP78:%.*]] = and i32 [[TMP77]], 65535
; CHECK-NEXT:    [[TMP79:%.*]] = trunc i32 [[TMP78]] to i16
; CHECK-NEXT:    [[TMP80:%.*]] = insertelement <4 x i16> [[TMP60]], i16 [[TMP79]], i64 3
; CHECK-NEXT:    store <4 x i16> [[TMP80]], <4 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v4i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s8, 0xffff
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_and_b32 s9, s2, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s9
; GCN-NEXT:    s_lshr_b32 s9, s0, 16
; GCN-NEXT:    s_and_b32 s0, s0, s8
; GCN-NEXT:    s_lshr_b32 s2, s2, 16
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s2
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s9
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v3
; GCN-NEXT:    s_and_b32 s2, s3, s8
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_mul_f32_e32 v1, v4, v5
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v2, vcc
; GCN-NEXT:    v_mad_f32 v2, -v1, v3, v4
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s2
; GCN-NEXT:    s_lshr_b32 s0, s1, 16
; GCN-NEXT:    s_and_b32 s1, s1, s8
; GCN-NEXT:    s_lshr_b32 s10, s3, 16
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v2|, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s10
; GCN-NEXT:    v_cvt_f32_u32_e32 v5, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v6, v4
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, 0, v1, vcc
; GCN-NEXT:    v_rcp_iflag_f32_e32 v7, v3
; GCN-NEXT:    v_lshlrev_b32_e32 v2, 16, v2
; GCN-NEXT:    v_mul_f32_e32 v1, v5, v6
; GCN-NEXT:    v_cvt_f32_u32_e32 v6, s0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mad_f32 v5, -v1, v4, v5
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v5|, v4
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_f32_e32 v4, v6, v7
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_cvt_u32_f32_e32 v5, v4
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mad_f32 v4, -v4, v3, v6
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v4|, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_and_b32_e32 v0, s8, v0
; GCN-NEXT:    v_lshlrev_b32_e32 v3, 16, v3
; GCN-NEXT:    v_and_b32_e32 v1, s8, v1
; GCN-NEXT:    v_or_b32_e32 v1, v1, v3
; GCN-NEXT:    v_or_b32_e32 v0, v0, v2
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv <4 x i16> %x, %y
  store <4 x i16> %r, <4 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v4i16(<4 x i16> addrspace(1)* %out, <4 x i16> %x, <4 x i16> %y) {
; CHECK-LABEL: @urem_v4i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = zext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = zext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = uitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP6:%.*]] = uitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fmul fast float [[TMP5]], [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.trunc.f32(float [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = fneg fast float [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP10]], float [[TMP6]], float [[TMP5]])
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP9]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = call fast float @llvm.fabs.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP15:%.*]] = fcmp fast oge float [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = select i1 [[TMP15]], i32 1, i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = add i32 [[TMP12]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = mul i32 [[TMP17]], [[TMP4]]
; CHECK-NEXT:    [[TMP19:%.*]] = sub i32 [[TMP3]], [[TMP18]]
; CHECK-NEXT:    [[TMP20:%.*]] = and i32 [[TMP19]], 65535
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i32 [[TMP20]] to i16
; CHECK-NEXT:    [[TMP22:%.*]] = insertelement <4 x i16> undef, i16 [[TMP21]], i64 0
; CHECK-NEXT:    [[TMP23:%.*]] = extractelement <4 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP24:%.*]] = extractelement <4 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP25:%.*]] = zext i16 [[TMP23]] to i32
; CHECK-NEXT:    [[TMP26:%.*]] = zext i16 [[TMP24]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = uitofp i32 [[TMP25]] to float
; CHECK-NEXT:    [[TMP28:%.*]] = uitofp i32 [[TMP26]] to float
; CHECK-NEXT:    [[TMP29:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP30:%.*]] = fmul fast float [[TMP27]], [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = call fast float @llvm.trunc.f32(float [[TMP30]])
; CHECK-NEXT:    [[TMP32:%.*]] = fneg fast float [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP32]], float [[TMP28]], float [[TMP27]])
; CHECK-NEXT:    [[TMP34:%.*]] = fptoui float [[TMP31]] to i32
; CHECK-NEXT:    [[TMP35:%.*]] = call fast float @llvm.fabs.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.fabs.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP37:%.*]] = fcmp fast oge float [[TMP35]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = select i1 [[TMP37]], i32 1, i32 0
; CHECK-NEXT:    [[TMP39:%.*]] = add i32 [[TMP34]], [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = mul i32 [[TMP39]], [[TMP26]]
; CHECK-NEXT:    [[TMP41:%.*]] = sub i32 [[TMP25]], [[TMP40]]
; CHECK-NEXT:    [[TMP42:%.*]] = and i32 [[TMP41]], 65535
; CHECK-NEXT:    [[TMP43:%.*]] = trunc i32 [[TMP42]] to i16
; CHECK-NEXT:    [[TMP44:%.*]] = insertelement <4 x i16> [[TMP22]], i16 [[TMP43]], i64 1
; CHECK-NEXT:    [[TMP45:%.*]] = extractelement <4 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP46:%.*]] = extractelement <4 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP47:%.*]] = zext i16 [[TMP45]] to i32
; CHECK-NEXT:    [[TMP48:%.*]] = zext i16 [[TMP46]] to i32
; CHECK-NEXT:    [[TMP49:%.*]] = uitofp i32 [[TMP47]] to float
; CHECK-NEXT:    [[TMP50:%.*]] = uitofp i32 [[TMP48]] to float
; CHECK-NEXT:    [[TMP51:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP50]])
; CHECK-NEXT:    [[TMP52:%.*]] = fmul fast float [[TMP49]], [[TMP51]]
; CHECK-NEXT:    [[TMP53:%.*]] = call fast float @llvm.trunc.f32(float [[TMP52]])
; CHECK-NEXT:    [[TMP54:%.*]] = fneg fast float [[TMP53]]
; CHECK-NEXT:    [[TMP55:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP54]], float [[TMP50]], float [[TMP49]])
; CHECK-NEXT:    [[TMP56:%.*]] = fptoui float [[TMP53]] to i32
; CHECK-NEXT:    [[TMP57:%.*]] = call fast float @llvm.fabs.f32(float [[TMP55]])
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.fabs.f32(float [[TMP50]])
; CHECK-NEXT:    [[TMP59:%.*]] = fcmp fast oge float [[TMP57]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = select i1 [[TMP59]], i32 1, i32 0
; CHECK-NEXT:    [[TMP61:%.*]] = add i32 [[TMP56]], [[TMP60]]
; CHECK-NEXT:    [[TMP62:%.*]] = mul i32 [[TMP61]], [[TMP48]]
; CHECK-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP47]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = and i32 [[TMP63]], 65535
; CHECK-NEXT:    [[TMP65:%.*]] = trunc i32 [[TMP64]] to i16
; CHECK-NEXT:    [[TMP66:%.*]] = insertelement <4 x i16> [[TMP44]], i16 [[TMP65]], i64 2
; CHECK-NEXT:    [[TMP67:%.*]] = extractelement <4 x i16> [[X]], i64 3
; CHECK-NEXT:    [[TMP68:%.*]] = extractelement <4 x i16> [[Y]], i64 3
; CHECK-NEXT:    [[TMP69:%.*]] = zext i16 [[TMP67]] to i32
; CHECK-NEXT:    [[TMP70:%.*]] = zext i16 [[TMP68]] to i32
; CHECK-NEXT:    [[TMP71:%.*]] = uitofp i32 [[TMP69]] to float
; CHECK-NEXT:    [[TMP72:%.*]] = uitofp i32 [[TMP70]] to float
; CHECK-NEXT:    [[TMP73:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP72]])
; CHECK-NEXT:    [[TMP74:%.*]] = fmul fast float [[TMP71]], [[TMP73]]
; CHECK-NEXT:    [[TMP75:%.*]] = call fast float @llvm.trunc.f32(float [[TMP74]])
; CHECK-NEXT:    [[TMP76:%.*]] = fneg fast float [[TMP75]]
; CHECK-NEXT:    [[TMP77:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP76]], float [[TMP72]], float [[TMP71]])
; CHECK-NEXT:    [[TMP78:%.*]] = fptoui float [[TMP75]] to i32
; CHECK-NEXT:    [[TMP79:%.*]] = call fast float @llvm.fabs.f32(float [[TMP77]])
; CHECK-NEXT:    [[TMP80:%.*]] = call fast float @llvm.fabs.f32(float [[TMP72]])
; CHECK-NEXT:    [[TMP81:%.*]] = fcmp fast oge float [[TMP79]], [[TMP80]]
; CHECK-NEXT:    [[TMP82:%.*]] = select i1 [[TMP81]], i32 1, i32 0
; CHECK-NEXT:    [[TMP83:%.*]] = add i32 [[TMP78]], [[TMP82]]
; CHECK-NEXT:    [[TMP84:%.*]] = mul i32 [[TMP83]], [[TMP70]]
; CHECK-NEXT:    [[TMP85:%.*]] = sub i32 [[TMP69]], [[TMP84]]
; CHECK-NEXT:    [[TMP86:%.*]] = and i32 [[TMP85]], 65535
; CHECK-NEXT:    [[TMP87:%.*]] = trunc i32 [[TMP86]] to i16
; CHECK-NEXT:    [[TMP88:%.*]] = insertelement <4 x i16> [[TMP66]], i16 [[TMP87]], i64 3
; CHECK-NEXT:    store <4 x i16> [[TMP88]], <4 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v4i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s8, 0xffff
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_and_b32 s9, s2, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s9
; GCN-NEXT:    s_and_b32 s10, s0, s8
; GCN-NEXT:    s_lshr_b32 s11, s2, 16
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s10
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s11
; GCN-NEXT:    s_lshr_b32 s9, s0, 16
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s9
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v3
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_mul_f32_e32 v1, v4, v5
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v2, vcc
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v1
; GCN-NEXT:    v_mad_f32 v1, -v1, v3, v4
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v3
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s2
; GCN-NEXT:    s_and_b32 s2, s3, s8
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v2, vcc
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s2
; GCN-NEXT:    s_and_b32 s2, s1, s8
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s11
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s2
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v2
; GCN-NEXT:    s_lshr_b32 s12, s3, 16
; GCN-NEXT:    v_sub_i32_e32 v5, vcc, s9, v1
; GCN-NEXT:    s_lshr_b32 s10, s1, 16
; GCN-NEXT:    v_mul_f32_e32 v1, v3, v4
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s12
; GCN-NEXT:    v_cvt_f32_u32_e32 v6, s10
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v7, v4
; GCN-NEXT:    v_mad_f32 v3, -v1, v2, v3
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v3|, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_f32_e32 v2, v6, v7
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v2
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mad_f32 v2, -v2, v4, v6
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v2|, v4
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, 0, v3, vcc
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s3
; GCN-NEXT:    v_mul_lo_u32 v2, v2, s12
; GCN-NEXT:    v_and_b32_e32 v0, s8, v0
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s1, v1
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s10, v2
; GCN-NEXT:    v_lshlrev_b32_e32 v2, 16, v2
; GCN-NEXT:    v_and_b32_e32 v1, s8, v1
; GCN-NEXT:    v_or_b32_e32 v1, v1, v2
; GCN-NEXT:    v_lshlrev_b32_e32 v2, 16, v5
; GCN-NEXT:    v_or_b32_e32 v0, v0, v2
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem <4 x i16> %x, %y
  store <4 x i16> %r, <4 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v4i16(<4 x i16> addrspace(1)* %out, <4 x i16> %x, <4 x i16> %y) {
; CHECK-LABEL: @sdiv_v4i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = sext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = sext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = ashr i32 [[TMP5]], 30
; CHECK-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 1
; CHECK-NEXT:    [[TMP8:%.*]] = sitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP9:%.*]] = sitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP8]], [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.trunc.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP13:%.*]] = fneg fast float [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP13]], float [[TMP9]], float [[TMP8]])
; CHECK-NEXT:    [[TMP15:%.*]] = fptosi float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP16:%.*]] = call fast float @llvm.fabs.f32(float [[TMP14]])
; CHECK-NEXT:    [[TMP17:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP18:%.*]] = fcmp fast oge float [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = select i1 [[TMP18]], i32 [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP15]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = shl i32 [[TMP20]], 16
; CHECK-NEXT:    [[TMP22:%.*]] = ashr i32 [[TMP21]], 16
; CHECK-NEXT:    [[TMP23:%.*]] = trunc i32 [[TMP22]] to i16
; CHECK-NEXT:    [[TMP24:%.*]] = insertelement <4 x i16> undef, i16 [[TMP23]], i64 0
; CHECK-NEXT:    [[TMP25:%.*]] = extractelement <4 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP26:%.*]] = extractelement <4 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP27:%.*]] = sext i16 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP28:%.*]] = sext i16 [[TMP26]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = xor i32 [[TMP27]], [[TMP28]]
; CHECK-NEXT:    [[TMP30:%.*]] = ashr i32 [[TMP29]], 30
; CHECK-NEXT:    [[TMP31:%.*]] = or i32 [[TMP30]], 1
; CHECK-NEXT:    [[TMP32:%.*]] = sitofp i32 [[TMP27]] to float
; CHECK-NEXT:    [[TMP33:%.*]] = sitofp i32 [[TMP28]] to float
; CHECK-NEXT:    [[TMP34:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP35:%.*]] = fmul fast float [[TMP32]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.trunc.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP37:%.*]] = fneg fast float [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP37]], float [[TMP33]], float [[TMP32]])
; CHECK-NEXT:    [[TMP39:%.*]] = fptosi float [[TMP36]] to i32
; CHECK-NEXT:    [[TMP40:%.*]] = call fast float @llvm.fabs.f32(float [[TMP38]])
; CHECK-NEXT:    [[TMP41:%.*]] = call fast float @llvm.fabs.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP42:%.*]] = fcmp fast oge float [[TMP40]], [[TMP41]]
; CHECK-NEXT:    [[TMP43:%.*]] = select i1 [[TMP42]], i32 [[TMP31]], i32 0
; CHECK-NEXT:    [[TMP44:%.*]] = add i32 [[TMP39]], [[TMP43]]
; CHECK-NEXT:    [[TMP45:%.*]] = shl i32 [[TMP44]], 16
; CHECK-NEXT:    [[TMP46:%.*]] = ashr i32 [[TMP45]], 16
; CHECK-NEXT:    [[TMP47:%.*]] = trunc i32 [[TMP46]] to i16
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <4 x i16> [[TMP24]], i16 [[TMP47]], i64 1
; CHECK-NEXT:    [[TMP49:%.*]] = extractelement <4 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP50:%.*]] = extractelement <4 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP51:%.*]] = sext i16 [[TMP49]] to i32
; CHECK-NEXT:    [[TMP52:%.*]] = sext i16 [[TMP50]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = xor i32 [[TMP51]], [[TMP52]]
; CHECK-NEXT:    [[TMP54:%.*]] = ashr i32 [[TMP53]], 30
; CHECK-NEXT:    [[TMP55:%.*]] = or i32 [[TMP54]], 1
; CHECK-NEXT:    [[TMP56:%.*]] = sitofp i32 [[TMP51]] to float
; CHECK-NEXT:    [[TMP57:%.*]] = sitofp i32 [[TMP52]] to float
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP59:%.*]] = fmul fast float [[TMP56]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = call fast float @llvm.trunc.f32(float [[TMP59]])
; CHECK-NEXT:    [[TMP61:%.*]] = fneg fast float [[TMP60]]
; CHECK-NEXT:    [[TMP62:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP61]], float [[TMP57]], float [[TMP56]])
; CHECK-NEXT:    [[TMP63:%.*]] = fptosi float [[TMP60]] to i32
; CHECK-NEXT:    [[TMP64:%.*]] = call fast float @llvm.fabs.f32(float [[TMP62]])
; CHECK-NEXT:    [[TMP65:%.*]] = call fast float @llvm.fabs.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP66:%.*]] = fcmp fast oge float [[TMP64]], [[TMP65]]
; CHECK-NEXT:    [[TMP67:%.*]] = select i1 [[TMP66]], i32 [[TMP55]], i32 0
; CHECK-NEXT:    [[TMP68:%.*]] = add i32 [[TMP63]], [[TMP67]]
; CHECK-NEXT:    [[TMP69:%.*]] = shl i32 [[TMP68]], 16
; CHECK-NEXT:    [[TMP70:%.*]] = ashr i32 [[TMP69]], 16
; CHECK-NEXT:    [[TMP71:%.*]] = trunc i32 [[TMP70]] to i16
; CHECK-NEXT:    [[TMP72:%.*]] = insertelement <4 x i16> [[TMP48]], i16 [[TMP71]], i64 2
; CHECK-NEXT:    [[TMP73:%.*]] = extractelement <4 x i16> [[X]], i64 3
; CHECK-NEXT:    [[TMP74:%.*]] = extractelement <4 x i16> [[Y]], i64 3
; CHECK-NEXT:    [[TMP75:%.*]] = sext i16 [[TMP73]] to i32
; CHECK-NEXT:    [[TMP76:%.*]] = sext i16 [[TMP74]] to i32
; CHECK-NEXT:    [[TMP77:%.*]] = xor i32 [[TMP75]], [[TMP76]]
; CHECK-NEXT:    [[TMP78:%.*]] = ashr i32 [[TMP77]], 30
; CHECK-NEXT:    [[TMP79:%.*]] = or i32 [[TMP78]], 1
; CHECK-NEXT:    [[TMP80:%.*]] = sitofp i32 [[TMP75]] to float
; CHECK-NEXT:    [[TMP81:%.*]] = sitofp i32 [[TMP76]] to float
; CHECK-NEXT:    [[TMP82:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP81]])
; CHECK-NEXT:    [[TMP83:%.*]] = fmul fast float [[TMP80]], [[TMP82]]
; CHECK-NEXT:    [[TMP84:%.*]] = call fast float @llvm.trunc.f32(float [[TMP83]])
; CHECK-NEXT:    [[TMP85:%.*]] = fneg fast float [[TMP84]]
; CHECK-NEXT:    [[TMP86:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP85]], float [[TMP81]], float [[TMP80]])
; CHECK-NEXT:    [[TMP87:%.*]] = fptosi float [[TMP84]] to i32
; CHECK-NEXT:    [[TMP88:%.*]] = call fast float @llvm.fabs.f32(float [[TMP86]])
; CHECK-NEXT:    [[TMP89:%.*]] = call fast float @llvm.fabs.f32(float [[TMP81]])
; CHECK-NEXT:    [[TMP90:%.*]] = fcmp fast oge float [[TMP88]], [[TMP89]]
; CHECK-NEXT:    [[TMP91:%.*]] = select i1 [[TMP90]], i32 [[TMP79]], i32 0
; CHECK-NEXT:    [[TMP92:%.*]] = add i32 [[TMP87]], [[TMP91]]
; CHECK-NEXT:    [[TMP93:%.*]] = shl i32 [[TMP92]], 16
; CHECK-NEXT:    [[TMP94:%.*]] = ashr i32 [[TMP93]], 16
; CHECK-NEXT:    [[TMP95:%.*]] = trunc i32 [[TMP94]] to i16
; CHECK-NEXT:    [[TMP96:%.*]] = insertelement <4 x i16> [[TMP72]], i16 [[TMP95]], i64 3
; CHECK-NEXT:    store <4 x i16> [[TMP96]], <4 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v4i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_sext_i32_i16 s8, s2
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s8
; GCN-NEXT:    s_sext_i32_i16 s9, s0
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s9
; GCN-NEXT:    s_xor_b32 s8, s9, s8
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s8, s8, 30
; GCN-NEXT:    s_or_b32 s10, s8, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s8, s10, 0
; GCN-NEXT:    s_ashr_i32 s2, s2, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s2
; GCN-NEXT:    s_ashr_i32 s0, s0, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s0
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_rcp_iflag_f32_e32 v3, v0
; GCN-NEXT:    s_xor_b32 s0, s0, s2
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_sext_i32_i16 s2, s3
; GCN-NEXT:    v_mul_f32_e32 v3, v1, v3
; GCN-NEXT:    v_trunc_f32_e32 v3, v3
; GCN-NEXT:    v_mad_f32 v1, -v3, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v3, v3
; GCN-NEXT:    v_add_i32_e32 v2, vcc, s8, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v1|, |v0|
; GCN-NEXT:    s_or_b32 s0, s0, 1
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s2
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s0, s0, 0
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s0, v3
; GCN-NEXT:    s_sext_i32_i16 s0, s1
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v0
; GCN-NEXT:    s_xor_b32 s0, s0, s2
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s0, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v4, v1, v4
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_mad_f32 v1, -v4, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s0, s0, 0
; GCN-NEXT:    v_cvt_i32_f32_e32 v4, v4
; GCN-NEXT:    s_ashr_i32 s2, s3, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s2
; GCN-NEXT:    v_add_i32_e32 v1, vcc, s0, v4
; GCN-NEXT:    s_ashr_i32 s0, s1, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v4, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v0
; GCN-NEXT:    s_xor_b32 s0, s0, s2
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s2, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v5, v4, v5
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_mad_f32 v4, -v5, v0, v4
; GCN-NEXT:    v_cvt_i32_f32_e32 v5, v5
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v4|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s2, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v5
; GCN-NEXT:    s_mov_b32 s0, 0xffff
; GCN-NEXT:    v_lshlrev_b32_e32 v0, 16, v0
; GCN-NEXT:    v_and_b32_e32 v1, s0, v1
; GCN-NEXT:    v_or_b32_e32 v1, v1, v0
; GCN-NEXT:    v_lshlrev_b32_e32 v0, 16, v3
; GCN-NEXT:    v_and_b32_e32 v2, s0, v2
; GCN-NEXT:    v_or_b32_e32 v0, v2, v0
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv <4 x i16> %x, %y
  store <4 x i16> %r, <4 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v4i16(<4 x i16> addrspace(1)* %out, <4 x i16> %x, <4 x i16> %y) {
; CHECK-LABEL: @srem_v4i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <4 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <4 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = sext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = sext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = ashr i32 [[TMP5]], 30
; CHECK-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 1
; CHECK-NEXT:    [[TMP8:%.*]] = sitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP9:%.*]] = sitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP8]], [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.trunc.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP13:%.*]] = fneg fast float [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP13]], float [[TMP9]], float [[TMP8]])
; CHECK-NEXT:    [[TMP15:%.*]] = fptosi float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP16:%.*]] = call fast float @llvm.fabs.f32(float [[TMP14]])
; CHECK-NEXT:    [[TMP17:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP18:%.*]] = fcmp fast oge float [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = select i1 [[TMP18]], i32 [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP15]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = mul i32 [[TMP20]], [[TMP4]]
; CHECK-NEXT:    [[TMP22:%.*]] = sub i32 [[TMP3]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = shl i32 [[TMP22]], 16
; CHECK-NEXT:    [[TMP24:%.*]] = ashr i32 [[TMP23]], 16
; CHECK-NEXT:    [[TMP25:%.*]] = trunc i32 [[TMP24]] to i16
; CHECK-NEXT:    [[TMP26:%.*]] = insertelement <4 x i16> undef, i16 [[TMP25]], i64 0
; CHECK-NEXT:    [[TMP27:%.*]] = extractelement <4 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP28:%.*]] = extractelement <4 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP29:%.*]] = sext i16 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP30:%.*]] = sext i16 [[TMP28]] to i32
; CHECK-NEXT:    [[TMP31:%.*]] = xor i32 [[TMP29]], [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = ashr i32 [[TMP31]], 30
; CHECK-NEXT:    [[TMP33:%.*]] = or i32 [[TMP32]], 1
; CHECK-NEXT:    [[TMP34:%.*]] = sitofp i32 [[TMP29]] to float
; CHECK-NEXT:    [[TMP35:%.*]] = sitofp i32 [[TMP30]] to float
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP37:%.*]] = fmul fast float [[TMP34]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = call fast float @llvm.trunc.f32(float [[TMP37]])
; CHECK-NEXT:    [[TMP39:%.*]] = fneg fast float [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP39]], float [[TMP35]], float [[TMP34]])
; CHECK-NEXT:    [[TMP41:%.*]] = fptosi float [[TMP38]] to i32
; CHECK-NEXT:    [[TMP42:%.*]] = call fast float @llvm.fabs.f32(float [[TMP40]])
; CHECK-NEXT:    [[TMP43:%.*]] = call fast float @llvm.fabs.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP44:%.*]] = fcmp fast oge float [[TMP42]], [[TMP43]]
; CHECK-NEXT:    [[TMP45:%.*]] = select i1 [[TMP44]], i32 [[TMP33]], i32 0
; CHECK-NEXT:    [[TMP46:%.*]] = add i32 [[TMP41]], [[TMP45]]
; CHECK-NEXT:    [[TMP47:%.*]] = mul i32 [[TMP46]], [[TMP30]]
; CHECK-NEXT:    [[TMP48:%.*]] = sub i32 [[TMP29]], [[TMP47]]
; CHECK-NEXT:    [[TMP49:%.*]] = shl i32 [[TMP48]], 16
; CHECK-NEXT:    [[TMP50:%.*]] = ashr i32 [[TMP49]], 16
; CHECK-NEXT:    [[TMP51:%.*]] = trunc i32 [[TMP50]] to i16
; CHECK-NEXT:    [[TMP52:%.*]] = insertelement <4 x i16> [[TMP26]], i16 [[TMP51]], i64 1
; CHECK-NEXT:    [[TMP53:%.*]] = extractelement <4 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <4 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP55:%.*]] = sext i16 [[TMP53]] to i32
; CHECK-NEXT:    [[TMP56:%.*]] = sext i16 [[TMP54]] to i32
; CHECK-NEXT:    [[TMP57:%.*]] = xor i32 [[TMP55]], [[TMP56]]
; CHECK-NEXT:    [[TMP58:%.*]] = ashr i32 [[TMP57]], 30
; CHECK-NEXT:    [[TMP59:%.*]] = or i32 [[TMP58]], 1
; CHECK-NEXT:    [[TMP60:%.*]] = sitofp i32 [[TMP55]] to float
; CHECK-NEXT:    [[TMP61:%.*]] = sitofp i32 [[TMP56]] to float
; CHECK-NEXT:    [[TMP62:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP61]])
; CHECK-NEXT:    [[TMP63:%.*]] = fmul fast float [[TMP60]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = call fast float @llvm.trunc.f32(float [[TMP63]])
; CHECK-NEXT:    [[TMP65:%.*]] = fneg fast float [[TMP64]]
; CHECK-NEXT:    [[TMP66:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP65]], float [[TMP61]], float [[TMP60]])
; CHECK-NEXT:    [[TMP67:%.*]] = fptosi float [[TMP64]] to i32
; CHECK-NEXT:    [[TMP68:%.*]] = call fast float @llvm.fabs.f32(float [[TMP66]])
; CHECK-NEXT:    [[TMP69:%.*]] = call fast float @llvm.fabs.f32(float [[TMP61]])
; CHECK-NEXT:    [[TMP70:%.*]] = fcmp fast oge float [[TMP68]], [[TMP69]]
; CHECK-NEXT:    [[TMP71:%.*]] = select i1 [[TMP70]], i32 [[TMP59]], i32 0
; CHECK-NEXT:    [[TMP72:%.*]] = add i32 [[TMP67]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = mul i32 [[TMP72]], [[TMP56]]
; CHECK-NEXT:    [[TMP74:%.*]] = sub i32 [[TMP55]], [[TMP73]]
; CHECK-NEXT:    [[TMP75:%.*]] = shl i32 [[TMP74]], 16
; CHECK-NEXT:    [[TMP76:%.*]] = ashr i32 [[TMP75]], 16
; CHECK-NEXT:    [[TMP77:%.*]] = trunc i32 [[TMP76]] to i16
; CHECK-NEXT:    [[TMP78:%.*]] = insertelement <4 x i16> [[TMP52]], i16 [[TMP77]], i64 2
; CHECK-NEXT:    [[TMP79:%.*]] = extractelement <4 x i16> [[X]], i64 3
; CHECK-NEXT:    [[TMP80:%.*]] = extractelement <4 x i16> [[Y]], i64 3
; CHECK-NEXT:    [[TMP81:%.*]] = sext i16 [[TMP79]] to i32
; CHECK-NEXT:    [[TMP82:%.*]] = sext i16 [[TMP80]] to i32
; CHECK-NEXT:    [[TMP83:%.*]] = xor i32 [[TMP81]], [[TMP82]]
; CHECK-NEXT:    [[TMP84:%.*]] = ashr i32 [[TMP83]], 30
; CHECK-NEXT:    [[TMP85:%.*]] = or i32 [[TMP84]], 1
; CHECK-NEXT:    [[TMP86:%.*]] = sitofp i32 [[TMP81]] to float
; CHECK-NEXT:    [[TMP87:%.*]] = sitofp i32 [[TMP82]] to float
; CHECK-NEXT:    [[TMP88:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP87]])
; CHECK-NEXT:    [[TMP89:%.*]] = fmul fast float [[TMP86]], [[TMP88]]
; CHECK-NEXT:    [[TMP90:%.*]] = call fast float @llvm.trunc.f32(float [[TMP89]])
; CHECK-NEXT:    [[TMP91:%.*]] = fneg fast float [[TMP90]]
; CHECK-NEXT:    [[TMP92:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP91]], float [[TMP87]], float [[TMP86]])
; CHECK-NEXT:    [[TMP93:%.*]] = fptosi float [[TMP90]] to i32
; CHECK-NEXT:    [[TMP94:%.*]] = call fast float @llvm.fabs.f32(float [[TMP92]])
; CHECK-NEXT:    [[TMP95:%.*]] = call fast float @llvm.fabs.f32(float [[TMP87]])
; CHECK-NEXT:    [[TMP96:%.*]] = fcmp fast oge float [[TMP94]], [[TMP95]]
; CHECK-NEXT:    [[TMP97:%.*]] = select i1 [[TMP96]], i32 [[TMP85]], i32 0
; CHECK-NEXT:    [[TMP98:%.*]] = add i32 [[TMP93]], [[TMP97]]
; CHECK-NEXT:    [[TMP99:%.*]] = mul i32 [[TMP98]], [[TMP82]]
; CHECK-NEXT:    [[TMP100:%.*]] = sub i32 [[TMP81]], [[TMP99]]
; CHECK-NEXT:    [[TMP101:%.*]] = shl i32 [[TMP100]], 16
; CHECK-NEXT:    [[TMP102:%.*]] = ashr i32 [[TMP101]], 16
; CHECK-NEXT:    [[TMP103:%.*]] = trunc i32 [[TMP102]] to i16
; CHECK-NEXT:    [[TMP104:%.*]] = insertelement <4 x i16> [[TMP78]], i16 [[TMP103]], i64 3
; CHECK-NEXT:    store <4 x i16> [[TMP104]], <4 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v4i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_sext_i32_i16 s8, s2
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s8
; GCN-NEXT:    s_sext_i32_i16 s9, s0
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s9
; GCN-NEXT:    s_xor_b32 s8, s9, s8
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s8, s8, 30
; GCN-NEXT:    s_or_b32 s10, s8, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s8, s10, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s8, v2
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s2
; GCN-NEXT:    s_ashr_i32 s2, s2, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s2
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v3, v1
; GCN-NEXT:    s_xor_b32 s8, s0, s2
; GCN-NEXT:    s_ashr_i32 s8, s8, 30
; GCN-NEXT:    s_or_b32 s10, s8, 1
; GCN-NEXT:    v_mul_f32_e32 v3, v2, v3
; GCN-NEXT:    v_trunc_f32_e32 v3, v3
; GCN-NEXT:    v_mad_f32 v2, -v3, v1, v2
; GCN-NEXT:    v_cvt_i32_f32_e32 v3, v3
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v2|, |v1|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s8, s10, 0
; GCN-NEXT:    v_add_i32_e32 v1, vcc, s8, v3
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s2
; GCN-NEXT:    s_sext_i32_i16 s2, s3
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, s2
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s0, v1
; GCN-NEXT:    s_sext_i32_i16 s0, s1
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v2
; GCN-NEXT:    s_xor_b32 s0, s0, s2
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s0, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v4, v1, v4
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_mad_f32 v1, -v4, v2, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v4, v4
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v1|, |v2|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s0, s0, 0
; GCN-NEXT:    v_add_i32_e32 v1, vcc, s0, v4
; GCN-NEXT:    s_ashr_i32 s0, s3, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, s0
; GCN-NEXT:    s_ashr_i32 s8, s1, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v4, s8
; GCN-NEXT:    s_xor_b32 s2, s8, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v2
; GCN-NEXT:    s_ashr_i32 s2, s2, 30
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s3
; GCN-NEXT:    s_or_b32 s9, s2, 1
; GCN-NEXT:    v_mul_f32_e32 v5, v4, v5
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_mad_f32 v4, -v5, v2, v4
; GCN-NEXT:    v_cvt_i32_f32_e32 v5, v5
; GCN-NEXT:    v_cmp_ge_f32_e64 s[2:3], |v4|, |v2|
; GCN-NEXT:    s_cmp_lg_u64 s[2:3], 0
; GCN-NEXT:    s_cselect_b32 s2, s9, 0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, s2, v5
; GCN-NEXT:    v_mul_lo_u32 v2, v2, s0
; GCN-NEXT:    s_mov_b32 s0, 0xffff
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s1, v1
; GCN-NEXT:    v_and_b32_e32 v1, s0, v1
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s8, v2
; GCN-NEXT:    v_lshlrev_b32_e32 v2, 16, v2
; GCN-NEXT:    v_or_b32_e32 v1, v1, v2
; GCN-NEXT:    v_lshlrev_b32_e32 v2, 16, v3
; GCN-NEXT:    v_and_b32_e32 v0, s0, v0
; GCN-NEXT:    v_or_b32_e32 v0, v0, v2
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem <4 x i16> %x, %y
  store <4 x i16> %r, <4 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i3(i3 addrspace(1)* %out, i3 %x, i3 %y) {
; CHECK-LABEL: @udiv_i3(
; CHECK-NEXT:    [[TMP1:%.*]] = zext i3 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = zext i3 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP5:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP6:%.*]] = fmul fast float [[TMP3]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.trunc.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fneg fast float [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP8]], float [[TMP4]], float [[TMP3]])
; CHECK-NEXT:    [[TMP10:%.*]] = fptoui float [[TMP7]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.fabs.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP13:%.*]] = fcmp fast oge float [[TMP11]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = select i1 [[TMP13]], i32 1, i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = add i32 [[TMP10]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = and i32 [[TMP15]], 7
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i32 [[TMP16]] to i3
; CHECK-NEXT:    store i3 [[TMP17]], i3 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i3:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_bfe_u32 s1, s0, 0x30008
; GCN-NEXT:    v_cvt_f32_ubyte0_e32 v0, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v0
; GCN-NEXT:    s_and_b32 s0, s0, 7
; GCN-NEXT:    v_cvt_f32_ubyte0_e32 v2, s0
; GCN-NEXT:    v_mul_f32_e32 v1, v2, v1
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v1
; GCN-NEXT:    v_mad_f32 v1, -v1, v0, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v3, vcc
; GCN-NEXT:    v_and_b32_e32 v0, 7, v0
; GCN-NEXT:    buffer_store_byte v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i3 %x, %y
  store i3 %r, i3 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i3(i3 addrspace(1)* %out, i3 %x, i3 %y) {
; CHECK-LABEL: @urem_i3(
; CHECK-NEXT:    [[TMP1:%.*]] = zext i3 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = zext i3 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP5:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP6:%.*]] = fmul fast float [[TMP3]], [[TMP5]]
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.trunc.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fneg fast float [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP8]], float [[TMP4]], float [[TMP3]])
; CHECK-NEXT:    [[TMP10:%.*]] = fptoui float [[TMP7]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.fabs.f32(float [[TMP4]])
; CHECK-NEXT:    [[TMP13:%.*]] = fcmp fast oge float [[TMP11]], [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = select i1 [[TMP13]], i32 1, i32 0
; CHECK-NEXT:    [[TMP15:%.*]] = add i32 [[TMP10]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = mul i32 [[TMP15]], [[TMP2]]
; CHECK-NEXT:    [[TMP17:%.*]] = sub i32 [[TMP1]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 7
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i32 [[TMP18]] to i3
; CHECK-NEXT:    store i3 [[TMP19]], i3 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i3:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_bfe_u32 s1, s0, 0x30008
; GCN-NEXT:    v_cvt_f32_ubyte0_e32 v0, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v0
; GCN-NEXT:    s_and_b32 s2, s0, 7
; GCN-NEXT:    v_cvt_f32_ubyte0_e32 v2, s2
; GCN-NEXT:    s_lshr_b32 s1, s0, 8
; GCN-NEXT:    v_mul_f32_e32 v1, v2, v1
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v1
; GCN-NEXT:    v_mad_f32 v1, -v1, v0, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v3, vcc
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    v_and_b32_e32 v0, 7, v0
; GCN-NEXT:    buffer_store_byte v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem i3 %x, %y
  store i3 %r, i3 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i3(i3 addrspace(1)* %out, i3 %x, i3 %y) {
; CHECK-LABEL: @sdiv_i3(
; CHECK-NEXT:    [[TMP1:%.*]] = sext i3 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = sext i3 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP3]], 30
; CHECK-NEXT:    [[TMP5:%.*]] = or i32 [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = sitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = sitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP8:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = fmul fast float [[TMP6]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.trunc.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fneg fast float [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP11]], float [[TMP7]], float [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = fptosi float [[TMP10]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP12]])
; CHECK-NEXT:    [[TMP15:%.*]] = call fast float @llvm.fabs.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP16:%.*]] = fcmp fast oge float [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], i32 [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP18:%.*]] = add i32 [[TMP13]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = shl i32 [[TMP18]], 29
; CHECK-NEXT:    [[TMP20:%.*]] = ashr i32 [[TMP19]], 29
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i32 [[TMP20]] to i3
; CHECK-NEXT:    store i3 [[TMP21]], i3 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i3:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_bfe_i32 s1, s0, 0x30008
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s1
; GCN-NEXT:    s_bfe_i32 s0, s0, 0x30000
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s0
; GCN-NEXT:    s_xor_b32 s0, s0, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s2, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s2, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v2
; GCN-NEXT:    v_and_b32_e32 v0, 7, v0
; GCN-NEXT:    buffer_store_byte v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i3 %x, %y
  store i3 %r, i3 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i3(i3 addrspace(1)* %out, i3 %x, i3 %y) {
; CHECK-LABEL: @srem_i3(
; CHECK-NEXT:    [[TMP1:%.*]] = sext i3 [[X:%.*]] to i32
; CHECK-NEXT:    [[TMP2:%.*]] = sext i3 [[Y:%.*]] to i32
; CHECK-NEXT:    [[TMP3:%.*]] = xor i32 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP3]], 30
; CHECK-NEXT:    [[TMP5:%.*]] = or i32 [[TMP4]], 1
; CHECK-NEXT:    [[TMP6:%.*]] = sitofp i32 [[TMP1]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = sitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP8:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP9:%.*]] = fmul fast float [[TMP6]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.trunc.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fneg fast float [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP11]], float [[TMP7]], float [[TMP6]])
; CHECK-NEXT:    [[TMP13:%.*]] = fptosi float [[TMP10]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP12]])
; CHECK-NEXT:    [[TMP15:%.*]] = call fast float @llvm.fabs.f32(float [[TMP7]])
; CHECK-NEXT:    [[TMP16:%.*]] = fcmp fast oge float [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = select i1 [[TMP16]], i32 [[TMP5]], i32 0
; CHECK-NEXT:    [[TMP18:%.*]] = add i32 [[TMP13]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = mul i32 [[TMP18]], [[TMP2]]
; CHECK-NEXT:    [[TMP20:%.*]] = sub i32 [[TMP1]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = shl i32 [[TMP20]], 29
; CHECK-NEXT:    [[TMP22:%.*]] = ashr i32 [[TMP21]], 29
; CHECK-NEXT:    [[TMP23:%.*]] = trunc i32 [[TMP22]] to i3
; CHECK-NEXT:    store i3 [[TMP23]], i3 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i3:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s2, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_bfe_i32 s0, s2, 0x30008
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s0
; GCN-NEXT:    s_bfe_i32 s1, s2, 0x30000
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s1
; GCN-NEXT:    s_xor_b32 s0, s1, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_lshr_b32 s3, s2, 8
; GCN-NEXT:    s_or_b32 s6, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s6, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v2
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s3
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s2, v0
; GCN-NEXT:    v_and_b32_e32 v0, 7, v0
; GCN-NEXT:    buffer_store_byte v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem i3 %x, %y
  store i3 %r, i3 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v3i16(<3 x i16> addrspace(1)* %out, <3 x i16> %x, <3 x i16> %y) {
; CHECK-LABEL: @udiv_v3i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = zext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = zext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = uitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP6:%.*]] = uitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fmul fast float [[TMP5]], [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.trunc.f32(float [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = fneg fast float [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP10]], float [[TMP6]], float [[TMP5]])
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP9]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = call fast float @llvm.fabs.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP15:%.*]] = fcmp fast oge float [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = select i1 [[TMP15]], i32 1, i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = add i32 [[TMP12]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 65535
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i32 [[TMP18]] to i16
; CHECK-NEXT:    [[TMP20:%.*]] = insertelement <3 x i16> undef, i16 [[TMP19]], i64 0
; CHECK-NEXT:    [[TMP21:%.*]] = extractelement <3 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP22:%.*]] = extractelement <3 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP23:%.*]] = zext i16 [[TMP21]] to i32
; CHECK-NEXT:    [[TMP24:%.*]] = zext i16 [[TMP22]] to i32
; CHECK-NEXT:    [[TMP25:%.*]] = uitofp i32 [[TMP23]] to float
; CHECK-NEXT:    [[TMP26:%.*]] = uitofp i32 [[TMP24]] to float
; CHECK-NEXT:    [[TMP27:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP26]])
; CHECK-NEXT:    [[TMP28:%.*]] = fmul fast float [[TMP25]], [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = call fast float @llvm.trunc.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP30:%.*]] = fneg fast float [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP30]], float [[TMP26]], float [[TMP25]])
; CHECK-NEXT:    [[TMP32:%.*]] = fptoui float [[TMP29]] to i32
; CHECK-NEXT:    [[TMP33:%.*]] = call fast float @llvm.fabs.f32(float [[TMP31]])
; CHECK-NEXT:    [[TMP34:%.*]] = call fast float @llvm.fabs.f32(float [[TMP26]])
; CHECK-NEXT:    [[TMP35:%.*]] = fcmp fast oge float [[TMP33]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = select i1 [[TMP35]], i32 1, i32 0
; CHECK-NEXT:    [[TMP37:%.*]] = add i32 [[TMP32]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = and i32 [[TMP37]], 65535
; CHECK-NEXT:    [[TMP39:%.*]] = trunc i32 [[TMP38]] to i16
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <3 x i16> [[TMP20]], i16 [[TMP39]], i64 1
; CHECK-NEXT:    [[TMP41:%.*]] = extractelement <3 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <3 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP43:%.*]] = zext i16 [[TMP41]] to i32
; CHECK-NEXT:    [[TMP44:%.*]] = zext i16 [[TMP42]] to i32
; CHECK-NEXT:    [[TMP45:%.*]] = uitofp i32 [[TMP43]] to float
; CHECK-NEXT:    [[TMP46:%.*]] = uitofp i32 [[TMP44]] to float
; CHECK-NEXT:    [[TMP47:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP46]])
; CHECK-NEXT:    [[TMP48:%.*]] = fmul fast float [[TMP45]], [[TMP47]]
; CHECK-NEXT:    [[TMP49:%.*]] = call fast float @llvm.trunc.f32(float [[TMP48]])
; CHECK-NEXT:    [[TMP50:%.*]] = fneg fast float [[TMP49]]
; CHECK-NEXT:    [[TMP51:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP50]], float [[TMP46]], float [[TMP45]])
; CHECK-NEXT:    [[TMP52:%.*]] = fptoui float [[TMP49]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = call fast float @llvm.fabs.f32(float [[TMP51]])
; CHECK-NEXT:    [[TMP54:%.*]] = call fast float @llvm.fabs.f32(float [[TMP46]])
; CHECK-NEXT:    [[TMP55:%.*]] = fcmp fast oge float [[TMP53]], [[TMP54]]
; CHECK-NEXT:    [[TMP56:%.*]] = select i1 [[TMP55]], i32 1, i32 0
; CHECK-NEXT:    [[TMP57:%.*]] = add i32 [[TMP52]], [[TMP56]]
; CHECK-NEXT:    [[TMP58:%.*]] = and i32 [[TMP57]], 65535
; CHECK-NEXT:    [[TMP59:%.*]] = trunc i32 [[TMP58]] to i16
; CHECK-NEXT:    [[TMP60:%.*]] = insertelement <3 x i16> [[TMP40]], i16 [[TMP59]], i64 2
; CHECK-NEXT:    store <3 x i16> [[TMP60]], <3 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v3i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s8, 0xffff
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_and_b32 s6, s0, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s6
; GCN-NEXT:    s_and_b32 s6, s2, s8
; GCN-NEXT:    s_lshr_b32 s0, s0, 16
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s0
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s6
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_lshr_b32 s0, s2, 16
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v3
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v1|, v0
; GCN-NEXT:    v_mul_f32_e32 v1, v4, v5
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    s_and_b32 s0, s1, s8
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v2, vcc
; GCN-NEXT:    v_mad_f32 v2, -v1, v3, v4
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, s0
; GCN-NEXT:    s_and_b32 s0, s3, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v5, s0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v6, v4
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v2|, v3
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_f32_e32 v2, v5, v6
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v2
; GCN-NEXT:    v_mad_f32 v2, -v2, v4, v5
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v2|, v4
; GCN-NEXT:    v_lshlrev_b32_e32 v1, 16, v1
; GCN-NEXT:    v_and_b32_e32 v0, s8, v0
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, 0, v3, vcc
; GCN-NEXT:    v_or_b32_e32 v0, v0, v1
; GCN-NEXT:    buffer_store_short v2, off, s[4:7], 0 offset:4
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv <3 x i16> %x, %y
  store <3 x i16> %r, <3 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v3i16(<3 x i16> addrspace(1)* %out, <3 x i16> %x, <3 x i16> %y) {
; CHECK-LABEL: @urem_v3i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = zext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = zext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = uitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP6:%.*]] = uitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fmul fast float [[TMP5]], [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.trunc.f32(float [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = fneg fast float [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP10]], float [[TMP6]], float [[TMP5]])
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP9]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = call fast float @llvm.fabs.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP15:%.*]] = fcmp fast oge float [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = select i1 [[TMP15]], i32 1, i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = add i32 [[TMP12]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = mul i32 [[TMP17]], [[TMP4]]
; CHECK-NEXT:    [[TMP19:%.*]] = sub i32 [[TMP3]], [[TMP18]]
; CHECK-NEXT:    [[TMP20:%.*]] = and i32 [[TMP19]], 65535
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i32 [[TMP20]] to i16
; CHECK-NEXT:    [[TMP22:%.*]] = insertelement <3 x i16> undef, i16 [[TMP21]], i64 0
; CHECK-NEXT:    [[TMP23:%.*]] = extractelement <3 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP24:%.*]] = extractelement <3 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP25:%.*]] = zext i16 [[TMP23]] to i32
; CHECK-NEXT:    [[TMP26:%.*]] = zext i16 [[TMP24]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = uitofp i32 [[TMP25]] to float
; CHECK-NEXT:    [[TMP28:%.*]] = uitofp i32 [[TMP26]] to float
; CHECK-NEXT:    [[TMP29:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP30:%.*]] = fmul fast float [[TMP27]], [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = call fast float @llvm.trunc.f32(float [[TMP30]])
; CHECK-NEXT:    [[TMP32:%.*]] = fneg fast float [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP32]], float [[TMP28]], float [[TMP27]])
; CHECK-NEXT:    [[TMP34:%.*]] = fptoui float [[TMP31]] to i32
; CHECK-NEXT:    [[TMP35:%.*]] = call fast float @llvm.fabs.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.fabs.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP37:%.*]] = fcmp fast oge float [[TMP35]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = select i1 [[TMP37]], i32 1, i32 0
; CHECK-NEXT:    [[TMP39:%.*]] = add i32 [[TMP34]], [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = mul i32 [[TMP39]], [[TMP26]]
; CHECK-NEXT:    [[TMP41:%.*]] = sub i32 [[TMP25]], [[TMP40]]
; CHECK-NEXT:    [[TMP42:%.*]] = and i32 [[TMP41]], 65535
; CHECK-NEXT:    [[TMP43:%.*]] = trunc i32 [[TMP42]] to i16
; CHECK-NEXT:    [[TMP44:%.*]] = insertelement <3 x i16> [[TMP22]], i16 [[TMP43]], i64 1
; CHECK-NEXT:    [[TMP45:%.*]] = extractelement <3 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP46:%.*]] = extractelement <3 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP47:%.*]] = zext i16 [[TMP45]] to i32
; CHECK-NEXT:    [[TMP48:%.*]] = zext i16 [[TMP46]] to i32
; CHECK-NEXT:    [[TMP49:%.*]] = uitofp i32 [[TMP47]] to float
; CHECK-NEXT:    [[TMP50:%.*]] = uitofp i32 [[TMP48]] to float
; CHECK-NEXT:    [[TMP51:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP50]])
; CHECK-NEXT:    [[TMP52:%.*]] = fmul fast float [[TMP49]], [[TMP51]]
; CHECK-NEXT:    [[TMP53:%.*]] = call fast float @llvm.trunc.f32(float [[TMP52]])
; CHECK-NEXT:    [[TMP54:%.*]] = fneg fast float [[TMP53]]
; CHECK-NEXT:    [[TMP55:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP54]], float [[TMP50]], float [[TMP49]])
; CHECK-NEXT:    [[TMP56:%.*]] = fptoui float [[TMP53]] to i32
; CHECK-NEXT:    [[TMP57:%.*]] = call fast float @llvm.fabs.f32(float [[TMP55]])
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.fabs.f32(float [[TMP50]])
; CHECK-NEXT:    [[TMP59:%.*]] = fcmp fast oge float [[TMP57]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = select i1 [[TMP59]], i32 1, i32 0
; CHECK-NEXT:    [[TMP61:%.*]] = add i32 [[TMP56]], [[TMP60]]
; CHECK-NEXT:    [[TMP62:%.*]] = mul i32 [[TMP61]], [[TMP48]]
; CHECK-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP47]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = and i32 [[TMP63]], 65535
; CHECK-NEXT:    [[TMP65:%.*]] = trunc i32 [[TMP64]] to i16
; CHECK-NEXT:    [[TMP66:%.*]] = insertelement <3 x i16> [[TMP44]], i16 [[TMP65]], i64 2
; CHECK-NEXT:    store <3 x i16> [[TMP66]], <3 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v3i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s8, 0xffff
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mov_b32_e32 v1, s2
; GCN-NEXT:    s_and_b32 s6, s0, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s6
; GCN-NEXT:    s_and_b32 s6, s2, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s6
; GCN-NEXT:    v_mov_b32_e32 v4, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v3, v0
; GCN-NEXT:    v_alignbit_b32 v4, s1, v4, 16
; GCN-NEXT:    v_and_b32_e32 v5, s8, v4
; GCN-NEXT:    v_alignbit_b32 v1, s3, v1, 16
; GCN-NEXT:    v_mul_f32_e32 v3, v2, v3
; GCN-NEXT:    v_trunc_f32_e32 v3, v3
; GCN-NEXT:    v_mad_f32 v2, -v3, v0, v2
; GCN-NEXT:    v_cvt_u32_f32_e32 v6, v3
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v2|, v0
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, v5
; GCN-NEXT:    v_and_b32_e32 v3, s8, v1
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s0
; GCN-NEXT:    s_and_b32 s0, s1, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, v3
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v2
; GCN-NEXT:    v_cvt_f32_u32_e32 v6, s0
; GCN-NEXT:    s_and_b32 s0, s3, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v7, s0
; GCN-NEXT:    v_mul_f32_e32 v5, v3, v5
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_rcp_iflag_f32_e32 v8, v6
; GCN-NEXT:    v_mad_f32 v3, -v5, v2, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v5, v5
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s2, v0
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v3|, v2
; GCN-NEXT:    v_mul_f32_e32 v3, v7, v8
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, 0, v5, vcc
; GCN-NEXT:    v_trunc_f32_e32 v3, v3
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v4
; GCN-NEXT:    v_cvt_u32_f32_e32 v4, v3
; GCN-NEXT:    v_mad_f32 v3, -v3, v6, v7
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v3|, v6
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v4, vcc
; GCN-NEXT:    v_mul_lo_u32 v3, v3, s1
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, v1, v2
; GCN-NEXT:    v_lshlrev_b32_e32 v1, 16, v1
; GCN-NEXT:    v_and_b32_e32 v0, s8, v0
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s3, v3
; GCN-NEXT:    v_or_b32_e32 v0, v0, v1
; GCN-NEXT:    buffer_store_short v2, off, s[4:7], 0 offset:4
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem <3 x i16> %x, %y
  store <3 x i16> %r, <3 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v3i16(<3 x i16> addrspace(1)* %out, <3 x i16> %x, <3 x i16> %y) {
; CHECK-LABEL: @sdiv_v3i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = sext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = sext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = ashr i32 [[TMP5]], 30
; CHECK-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 1
; CHECK-NEXT:    [[TMP8:%.*]] = sitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP9:%.*]] = sitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP8]], [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.trunc.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP13:%.*]] = fneg fast float [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP13]], float [[TMP9]], float [[TMP8]])
; CHECK-NEXT:    [[TMP15:%.*]] = fptosi float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP16:%.*]] = call fast float @llvm.fabs.f32(float [[TMP14]])
; CHECK-NEXT:    [[TMP17:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP18:%.*]] = fcmp fast oge float [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = select i1 [[TMP18]], i32 [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP15]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = shl i32 [[TMP20]], 16
; CHECK-NEXT:    [[TMP22:%.*]] = ashr i32 [[TMP21]], 16
; CHECK-NEXT:    [[TMP23:%.*]] = trunc i32 [[TMP22]] to i16
; CHECK-NEXT:    [[TMP24:%.*]] = insertelement <3 x i16> undef, i16 [[TMP23]], i64 0
; CHECK-NEXT:    [[TMP25:%.*]] = extractelement <3 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP26:%.*]] = extractelement <3 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP27:%.*]] = sext i16 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP28:%.*]] = sext i16 [[TMP26]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = xor i32 [[TMP27]], [[TMP28]]
; CHECK-NEXT:    [[TMP30:%.*]] = ashr i32 [[TMP29]], 30
; CHECK-NEXT:    [[TMP31:%.*]] = or i32 [[TMP30]], 1
; CHECK-NEXT:    [[TMP32:%.*]] = sitofp i32 [[TMP27]] to float
; CHECK-NEXT:    [[TMP33:%.*]] = sitofp i32 [[TMP28]] to float
; CHECK-NEXT:    [[TMP34:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP35:%.*]] = fmul fast float [[TMP32]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.trunc.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP37:%.*]] = fneg fast float [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP37]], float [[TMP33]], float [[TMP32]])
; CHECK-NEXT:    [[TMP39:%.*]] = fptosi float [[TMP36]] to i32
; CHECK-NEXT:    [[TMP40:%.*]] = call fast float @llvm.fabs.f32(float [[TMP38]])
; CHECK-NEXT:    [[TMP41:%.*]] = call fast float @llvm.fabs.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP42:%.*]] = fcmp fast oge float [[TMP40]], [[TMP41]]
; CHECK-NEXT:    [[TMP43:%.*]] = select i1 [[TMP42]], i32 [[TMP31]], i32 0
; CHECK-NEXT:    [[TMP44:%.*]] = add i32 [[TMP39]], [[TMP43]]
; CHECK-NEXT:    [[TMP45:%.*]] = shl i32 [[TMP44]], 16
; CHECK-NEXT:    [[TMP46:%.*]] = ashr i32 [[TMP45]], 16
; CHECK-NEXT:    [[TMP47:%.*]] = trunc i32 [[TMP46]] to i16
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <3 x i16> [[TMP24]], i16 [[TMP47]], i64 1
; CHECK-NEXT:    [[TMP49:%.*]] = extractelement <3 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP50:%.*]] = extractelement <3 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP51:%.*]] = sext i16 [[TMP49]] to i32
; CHECK-NEXT:    [[TMP52:%.*]] = sext i16 [[TMP50]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = xor i32 [[TMP51]], [[TMP52]]
; CHECK-NEXT:    [[TMP54:%.*]] = ashr i32 [[TMP53]], 30
; CHECK-NEXT:    [[TMP55:%.*]] = or i32 [[TMP54]], 1
; CHECK-NEXT:    [[TMP56:%.*]] = sitofp i32 [[TMP51]] to float
; CHECK-NEXT:    [[TMP57:%.*]] = sitofp i32 [[TMP52]] to float
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP59:%.*]] = fmul fast float [[TMP56]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = call fast float @llvm.trunc.f32(float [[TMP59]])
; CHECK-NEXT:    [[TMP61:%.*]] = fneg fast float [[TMP60]]
; CHECK-NEXT:    [[TMP62:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP61]], float [[TMP57]], float [[TMP56]])
; CHECK-NEXT:    [[TMP63:%.*]] = fptosi float [[TMP60]] to i32
; CHECK-NEXT:    [[TMP64:%.*]] = call fast float @llvm.fabs.f32(float [[TMP62]])
; CHECK-NEXT:    [[TMP65:%.*]] = call fast float @llvm.fabs.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP66:%.*]] = fcmp fast oge float [[TMP64]], [[TMP65]]
; CHECK-NEXT:    [[TMP67:%.*]] = select i1 [[TMP66]], i32 [[TMP55]], i32 0
; CHECK-NEXT:    [[TMP68:%.*]] = add i32 [[TMP63]], [[TMP67]]
; CHECK-NEXT:    [[TMP69:%.*]] = shl i32 [[TMP68]], 16
; CHECK-NEXT:    [[TMP70:%.*]] = ashr i32 [[TMP69]], 16
; CHECK-NEXT:    [[TMP71:%.*]] = trunc i32 [[TMP70]] to i16
; CHECK-NEXT:    [[TMP72:%.*]] = insertelement <3 x i16> [[TMP48]], i16 [[TMP71]], i64 2
; CHECK-NEXT:    store <3 x i16> [[TMP72]], <3 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v3i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_sext_i32_i16 s9, s2
; GCN-NEXT:    s_sext_i32_i16 s8, s0
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s8
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s9
; GCN-NEXT:    s_xor_b32 s8, s9, s8
; GCN-NEXT:    s_ashr_i32 s8, s8, 30
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_or_b32 s10, s8, 1
; GCN-NEXT:    s_sext_i32_i16 s1, s1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s8, s10, 0
; GCN-NEXT:    s_ashr_i32 s0, s0, 16
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s0
; GCN-NEXT:    s_ashr_i32 s2, s2, 16
; GCN-NEXT:    s_xor_b32 s0, s2, s0
; GCN-NEXT:    v_add_i32_e32 v1, vcc, s8, v2
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, s2
; GCN-NEXT:    v_rcp_iflag_f32_e32 v3, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s0, s0, 1
; GCN-NEXT:    v_and_b32_e32 v1, 0xffff, v1
; GCN-NEXT:    v_mul_f32_e32 v3, v2, v3
; GCN-NEXT:    v_trunc_f32_e32 v3, v3
; GCN-NEXT:    v_mad_f32 v2, -v3, v0, v2
; GCN-NEXT:    v_cvt_i32_f32_e32 v3, v3
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v2|, |v0|
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s1
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s0, s0, 0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, s0, v3
; GCN-NEXT:    s_sext_i32_i16 s0, s3
; GCN-NEXT:    v_cvt_f32_i32_e32 v3, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v0
; GCN-NEXT:    s_xor_b32 s0, s0, s1
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s2, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v4, v3, v4
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_mad_f32 v3, -v4, v0, v3
; GCN-NEXT:    v_cvt_i32_f32_e32 v4, v4
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v3|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s2, 0
; GCN-NEXT:    v_lshlrev_b32_e32 v2, 16, v2
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v4
; GCN-NEXT:    v_or_b32_e32 v1, v1, v2
; GCN-NEXT:    buffer_store_short v0, off, s[4:7], 0 offset:4
; GCN-NEXT:    buffer_store_dword v1, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv <3 x i16> %x, %y
  store <3 x i16> %r, <3 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v3i16(<3 x i16> addrspace(1)* %out, <3 x i16> %x, <3 x i16> %y) {
; CHECK-LABEL: @srem_v3i16(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i16> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i16> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = sext i16 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = sext i16 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = ashr i32 [[TMP5]], 30
; CHECK-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 1
; CHECK-NEXT:    [[TMP8:%.*]] = sitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP9:%.*]] = sitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP8]], [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.trunc.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP13:%.*]] = fneg fast float [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP13]], float [[TMP9]], float [[TMP8]])
; CHECK-NEXT:    [[TMP15:%.*]] = fptosi float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP16:%.*]] = call fast float @llvm.fabs.f32(float [[TMP14]])
; CHECK-NEXT:    [[TMP17:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP18:%.*]] = fcmp fast oge float [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = select i1 [[TMP18]], i32 [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP15]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = mul i32 [[TMP20]], [[TMP4]]
; CHECK-NEXT:    [[TMP22:%.*]] = sub i32 [[TMP3]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = shl i32 [[TMP22]], 16
; CHECK-NEXT:    [[TMP24:%.*]] = ashr i32 [[TMP23]], 16
; CHECK-NEXT:    [[TMP25:%.*]] = trunc i32 [[TMP24]] to i16
; CHECK-NEXT:    [[TMP26:%.*]] = insertelement <3 x i16> undef, i16 [[TMP25]], i64 0
; CHECK-NEXT:    [[TMP27:%.*]] = extractelement <3 x i16> [[X]], i64 1
; CHECK-NEXT:    [[TMP28:%.*]] = extractelement <3 x i16> [[Y]], i64 1
; CHECK-NEXT:    [[TMP29:%.*]] = sext i16 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP30:%.*]] = sext i16 [[TMP28]] to i32
; CHECK-NEXT:    [[TMP31:%.*]] = xor i32 [[TMP29]], [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = ashr i32 [[TMP31]], 30
; CHECK-NEXT:    [[TMP33:%.*]] = or i32 [[TMP32]], 1
; CHECK-NEXT:    [[TMP34:%.*]] = sitofp i32 [[TMP29]] to float
; CHECK-NEXT:    [[TMP35:%.*]] = sitofp i32 [[TMP30]] to float
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP37:%.*]] = fmul fast float [[TMP34]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = call fast float @llvm.trunc.f32(float [[TMP37]])
; CHECK-NEXT:    [[TMP39:%.*]] = fneg fast float [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP39]], float [[TMP35]], float [[TMP34]])
; CHECK-NEXT:    [[TMP41:%.*]] = fptosi float [[TMP38]] to i32
; CHECK-NEXT:    [[TMP42:%.*]] = call fast float @llvm.fabs.f32(float [[TMP40]])
; CHECK-NEXT:    [[TMP43:%.*]] = call fast float @llvm.fabs.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP44:%.*]] = fcmp fast oge float [[TMP42]], [[TMP43]]
; CHECK-NEXT:    [[TMP45:%.*]] = select i1 [[TMP44]], i32 [[TMP33]], i32 0
; CHECK-NEXT:    [[TMP46:%.*]] = add i32 [[TMP41]], [[TMP45]]
; CHECK-NEXT:    [[TMP47:%.*]] = mul i32 [[TMP46]], [[TMP30]]
; CHECK-NEXT:    [[TMP48:%.*]] = sub i32 [[TMP29]], [[TMP47]]
; CHECK-NEXT:    [[TMP49:%.*]] = shl i32 [[TMP48]], 16
; CHECK-NEXT:    [[TMP50:%.*]] = ashr i32 [[TMP49]], 16
; CHECK-NEXT:    [[TMP51:%.*]] = trunc i32 [[TMP50]] to i16
; CHECK-NEXT:    [[TMP52:%.*]] = insertelement <3 x i16> [[TMP26]], i16 [[TMP51]], i64 1
; CHECK-NEXT:    [[TMP53:%.*]] = extractelement <3 x i16> [[X]], i64 2
; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <3 x i16> [[Y]], i64 2
; CHECK-NEXT:    [[TMP55:%.*]] = sext i16 [[TMP53]] to i32
; CHECK-NEXT:    [[TMP56:%.*]] = sext i16 [[TMP54]] to i32
; CHECK-NEXT:    [[TMP57:%.*]] = xor i32 [[TMP55]], [[TMP56]]
; CHECK-NEXT:    [[TMP58:%.*]] = ashr i32 [[TMP57]], 30
; CHECK-NEXT:    [[TMP59:%.*]] = or i32 [[TMP58]], 1
; CHECK-NEXT:    [[TMP60:%.*]] = sitofp i32 [[TMP55]] to float
; CHECK-NEXT:    [[TMP61:%.*]] = sitofp i32 [[TMP56]] to float
; CHECK-NEXT:    [[TMP62:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP61]])
; CHECK-NEXT:    [[TMP63:%.*]] = fmul fast float [[TMP60]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = call fast float @llvm.trunc.f32(float [[TMP63]])
; CHECK-NEXT:    [[TMP65:%.*]] = fneg fast float [[TMP64]]
; CHECK-NEXT:    [[TMP66:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP65]], float [[TMP61]], float [[TMP60]])
; CHECK-NEXT:    [[TMP67:%.*]] = fptosi float [[TMP64]] to i32
; CHECK-NEXT:    [[TMP68:%.*]] = call fast float @llvm.fabs.f32(float [[TMP66]])
; CHECK-NEXT:    [[TMP69:%.*]] = call fast float @llvm.fabs.f32(float [[TMP61]])
; CHECK-NEXT:    [[TMP70:%.*]] = fcmp fast oge float [[TMP68]], [[TMP69]]
; CHECK-NEXT:    [[TMP71:%.*]] = select i1 [[TMP70]], i32 [[TMP59]], i32 0
; CHECK-NEXT:    [[TMP72:%.*]] = add i32 [[TMP67]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = mul i32 [[TMP72]], [[TMP56]]
; CHECK-NEXT:    [[TMP74:%.*]] = sub i32 [[TMP55]], [[TMP73]]
; CHECK-NEXT:    [[TMP75:%.*]] = shl i32 [[TMP74]], 16
; CHECK-NEXT:    [[TMP76:%.*]] = ashr i32 [[TMP75]], 16
; CHECK-NEXT:    [[TMP77:%.*]] = trunc i32 [[TMP76]] to i16
; CHECK-NEXT:    [[TMP78:%.*]] = insertelement <3 x i16> [[TMP52]], i16 [[TMP77]], i64 2
; CHECK-NEXT:    store <3 x i16> [[TMP78]], <3 x i16> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v3i16:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_sext_i32_i16 s8, s2
; GCN-NEXT:    s_sext_i32_i16 s6, s0
; GCN-NEXT:    v_cvt_f32_i32_e32 v0, s6
; GCN-NEXT:    v_cvt_f32_i32_e32 v1, s8
; GCN-NEXT:    s_xor_b32 s6, s8, s6
; GCN-NEXT:    s_ashr_i32 s6, s6, 30
; GCN-NEXT:    v_rcp_iflag_f32_e32 v2, v0
; GCN-NEXT:    s_or_b32 s6, s6, 1
; GCN-NEXT:    v_mul_f32_e32 v2, v1, v2
; GCN-NEXT:    v_trunc_f32_e32 v2, v2
; GCN-NEXT:    v_mad_f32 v1, -v2, v0, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v1|, |v0|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s6, s6, 0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s6, v2
; GCN-NEXT:    v_mov_b32_e32 v2, s0
; GCN-NEXT:    v_alignbit_b32 v2, s1, v2, 16
; GCN-NEXT:    v_bfe_i32 v3, v2, 0, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v4, v3
; GCN-NEXT:    v_mov_b32_e32 v1, s2
; GCN-NEXT:    v_alignbit_b32 v1, s3, v1, 16
; GCN-NEXT:    v_bfe_i32 v5, v1, 0, 16
; GCN-NEXT:    v_cvt_f32_i32_e32 v6, v5
; GCN-NEXT:    v_rcp_iflag_f32_e32 v7, v4
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s0
; GCN-NEXT:    v_xor_b32_e32 v3, v5, v3
; GCN-NEXT:    s_sext_i32_i16 s0, s1
; GCN-NEXT:    v_mul_f32_e32 v5, v6, v7
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s2, v0
; GCN-NEXT:    v_mad_f32 v6, -v5, v4, v6
; GCN-NEXT:    v_cvt_i32_f32_e32 v5, v5
; GCN-NEXT:    v_ashrrev_i32_e32 v3, 30, v3
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v6|, |v4|
; GCN-NEXT:    v_cvt_f32_i32_e32 v4, s0
; GCN-NEXT:    v_or_b32_e32 v3, 1, v3
; GCN-NEXT:    v_cndmask_b32_e32 v3, 0, v3, vcc
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v5, v3
; GCN-NEXT:    s_sext_i32_i16 s2, s3
; GCN-NEXT:    v_mul_lo_u32 v2, v3, v2
; GCN-NEXT:    v_cvt_f32_i32_e32 v3, s2
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v4
; GCN-NEXT:    s_xor_b32 s0, s2, s0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s0, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v5, v3, v5
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_mad_f32 v3, -v5, v4, v3
; GCN-NEXT:    v_cvt_i32_f32_e32 v5, v5
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v3|, |v4|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s0, s0, 0
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s0, v5
; GCN-NEXT:    v_mul_lo_u32 v3, v3, s1
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, v1, v2
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_lshlrev_b32_e32 v1, 16, v1
; GCN-NEXT:    v_and_b32_e32 v0, 0xffff, v0
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s3, v3
; GCN-NEXT:    v_or_b32_e32 v0, v0, v1
; GCN-NEXT:    buffer_store_short v2, off, s[4:7], 0 offset:4
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem <3 x i16> %x, %y
  store <3 x i16> %r, <3 x i16> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v3i15(<3 x i15> addrspace(1)* %out, <3 x i15> %x, <3 x i15> %y) {
; CHECK-LABEL: @udiv_v3i15(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i15> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i15> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = zext i15 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = zext i15 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = uitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP6:%.*]] = uitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fmul fast float [[TMP5]], [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.trunc.f32(float [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = fneg fast float [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP10]], float [[TMP6]], float [[TMP5]])
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP9]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = call fast float @llvm.fabs.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP15:%.*]] = fcmp fast oge float [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = select i1 [[TMP15]], i32 1, i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = add i32 [[TMP12]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = and i32 [[TMP17]], 32767
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i32 [[TMP18]] to i15
; CHECK-NEXT:    [[TMP20:%.*]] = insertelement <3 x i15> undef, i15 [[TMP19]], i64 0
; CHECK-NEXT:    [[TMP21:%.*]] = extractelement <3 x i15> [[X]], i64 1
; CHECK-NEXT:    [[TMP22:%.*]] = extractelement <3 x i15> [[Y]], i64 1
; CHECK-NEXT:    [[TMP23:%.*]] = zext i15 [[TMP21]] to i32
; CHECK-NEXT:    [[TMP24:%.*]] = zext i15 [[TMP22]] to i32
; CHECK-NEXT:    [[TMP25:%.*]] = uitofp i32 [[TMP23]] to float
; CHECK-NEXT:    [[TMP26:%.*]] = uitofp i32 [[TMP24]] to float
; CHECK-NEXT:    [[TMP27:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP26]])
; CHECK-NEXT:    [[TMP28:%.*]] = fmul fast float [[TMP25]], [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = call fast float @llvm.trunc.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP30:%.*]] = fneg fast float [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP30]], float [[TMP26]], float [[TMP25]])
; CHECK-NEXT:    [[TMP32:%.*]] = fptoui float [[TMP29]] to i32
; CHECK-NEXT:    [[TMP33:%.*]] = call fast float @llvm.fabs.f32(float [[TMP31]])
; CHECK-NEXT:    [[TMP34:%.*]] = call fast float @llvm.fabs.f32(float [[TMP26]])
; CHECK-NEXT:    [[TMP35:%.*]] = fcmp fast oge float [[TMP33]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = select i1 [[TMP35]], i32 1, i32 0
; CHECK-NEXT:    [[TMP37:%.*]] = add i32 [[TMP32]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = and i32 [[TMP37]], 32767
; CHECK-NEXT:    [[TMP39:%.*]] = trunc i32 [[TMP38]] to i15
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <3 x i15> [[TMP20]], i15 [[TMP39]], i64 1
; CHECK-NEXT:    [[TMP41:%.*]] = extractelement <3 x i15> [[X]], i64 2
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <3 x i15> [[Y]], i64 2
; CHECK-NEXT:    [[TMP43:%.*]] = zext i15 [[TMP41]] to i32
; CHECK-NEXT:    [[TMP44:%.*]] = zext i15 [[TMP42]] to i32
; CHECK-NEXT:    [[TMP45:%.*]] = uitofp i32 [[TMP43]] to float
; CHECK-NEXT:    [[TMP46:%.*]] = uitofp i32 [[TMP44]] to float
; CHECK-NEXT:    [[TMP47:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP46]])
; CHECK-NEXT:    [[TMP48:%.*]] = fmul fast float [[TMP45]], [[TMP47]]
; CHECK-NEXT:    [[TMP49:%.*]] = call fast float @llvm.trunc.f32(float [[TMP48]])
; CHECK-NEXT:    [[TMP50:%.*]] = fneg fast float [[TMP49]]
; CHECK-NEXT:    [[TMP51:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP50]], float [[TMP46]], float [[TMP45]])
; CHECK-NEXT:    [[TMP52:%.*]] = fptoui float [[TMP49]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = call fast float @llvm.fabs.f32(float [[TMP51]])
; CHECK-NEXT:    [[TMP54:%.*]] = call fast float @llvm.fabs.f32(float [[TMP46]])
; CHECK-NEXT:    [[TMP55:%.*]] = fcmp fast oge float [[TMP53]], [[TMP54]]
; CHECK-NEXT:    [[TMP56:%.*]] = select i1 [[TMP55]], i32 1, i32 0
; CHECK-NEXT:    [[TMP57:%.*]] = add i32 [[TMP52]], [[TMP56]]
; CHECK-NEXT:    [[TMP58:%.*]] = and i32 [[TMP57]], 32767
; CHECK-NEXT:    [[TMP59:%.*]] = trunc i32 [[TMP58]] to i15
; CHECK-NEXT:    [[TMP60:%.*]] = insertelement <3 x i15> [[TMP40]], i15 [[TMP59]], i64 2
; CHECK-NEXT:    store <3 x i15> [[TMP60]], <3 x i15> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v3i15:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_alignbit_b32 v0, s3, v0, 30
; GCN-NEXT:    s_movk_i32 s3, 0x7fff
; GCN-NEXT:    s_and_b32 s9, s0, s3
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s9
; GCN-NEXT:    v_mov_b32_e32 v2, s0
; GCN-NEXT:    s_and_b32 s8, s2, s3
; GCN-NEXT:    s_bfe_u32 s0, s0, 0xf000f
; GCN-NEXT:    v_cvt_f32_u32_e32 v5, s0
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s8
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v1
; GCN-NEXT:    s_bfe_u32 s2, s2, 0xf000f
; GCN-NEXT:    v_alignbit_b32 v2, s1, v2, 30
; GCN-NEXT:    v_cvt_f32_u32_e32 v6, s2
; GCN-NEXT:    v_mul_f32_e32 v4, v3, v4
; GCN-NEXT:    v_rcp_iflag_f32_e32 v7, v5
; GCN-NEXT:    v_and_b32_e32 v2, s3, v2
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_mad_f32 v3, -v4, v1, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v4, v4
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v3|, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v6, v7
; GCN-NEXT:    v_and_b32_e32 v0, s3, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v4, vcc
; GCN-NEXT:    v_mad_f32 v4, -v1, v5, v6
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v6, v2
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v4|, v5
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_f32_e32 v1, v0, v6
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v5, v1
; GCN-NEXT:    v_mad_f32 v0, -v1, v2, v0
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v0|, v2
; GCN-NEXT:    v_and_b32_e32 v2, s3, v3
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, 0, v5, vcc
; GCN-NEXT:    v_and_b32_e32 v3, s3, v4
; GCN-NEXT:    v_lshl_b64 v[0:1], v[0:1], 30
; GCN-NEXT:    v_lshlrev_b32_e32 v3, 15, v3
; GCN-NEXT:    v_or_b32_e32 v2, v2, v3
; GCN-NEXT:    v_or_b32_e32 v0, v2, v0
; GCN-NEXT:    v_and_b32_e32 v1, 0x1fff, v1
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    buffer_store_short v1, off, s[4:7], 0 offset:4
; GCN-NEXT:    s_endpgm
  %r = udiv <3 x i15> %x, %y
  store <3 x i15> %r, <3 x i15> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v3i15(<3 x i15> addrspace(1)* %out, <3 x i15> %x, <3 x i15> %y) {
; CHECK-LABEL: @urem_v3i15(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i15> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i15> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = zext i15 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = zext i15 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = uitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP6:%.*]] = uitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP7:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP8:%.*]] = fmul fast float [[TMP5]], [[TMP7]]
; CHECK-NEXT:    [[TMP9:%.*]] = call fast float @llvm.trunc.f32(float [[TMP8]])
; CHECK-NEXT:    [[TMP10:%.*]] = fneg fast float [[TMP9]]
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP10]], float [[TMP6]], float [[TMP5]])
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP9]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = call fast float @llvm.fabs.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.fabs.f32(float [[TMP6]])
; CHECK-NEXT:    [[TMP15:%.*]] = fcmp fast oge float [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = select i1 [[TMP15]], i32 1, i32 0
; CHECK-NEXT:    [[TMP17:%.*]] = add i32 [[TMP12]], [[TMP16]]
; CHECK-NEXT:    [[TMP18:%.*]] = mul i32 [[TMP17]], [[TMP4]]
; CHECK-NEXT:    [[TMP19:%.*]] = sub i32 [[TMP3]], [[TMP18]]
; CHECK-NEXT:    [[TMP20:%.*]] = and i32 [[TMP19]], 32767
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i32 [[TMP20]] to i15
; CHECK-NEXT:    [[TMP22:%.*]] = insertelement <3 x i15> undef, i15 [[TMP21]], i64 0
; CHECK-NEXT:    [[TMP23:%.*]] = extractelement <3 x i15> [[X]], i64 1
; CHECK-NEXT:    [[TMP24:%.*]] = extractelement <3 x i15> [[Y]], i64 1
; CHECK-NEXT:    [[TMP25:%.*]] = zext i15 [[TMP23]] to i32
; CHECK-NEXT:    [[TMP26:%.*]] = zext i15 [[TMP24]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = uitofp i32 [[TMP25]] to float
; CHECK-NEXT:    [[TMP28:%.*]] = uitofp i32 [[TMP26]] to float
; CHECK-NEXT:    [[TMP29:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP30:%.*]] = fmul fast float [[TMP27]], [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = call fast float @llvm.trunc.f32(float [[TMP30]])
; CHECK-NEXT:    [[TMP32:%.*]] = fneg fast float [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP32]], float [[TMP28]], float [[TMP27]])
; CHECK-NEXT:    [[TMP34:%.*]] = fptoui float [[TMP31]] to i32
; CHECK-NEXT:    [[TMP35:%.*]] = call fast float @llvm.fabs.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.fabs.f32(float [[TMP28]])
; CHECK-NEXT:    [[TMP37:%.*]] = fcmp fast oge float [[TMP35]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = select i1 [[TMP37]], i32 1, i32 0
; CHECK-NEXT:    [[TMP39:%.*]] = add i32 [[TMP34]], [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = mul i32 [[TMP39]], [[TMP26]]
; CHECK-NEXT:    [[TMP41:%.*]] = sub i32 [[TMP25]], [[TMP40]]
; CHECK-NEXT:    [[TMP42:%.*]] = and i32 [[TMP41]], 32767
; CHECK-NEXT:    [[TMP43:%.*]] = trunc i32 [[TMP42]] to i15
; CHECK-NEXT:    [[TMP44:%.*]] = insertelement <3 x i15> [[TMP22]], i15 [[TMP43]], i64 1
; CHECK-NEXT:    [[TMP45:%.*]] = extractelement <3 x i15> [[X]], i64 2
; CHECK-NEXT:    [[TMP46:%.*]] = extractelement <3 x i15> [[Y]], i64 2
; CHECK-NEXT:    [[TMP47:%.*]] = zext i15 [[TMP45]] to i32
; CHECK-NEXT:    [[TMP48:%.*]] = zext i15 [[TMP46]] to i32
; CHECK-NEXT:    [[TMP49:%.*]] = uitofp i32 [[TMP47]] to float
; CHECK-NEXT:    [[TMP50:%.*]] = uitofp i32 [[TMP48]] to float
; CHECK-NEXT:    [[TMP51:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP50]])
; CHECK-NEXT:    [[TMP52:%.*]] = fmul fast float [[TMP49]], [[TMP51]]
; CHECK-NEXT:    [[TMP53:%.*]] = call fast float @llvm.trunc.f32(float [[TMP52]])
; CHECK-NEXT:    [[TMP54:%.*]] = fneg fast float [[TMP53]]
; CHECK-NEXT:    [[TMP55:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP54]], float [[TMP50]], float [[TMP49]])
; CHECK-NEXT:    [[TMP56:%.*]] = fptoui float [[TMP53]] to i32
; CHECK-NEXT:    [[TMP57:%.*]] = call fast float @llvm.fabs.f32(float [[TMP55]])
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.fabs.f32(float [[TMP50]])
; CHECK-NEXT:    [[TMP59:%.*]] = fcmp fast oge float [[TMP57]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = select i1 [[TMP59]], i32 1, i32 0
; CHECK-NEXT:    [[TMP61:%.*]] = add i32 [[TMP56]], [[TMP60]]
; CHECK-NEXT:    [[TMP62:%.*]] = mul i32 [[TMP61]], [[TMP48]]
; CHECK-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP47]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = and i32 [[TMP63]], 32767
; CHECK-NEXT:    [[TMP65:%.*]] = trunc i32 [[TMP64]] to i15
; CHECK-NEXT:    [[TMP66:%.*]] = insertelement <3 x i15> [[TMP44]], i15 [[TMP65]], i64 2
; CHECK-NEXT:    store <3 x i15> [[TMP66]], <3 x i15> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v3i15:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_alignbit_b32 v0, s3, v0, 30
; GCN-NEXT:    s_movk_i32 s3, 0x7fff
; GCN-NEXT:    s_and_b32 s10, s0, s3
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s10
; GCN-NEXT:    s_and_b32 s9, s2, s3
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s9
; GCN-NEXT:    v_mov_b32_e32 v2, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v1
; GCN-NEXT:    v_alignbit_b32 v2, s1, v2, 30
; GCN-NEXT:    s_bfe_u32 s1, s0, 0xf000f
; GCN-NEXT:    v_cvt_f32_u32_e32 v5, s1
; GCN-NEXT:    v_mul_f32_e32 v4, v3, v4
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_mad_f32 v3, -v4, v1, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v4, v4
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v3|, v1
; GCN-NEXT:    s_bfe_u32 s10, s2, 0xf000f
; GCN-NEXT:    v_cvt_f32_u32_e32 v3, s10
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v4, vcc
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v5
; GCN-NEXT:    v_and_b32_e32 v2, s3, v2
; GCN-NEXT:    v_and_b32_e32 v0, s3, v0
; GCN-NEXT:    v_sub_i32_e32 v6, vcc, s2, v1
; GCN-NEXT:    v_mul_f32_e32 v1, v3, v4
; GCN-NEXT:    v_cvt_f32_u32_e32 v4, v2
; GCN-NEXT:    v_cvt_f32_u32_e32 v7, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mad_f32 v3, -v1, v5, v3
; GCN-NEXT:    v_rcp_iflag_f32_e32 v8, v4
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v3|, v5
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_lshr_b32 s0, s0, 15
; GCN-NEXT:    v_mul_f32_e32 v3, v7, v8
; GCN-NEXT:    v_trunc_f32_e32 v3, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v5, v3
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mad_f32 v3, -v3, v4, v7
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v3|, v4
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s0
; GCN-NEXT:    v_mul_lo_u32 v2, v3, v2
; GCN-NEXT:    s_lshr_b32 s8, s2, 15
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s8, v1
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v2, v0
; GCN-NEXT:    v_and_b32_e32 v3, s3, v3
; GCN-NEXT:    v_lshl_b64 v[0:1], v[0:1], 30
; GCN-NEXT:    v_and_b32_e32 v2, s3, v6
; GCN-NEXT:    v_lshlrev_b32_e32 v3, 15, v3
; GCN-NEXT:    v_or_b32_e32 v2, v2, v3
; GCN-NEXT:    v_or_b32_e32 v0, v2, v0
; GCN-NEXT:    v_and_b32_e32 v1, 0x1fff, v1
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    buffer_store_short v1, off, s[4:7], 0 offset:4
; GCN-NEXT:    s_endpgm
  %r = urem <3 x i15> %x, %y
  store <3 x i15> %r, <3 x i15> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v3i15(<3 x i15> addrspace(1)* %out, <3 x i15> %x, <3 x i15> %y) {
; CHECK-LABEL: @sdiv_v3i15(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i15> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i15> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = sext i15 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = sext i15 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = ashr i32 [[TMP5]], 30
; CHECK-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 1
; CHECK-NEXT:    [[TMP8:%.*]] = sitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP9:%.*]] = sitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP8]], [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.trunc.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP13:%.*]] = fneg fast float [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP13]], float [[TMP9]], float [[TMP8]])
; CHECK-NEXT:    [[TMP15:%.*]] = fptosi float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP16:%.*]] = call fast float @llvm.fabs.f32(float [[TMP14]])
; CHECK-NEXT:    [[TMP17:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP18:%.*]] = fcmp fast oge float [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = select i1 [[TMP18]], i32 [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP15]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = shl i32 [[TMP20]], 17
; CHECK-NEXT:    [[TMP22:%.*]] = ashr i32 [[TMP21]], 17
; CHECK-NEXT:    [[TMP23:%.*]] = trunc i32 [[TMP22]] to i15
; CHECK-NEXT:    [[TMP24:%.*]] = insertelement <3 x i15> undef, i15 [[TMP23]], i64 0
; CHECK-NEXT:    [[TMP25:%.*]] = extractelement <3 x i15> [[X]], i64 1
; CHECK-NEXT:    [[TMP26:%.*]] = extractelement <3 x i15> [[Y]], i64 1
; CHECK-NEXT:    [[TMP27:%.*]] = sext i15 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP28:%.*]] = sext i15 [[TMP26]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = xor i32 [[TMP27]], [[TMP28]]
; CHECK-NEXT:    [[TMP30:%.*]] = ashr i32 [[TMP29]], 30
; CHECK-NEXT:    [[TMP31:%.*]] = or i32 [[TMP30]], 1
; CHECK-NEXT:    [[TMP32:%.*]] = sitofp i32 [[TMP27]] to float
; CHECK-NEXT:    [[TMP33:%.*]] = sitofp i32 [[TMP28]] to float
; CHECK-NEXT:    [[TMP34:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP35:%.*]] = fmul fast float [[TMP32]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.trunc.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP37:%.*]] = fneg fast float [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP37]], float [[TMP33]], float [[TMP32]])
; CHECK-NEXT:    [[TMP39:%.*]] = fptosi float [[TMP36]] to i32
; CHECK-NEXT:    [[TMP40:%.*]] = call fast float @llvm.fabs.f32(float [[TMP38]])
; CHECK-NEXT:    [[TMP41:%.*]] = call fast float @llvm.fabs.f32(float [[TMP33]])
; CHECK-NEXT:    [[TMP42:%.*]] = fcmp fast oge float [[TMP40]], [[TMP41]]
; CHECK-NEXT:    [[TMP43:%.*]] = select i1 [[TMP42]], i32 [[TMP31]], i32 0
; CHECK-NEXT:    [[TMP44:%.*]] = add i32 [[TMP39]], [[TMP43]]
; CHECK-NEXT:    [[TMP45:%.*]] = shl i32 [[TMP44]], 17
; CHECK-NEXT:    [[TMP46:%.*]] = ashr i32 [[TMP45]], 17
; CHECK-NEXT:    [[TMP47:%.*]] = trunc i32 [[TMP46]] to i15
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <3 x i15> [[TMP24]], i15 [[TMP47]], i64 1
; CHECK-NEXT:    [[TMP49:%.*]] = extractelement <3 x i15> [[X]], i64 2
; CHECK-NEXT:    [[TMP50:%.*]] = extractelement <3 x i15> [[Y]], i64 2
; CHECK-NEXT:    [[TMP51:%.*]] = sext i15 [[TMP49]] to i32
; CHECK-NEXT:    [[TMP52:%.*]] = sext i15 [[TMP50]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = xor i32 [[TMP51]], [[TMP52]]
; CHECK-NEXT:    [[TMP54:%.*]] = ashr i32 [[TMP53]], 30
; CHECK-NEXT:    [[TMP55:%.*]] = or i32 [[TMP54]], 1
; CHECK-NEXT:    [[TMP56:%.*]] = sitofp i32 [[TMP51]] to float
; CHECK-NEXT:    [[TMP57:%.*]] = sitofp i32 [[TMP52]] to float
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP59:%.*]] = fmul fast float [[TMP56]], [[TMP58]]
; CHECK-NEXT:    [[TMP60:%.*]] = call fast float @llvm.trunc.f32(float [[TMP59]])
; CHECK-NEXT:    [[TMP61:%.*]] = fneg fast float [[TMP60]]
; CHECK-NEXT:    [[TMP62:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP61]], float [[TMP57]], float [[TMP56]])
; CHECK-NEXT:    [[TMP63:%.*]] = fptosi float [[TMP60]] to i32
; CHECK-NEXT:    [[TMP64:%.*]] = call fast float @llvm.fabs.f32(float [[TMP62]])
; CHECK-NEXT:    [[TMP65:%.*]] = call fast float @llvm.fabs.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP66:%.*]] = fcmp fast oge float [[TMP64]], [[TMP65]]
; CHECK-NEXT:    [[TMP67:%.*]] = select i1 [[TMP66]], i32 [[TMP55]], i32 0
; CHECK-NEXT:    [[TMP68:%.*]] = add i32 [[TMP63]], [[TMP67]]
; CHECK-NEXT:    [[TMP69:%.*]] = shl i32 [[TMP68]], 17
; CHECK-NEXT:    [[TMP70:%.*]] = ashr i32 [[TMP69]], 17
; CHECK-NEXT:    [[TMP71:%.*]] = trunc i32 [[TMP70]] to i15
; CHECK-NEXT:    [[TMP72:%.*]] = insertelement <3 x i15> [[TMP48]], i15 [[TMP71]], i64 2
; CHECK-NEXT:    store <3 x i15> [[TMP72]], <3 x i15> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v3i15:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_alignbit_b32 v0, s3, v0, 30
; GCN-NEXT:    s_bfe_i32 s3, s0, 0xf0000
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, s3
; GCN-NEXT:    v_mov_b32_e32 v1, s0
; GCN-NEXT:    v_alignbit_b32 v1, s1, v1, 30
; GCN-NEXT:    s_bfe_i32 s1, s2, 0xf0000
; GCN-NEXT:    v_cvt_f32_i32_e32 v3, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v2
; GCN-NEXT:    s_xor_b32 s1, s1, s3
; GCN-NEXT:    s_ashr_i32 s1, s1, 30
; GCN-NEXT:    s_or_b32 s1, s1, 1
; GCN-NEXT:    v_mul_f32_e32 v4, v3, v4
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_mad_f32 v3, -v4, v2, v3
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v3|, |v2|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s1, s1, 0
; GCN-NEXT:    v_cvt_i32_f32_e32 v4, v4
; GCN-NEXT:    s_bfe_i32 s0, s0, 0xf000f
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, s0
; GCN-NEXT:    v_bfe_i32 v1, v1, 0, 15
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s1, v4
; GCN-NEXT:    s_bfe_i32 s1, s2, 0xf000f
; GCN-NEXT:    v_cvt_f32_i32_e32 v4, s1
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v2
; GCN-NEXT:    s_xor_b32 s0, s1, s0
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    s_or_b32 s2, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v5, v4, v5
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_mad_f32 v4, -v5, v2, v4
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v4|, |v2|
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, v1
; GCN-NEXT:    v_cvt_i32_f32_e32 v5, v5
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    s_cselect_b32 s0, s2, 0
; GCN-NEXT:    v_bfe_i32 v0, v0, 0, 15
; GCN-NEXT:    v_add_i32_e32 v4, vcc, s0, v5
; GCN-NEXT:    v_cvt_f32_i32_e32 v5, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v6, v2
; GCN-NEXT:    v_xor_b32_e32 v0, v0, v1
; GCN-NEXT:    v_ashrrev_i32_e32 v0, 30, v0
; GCN-NEXT:    v_or_b32_e32 v0, 1, v0
; GCN-NEXT:    v_mul_f32_e32 v1, v5, v6
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mad_f32 v5, -v1, v2, v5
; GCN-NEXT:    v_cvt_i32_f32_e32 v1, v1
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v5|, |v2|
; GCN-NEXT:    v_cndmask_b32_e32 v0, 0, v0, vcc
; GCN-NEXT:    s_movk_i32 s0, 0x7fff
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_and_b32_e32 v2, s0, v3
; GCN-NEXT:    v_and_b32_e32 v3, s0, v4
; GCN-NEXT:    v_lshl_b64 v[0:1], v[0:1], 30
; GCN-NEXT:    v_lshlrev_b32_e32 v3, 15, v3
; GCN-NEXT:    v_or_b32_e32 v2, v2, v3
; GCN-NEXT:    v_or_b32_e32 v0, v2, v0
; GCN-NEXT:    v_and_b32_e32 v1, 0x1fff, v1
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    buffer_store_short v1, off, s[4:7], 0 offset:4
; GCN-NEXT:    s_endpgm
  %r = sdiv <3 x i15> %x, %y
  store <3 x i15> %r, <3 x i15> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v3i15(<3 x i15> addrspace(1)* %out, <3 x i15> %x, <3 x i15> %y) {
; CHECK-LABEL: @srem_v3i15(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <3 x i15> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <3 x i15> [[Y:%.*]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = sext i15 [[TMP1]] to i32
; CHECK-NEXT:    [[TMP4:%.*]] = sext i15 [[TMP2]] to i32
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = ashr i32 [[TMP5]], 30
; CHECK-NEXT:    [[TMP7:%.*]] = or i32 [[TMP6]], 1
; CHECK-NEXT:    [[TMP8:%.*]] = sitofp i32 [[TMP3]] to float
; CHECK-NEXT:    [[TMP9:%.*]] = sitofp i32 [[TMP4]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP8]], [[TMP10]]
; CHECK-NEXT:    [[TMP12:%.*]] = call fast float @llvm.trunc.f32(float [[TMP11]])
; CHECK-NEXT:    [[TMP13:%.*]] = fneg fast float [[TMP12]]
; CHECK-NEXT:    [[TMP14:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP13]], float [[TMP9]], float [[TMP8]])
; CHECK-NEXT:    [[TMP15:%.*]] = fptosi float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP16:%.*]] = call fast float @llvm.fabs.f32(float [[TMP14]])
; CHECK-NEXT:    [[TMP17:%.*]] = call fast float @llvm.fabs.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP18:%.*]] = fcmp fast oge float [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = select i1 [[TMP18]], i32 [[TMP7]], i32 0
; CHECK-NEXT:    [[TMP20:%.*]] = add i32 [[TMP15]], [[TMP19]]
; CHECK-NEXT:    [[TMP21:%.*]] = mul i32 [[TMP20]], [[TMP4]]
; CHECK-NEXT:    [[TMP22:%.*]] = sub i32 [[TMP3]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = shl i32 [[TMP22]], 17
; CHECK-NEXT:    [[TMP24:%.*]] = ashr i32 [[TMP23]], 17
; CHECK-NEXT:    [[TMP25:%.*]] = trunc i32 [[TMP24]] to i15
; CHECK-NEXT:    [[TMP26:%.*]] = insertelement <3 x i15> undef, i15 [[TMP25]], i64 0
; CHECK-NEXT:    [[TMP27:%.*]] = extractelement <3 x i15> [[X]], i64 1
; CHECK-NEXT:    [[TMP28:%.*]] = extractelement <3 x i15> [[Y]], i64 1
; CHECK-NEXT:    [[TMP29:%.*]] = sext i15 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP30:%.*]] = sext i15 [[TMP28]] to i32
; CHECK-NEXT:    [[TMP31:%.*]] = xor i32 [[TMP29]], [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = ashr i32 [[TMP31]], 30
; CHECK-NEXT:    [[TMP33:%.*]] = or i32 [[TMP32]], 1
; CHECK-NEXT:    [[TMP34:%.*]] = sitofp i32 [[TMP29]] to float
; CHECK-NEXT:    [[TMP35:%.*]] = sitofp i32 [[TMP30]] to float
; CHECK-NEXT:    [[TMP36:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP37:%.*]] = fmul fast float [[TMP34]], [[TMP36]]
; CHECK-NEXT:    [[TMP38:%.*]] = call fast float @llvm.trunc.f32(float [[TMP37]])
; CHECK-NEXT:    [[TMP39:%.*]] = fneg fast float [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP39]], float [[TMP35]], float [[TMP34]])
; CHECK-NEXT:    [[TMP41:%.*]] = fptosi float [[TMP38]] to i32
; CHECK-NEXT:    [[TMP42:%.*]] = call fast float @llvm.fabs.f32(float [[TMP40]])
; CHECK-NEXT:    [[TMP43:%.*]] = call fast float @llvm.fabs.f32(float [[TMP35]])
; CHECK-NEXT:    [[TMP44:%.*]] = fcmp fast oge float [[TMP42]], [[TMP43]]
; CHECK-NEXT:    [[TMP45:%.*]] = select i1 [[TMP44]], i32 [[TMP33]], i32 0
; CHECK-NEXT:    [[TMP46:%.*]] = add i32 [[TMP41]], [[TMP45]]
; CHECK-NEXT:    [[TMP47:%.*]] = mul i32 [[TMP46]], [[TMP30]]
; CHECK-NEXT:    [[TMP48:%.*]] = sub i32 [[TMP29]], [[TMP47]]
; CHECK-NEXT:    [[TMP49:%.*]] = shl i32 [[TMP48]], 17
; CHECK-NEXT:    [[TMP50:%.*]] = ashr i32 [[TMP49]], 17
; CHECK-NEXT:    [[TMP51:%.*]] = trunc i32 [[TMP50]] to i15
; CHECK-NEXT:    [[TMP52:%.*]] = insertelement <3 x i15> [[TMP26]], i15 [[TMP51]], i64 1
; CHECK-NEXT:    [[TMP53:%.*]] = extractelement <3 x i15> [[X]], i64 2
; CHECK-NEXT:    [[TMP54:%.*]] = extractelement <3 x i15> [[Y]], i64 2
; CHECK-NEXT:    [[TMP55:%.*]] = sext i15 [[TMP53]] to i32
; CHECK-NEXT:    [[TMP56:%.*]] = sext i15 [[TMP54]] to i32
; CHECK-NEXT:    [[TMP57:%.*]] = xor i32 [[TMP55]], [[TMP56]]
; CHECK-NEXT:    [[TMP58:%.*]] = ashr i32 [[TMP57]], 30
; CHECK-NEXT:    [[TMP59:%.*]] = or i32 [[TMP58]], 1
; CHECK-NEXT:    [[TMP60:%.*]] = sitofp i32 [[TMP55]] to float
; CHECK-NEXT:    [[TMP61:%.*]] = sitofp i32 [[TMP56]] to float
; CHECK-NEXT:    [[TMP62:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP61]])
; CHECK-NEXT:    [[TMP63:%.*]] = fmul fast float [[TMP60]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = call fast float @llvm.trunc.f32(float [[TMP63]])
; CHECK-NEXT:    [[TMP65:%.*]] = fneg fast float [[TMP64]]
; CHECK-NEXT:    [[TMP66:%.*]] = call fast float @llvm.amdgcn.fmad.ftz.f32(float [[TMP65]], float [[TMP61]], float [[TMP60]])
; CHECK-NEXT:    [[TMP67:%.*]] = fptosi float [[TMP64]] to i32
; CHECK-NEXT:    [[TMP68:%.*]] = call fast float @llvm.fabs.f32(float [[TMP66]])
; CHECK-NEXT:    [[TMP69:%.*]] = call fast float @llvm.fabs.f32(float [[TMP61]])
; CHECK-NEXT:    [[TMP70:%.*]] = fcmp fast oge float [[TMP68]], [[TMP69]]
; CHECK-NEXT:    [[TMP71:%.*]] = select i1 [[TMP70]], i32 [[TMP59]], i32 0
; CHECK-NEXT:    [[TMP72:%.*]] = add i32 [[TMP67]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = mul i32 [[TMP72]], [[TMP56]]
; CHECK-NEXT:    [[TMP74:%.*]] = sub i32 [[TMP55]], [[TMP73]]
; CHECK-NEXT:    [[TMP75:%.*]] = shl i32 [[TMP74]], 17
; CHECK-NEXT:    [[TMP76:%.*]] = ashr i32 [[TMP75]], 17
; CHECK-NEXT:    [[TMP77:%.*]] = trunc i32 [[TMP76]] to i15
; CHECK-NEXT:    [[TMP78:%.*]] = insertelement <3 x i15> [[TMP52]], i15 [[TMP77]], i64 2
; CHECK-NEXT:    store <3 x i15> [[TMP78]], <3 x i15> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v3i15:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_mov_b32_e32 v1, s0
; GCN-NEXT:    v_alignbit_b32 v0, s3, v0, 30
; GCN-NEXT:    s_movk_i32 s3, 0x7fff
; GCN-NEXT:    v_alignbit_b32 v1, s1, v1, 30
; GCN-NEXT:    s_and_b32 s1, s0, s3
; GCN-NEXT:    s_bfe_i32 s1, s1, 0xf0000
; GCN-NEXT:    v_cvt_f32_i32_e32 v2, s1
; GCN-NEXT:    s_and_b32 s8, s2, s3
; GCN-NEXT:    s_bfe_i32 s8, s8, 0xf0000
; GCN-NEXT:    v_cvt_f32_i32_e32 v3, s8
; GCN-NEXT:    v_rcp_iflag_f32_e32 v4, v2
; GCN-NEXT:    s_xor_b32 s1, s8, s1
; GCN-NEXT:    s_ashr_i32 s1, s1, 30
; GCN-NEXT:    s_lshr_b32 s10, s2, 15
; GCN-NEXT:    v_mul_f32_e32 v4, v3, v4
; GCN-NEXT:    v_trunc_f32_e32 v4, v4
; GCN-NEXT:    v_mad_f32 v3, -v4, v2, v3
; GCN-NEXT:    v_cvt_i32_f32_e32 v4, v4
; GCN-NEXT:    s_bfe_u32 s11, s2, 0xf000f
; GCN-NEXT:    s_lshr_b32 s12, s0, 15
; GCN-NEXT:    s_bfe_u32 s13, s0, 0xf000f
; GCN-NEXT:    s_or_b32 s1, s1, 1
; GCN-NEXT:    v_cmp_ge_f32_e64 s[8:9], |v3|, |v2|
; GCN-NEXT:    s_cmp_lg_u64 s[8:9], 0
; GCN-NEXT:    s_cselect_b32 s1, s1, 0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, s1, v4
; GCN-NEXT:    v_mul_lo_u32 v2, v2, s0
; GCN-NEXT:    s_bfe_i32 s0, s13, 0xf0000
; GCN-NEXT:    v_cvt_f32_i32_e32 v3, s0
; GCN-NEXT:    s_bfe_i32 s1, s11, 0xf0000
; GCN-NEXT:    v_cvt_f32_i32_e32 v4, s1
; GCN-NEXT:    s_xor_b32 s0, s1, s0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v5, v3
; GCN-NEXT:    s_ashr_i32 s0, s0, 30
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s2, v2
; GCN-NEXT:    s_or_b32 s2, s0, 1
; GCN-NEXT:    v_mul_f32_e32 v5, v4, v5
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_mad_f32 v4, -v5, v3, v4
; GCN-NEXT:    v_cvt_i32_f32_e32 v5, v5
; GCN-NEXT:    v_cmp_ge_f32_e64 s[0:1], |v4|, |v3|
; GCN-NEXT:    s_cmp_lg_u64 s[0:1], 0
; GCN-NEXT:    v_and_b32_e32 v1, s3, v1
; GCN-NEXT:    s_cselect_b32 s0, s2, 0
; GCN-NEXT:    v_bfe_i32 v4, v1, 0, 15
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s0, v5
; GCN-NEXT:    v_cvt_f32_i32_e32 v5, v4
; GCN-NEXT:    v_and_b32_e32 v0, s3, v0
; GCN-NEXT:    v_bfe_i32 v6, v0, 0, 15
; GCN-NEXT:    v_cvt_f32_i32_e32 v7, v6
; GCN-NEXT:    v_rcp_iflag_f32_e32 v8, v5
; GCN-NEXT:    v_xor_b32_e32 v4, v6, v4
; GCN-NEXT:    v_ashrrev_i32_e32 v4, 30, v4
; GCN-NEXT:    v_or_b32_e32 v4, 1, v4
; GCN-NEXT:    v_mul_f32_e32 v6, v7, v8
; GCN-NEXT:    v_trunc_f32_e32 v6, v6
; GCN-NEXT:    v_mad_f32 v7, -v6, v5, v7
; GCN-NEXT:    v_cvt_i32_f32_e32 v6, v6
; GCN-NEXT:    v_cmp_ge_f32_e64 vcc, |v7|, |v5|
; GCN-NEXT:    v_cndmask_b32_e32 v4, 0, v4, vcc
; GCN-NEXT:    v_mul_lo_u32 v3, v3, s12
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v6, v4
; GCN-NEXT:    v_mul_lo_u32 v1, v4, v1
; GCN-NEXT:    v_and_b32_e32 v2, s3, v2
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s10, v3
; GCN-NEXT:    v_and_b32_e32 v3, s3, v3
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_lshl_b64 v[0:1], v[0:1], 30
; GCN-NEXT:    v_lshlrev_b32_e32 v3, 15, v3
; GCN-NEXT:    v_or_b32_e32 v2, v2, v3
; GCN-NEXT:    v_or_b32_e32 v0, v2, v0
; GCN-NEXT:    v_and_b32_e32 v1, 0x1fff, v1
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    buffer_store_short v1, off, s[4:7], 0 offset:4
; GCN-NEXT:    s_endpgm
  %r = srem <3 x i15> %x, %y
  store <3 x i15> %r, <3 x i15> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i32_oddk_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @udiv_i32_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = udiv i32 [[X:%.*]], 1235195
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i32_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    v_mov_b32_e32 v0, 0xb2a50881
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_u32 v0, s0, v0
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s0, v0
; GCN-NEXT:    v_lshrrev_b32_e32 v1, 1, v1
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_lshrrev_b32_e32 v0, 20, v0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i32 %x, 1235195
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i32_pow2k_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @udiv_i32_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = udiv i32 [[X:%.*]], 4096
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshr_b32 s0, s0, 12
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i32 %x, 4096
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i32_pow2_shl_denom(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @udiv_i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i32 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = udiv i32 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_add_i32 s1, s1, 12
; GCN-NEXT:    s_lshr_b32 s0, s0, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i32 4096, %y
  %r = udiv i32 %x, %shl.y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v2i32_pow2k_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x) {
; CHECK-LABEL: @udiv_v2i32_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = udiv i32 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> undef, i32 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = udiv i32 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v2i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshr_b32 s0, s0, 12
; GCN-NEXT:    s_lshr_b32 s1, s1, 12
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv <2 x i32> %x, <i32 4096, i32 4096>
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v2i32_mixed_pow2k_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x) {
; CHECK-LABEL: @udiv_v2i32_mixed_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = udiv i32 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> undef, i32 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = udiv i32 [[TMP4]], 4095
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v2i32_mixed_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    v_mov_b32_e32 v0, 0x100101
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_u32 v0, s1, v0
; GCN-NEXT:    s_lshr_b32 s0, s0, 12
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s1, v0
; GCN-NEXT:    v_lshrrev_b32_e32 v1, 1, v1
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_lshrrev_b32_e32 v1, 11, v0
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv <2 x i32> %x, <i32 4096, i32 4095>
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v2i32_pow2_shl_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x, <2 x i32> %y) {
; CHECK-LABEL: @udiv_v2i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i32> <i32 4096, i32 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP3]])
; CHECK-NEXT:    [[TMP5:%.*]] = fmul fast float [[TMP4]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP6:%.*]] = fptoui float [[TMP5]] to i32
; CHECK-NEXT:    [[TMP7:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP2]] to i64
; CHECK-NEXT:    [[TMP9:%.*]] = mul i64 [[TMP7]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = trunc i64 [[TMP9]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = lshr i64 [[TMP9]], 32
; CHECK-NEXT:    [[TMP12:%.*]] = trunc i64 [[TMP11]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = sub i32 0, [[TMP10]]
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], 0
; CHECK-NEXT:    [[TMP15:%.*]] = select i1 [[TMP14]], i32 [[TMP13]], i32 [[TMP10]]
; CHECK-NEXT:    [[TMP16:%.*]] = zext i32 [[TMP15]] to i64
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP18:%.*]] = mul i64 [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = lshr i64 [[TMP18]], 32
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i64 [[TMP20]] to i32
; CHECK-NEXT:    [[TMP22:%.*]] = add i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = sub i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP24:%.*]] = select i1 [[TMP14]], i32 [[TMP22]], i32 [[TMP23]]
; CHECK-NEXT:    [[TMP25:%.*]] = zext i32 [[TMP24]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    [[TMP27:%.*]] = mul i64 [[TMP25]], [[TMP26]]
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = lshr i64 [[TMP27]], 32
; CHECK-NEXT:    [[TMP30:%.*]] = trunc i64 [[TMP29]] to i32
; CHECK-NEXT:    [[TMP31:%.*]] = mul i32 [[TMP30]], [[TMP2]]
; CHECK-NEXT:    [[TMP32:%.*]] = sub i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = icmp uge i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP34:%.*]] = icmp uge i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP35:%.*]] = and i1 [[TMP33]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = add i32 [[TMP30]], 1
; CHECK-NEXT:    [[TMP37:%.*]] = sub i32 [[TMP30]], 1
; CHECK-NEXT:    [[TMP38:%.*]] = select i1 [[TMP35]], i32 [[TMP36]], i32 [[TMP30]]
; CHECK-NEXT:    [[TMP39:%.*]] = select i1 [[TMP34]], i32 [[TMP38]], i32 [[TMP37]]
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <2 x i32> undef, i32 [[TMP39]], i64 0
; CHECK-NEXT:    [[TMP41:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP43:%.*]] = uitofp i32 [[TMP42]] to float
; CHECK-NEXT:    [[TMP44:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP43]])
; CHECK-NEXT:    [[TMP45:%.*]] = fmul fast float [[TMP44]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP46:%.*]] = fptoui float [[TMP45]] to i32
; CHECK-NEXT:    [[TMP47:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP48:%.*]] = zext i32 [[TMP42]] to i64
; CHECK-NEXT:    [[TMP49:%.*]] = mul i64 [[TMP47]], [[TMP48]]
; CHECK-NEXT:    [[TMP50:%.*]] = trunc i64 [[TMP49]] to i32
; CHECK-NEXT:    [[TMP51:%.*]] = lshr i64 [[TMP49]], 32
; CHECK-NEXT:    [[TMP52:%.*]] = trunc i64 [[TMP51]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = sub i32 0, [[TMP50]]
; CHECK-NEXT:    [[TMP54:%.*]] = icmp eq i32 [[TMP52]], 0
; CHECK-NEXT:    [[TMP55:%.*]] = select i1 [[TMP54]], i32 [[TMP53]], i32 [[TMP50]]
; CHECK-NEXT:    [[TMP56:%.*]] = zext i32 [[TMP55]] to i64
; CHECK-NEXT:    [[TMP57:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP58:%.*]] = mul i64 [[TMP56]], [[TMP57]]
; CHECK-NEXT:    [[TMP59:%.*]] = trunc i64 [[TMP58]] to i32
; CHECK-NEXT:    [[TMP60:%.*]] = lshr i64 [[TMP58]], 32
; CHECK-NEXT:    [[TMP61:%.*]] = trunc i64 [[TMP60]] to i32
; CHECK-NEXT:    [[TMP62:%.*]] = add i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP64:%.*]] = select i1 [[TMP54]], i32 [[TMP62]], i32 [[TMP63]]
; CHECK-NEXT:    [[TMP65:%.*]] = zext i32 [[TMP64]] to i64
; CHECK-NEXT:    [[TMP66:%.*]] = zext i32 [[TMP41]] to i64
; CHECK-NEXT:    [[TMP67:%.*]] = mul i64 [[TMP65]], [[TMP66]]
; CHECK-NEXT:    [[TMP68:%.*]] = trunc i64 [[TMP67]] to i32
; CHECK-NEXT:    [[TMP69:%.*]] = lshr i64 [[TMP67]], 32
; CHECK-NEXT:    [[TMP70:%.*]] = trunc i64 [[TMP69]] to i32
; CHECK-NEXT:    [[TMP71:%.*]] = mul i32 [[TMP70]], [[TMP42]]
; CHECK-NEXT:    [[TMP72:%.*]] = sub i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = icmp uge i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP74:%.*]] = icmp uge i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP75:%.*]] = and i1 [[TMP73]], [[TMP74]]
; CHECK-NEXT:    [[TMP76:%.*]] = add i32 [[TMP70]], 1
; CHECK-NEXT:    [[TMP77:%.*]] = sub i32 [[TMP70]], 1
; CHECK-NEXT:    [[TMP78:%.*]] = select i1 [[TMP75]], i32 [[TMP76]], i32 [[TMP70]]
; CHECK-NEXT:    [[TMP79:%.*]] = select i1 [[TMP74]], i32 [[TMP78]], i32 [[TMP77]]
; CHECK-NEXT:    [[TMP80:%.*]] = insertelement <2 x i32> [[TMP40]], i32 [[TMP79]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP80]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v2i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xd
; GCN-NEXT:    s_movk_i32 s4, 0x1000
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b32 s2, s4, s2
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s2
; GCN-NEXT:    s_lshl_b32 s10, s4, s3
; GCN-NEXT:    s_mov_b32 s3, 0x4f800000
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s10
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0xb
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v1
; GCN-NEXT:    v_mul_f32_e32 v0, s3, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_f32_e32 v1, s3, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s2
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s2
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v2
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v0
; GCN-NEXT:    v_mul_lo_u32 v3, v1, s10
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v2, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v2, v0
; GCN-NEXT:    v_mul_hi_u32 v2, v1, s10
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v4, s[0:1]
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v3
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s8
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v3, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v1
; GCN-NEXT:    v_mul_lo_u32 v5, v0, s2
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v2, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s9
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s8, v5
; GCN-NEXT:    v_cmp_le_u32_e64 s[2:3], s2, v3
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v0
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s10
; GCN-NEXT:    v_cmp_ge_u32_e64 s[0:1], s8, v5
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v0
; GCN-NEXT:    s_and_b64 vcc, s[2:3], s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s9, v4
; GCN-NEXT:    v_cndmask_b32_e64 v0, v3, v0, s[0:1]
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s10, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, -1, v1
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s9, v4
; GCN-NEXT:    v_add_i32_e32 v3, vcc, 1, v1
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v3, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v1, v2, v1, s[2:3]
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i32> <i32 4096, i32 4096>, %y
  %r = udiv <2 x i32> %x, %shl.y
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i32_oddk_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @urem_i32_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = urem i32 [[X:%.*]], 1235195
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i32_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    v_mov_b32_e32 v0, 0xb2a50881
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_u32 v0, s0, v0
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s0, v0
; GCN-NEXT:    v_lshrrev_b32_e32 v1, 1, v1
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_lshrrev_b32_e32 v0, 20, v0
; GCN-NEXT:    v_mul_u32_u24_e32 v0, 0x12d8fb, v0
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem i32 %x, 1235195
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i32_pow2k_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @urem_i32_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = urem i32 [[X:%.*]], 4096
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_and_b32 s0, s0, 0xfff
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem i32 %x, 4096
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i32_pow2_shl_denom(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @urem_i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i32 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = urem i32 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b32 s1, 0x1000, s1
; GCN-NEXT:    s_add_i32 s1, s1, -1
; GCN-NEXT:    s_and_b32 s0, s0, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i32 4096, %y
  %r = urem i32 %x, %shl.y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v2i32_pow2k_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x) {
; CHECK-LABEL: @urem_v2i32_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = urem i32 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> undef, i32 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = urem i32 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v2i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_movk_i32 s2, 0xfff
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_and_b32 s0, s0, s2
; GCN-NEXT:    s_and_b32 s1, s1, s2
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem <2 x i32> %x, <i32 4096, i32 4096>
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v2i32_pow2_shl_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x, <2 x i32> %y) {
; CHECK-LABEL: @urem_v2i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i32> <i32 4096, i32 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = uitofp i32 [[TMP2]] to float
; CHECK-NEXT:    [[TMP4:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP3]])
; CHECK-NEXT:    [[TMP5:%.*]] = fmul fast float [[TMP4]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP6:%.*]] = fptoui float [[TMP5]] to i32
; CHECK-NEXT:    [[TMP7:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP8:%.*]] = zext i32 [[TMP2]] to i64
; CHECK-NEXT:    [[TMP9:%.*]] = mul i64 [[TMP7]], [[TMP8]]
; CHECK-NEXT:    [[TMP10:%.*]] = trunc i64 [[TMP9]] to i32
; CHECK-NEXT:    [[TMP11:%.*]] = lshr i64 [[TMP9]], 32
; CHECK-NEXT:    [[TMP12:%.*]] = trunc i64 [[TMP11]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = sub i32 0, [[TMP10]]
; CHECK-NEXT:    [[TMP14:%.*]] = icmp eq i32 [[TMP12]], 0
; CHECK-NEXT:    [[TMP15:%.*]] = select i1 [[TMP14]], i32 [[TMP13]], i32 [[TMP10]]
; CHECK-NEXT:    [[TMP16:%.*]] = zext i32 [[TMP15]] to i64
; CHECK-NEXT:    [[TMP17:%.*]] = zext i32 [[TMP6]] to i64
; CHECK-NEXT:    [[TMP18:%.*]] = mul i64 [[TMP16]], [[TMP17]]
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = lshr i64 [[TMP18]], 32
; CHECK-NEXT:    [[TMP21:%.*]] = trunc i64 [[TMP20]] to i32
; CHECK-NEXT:    [[TMP22:%.*]] = add i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP23:%.*]] = sub i32 [[TMP6]], [[TMP21]]
; CHECK-NEXT:    [[TMP24:%.*]] = select i1 [[TMP14]], i32 [[TMP22]], i32 [[TMP23]]
; CHECK-NEXT:    [[TMP25:%.*]] = zext i32 [[TMP24]] to i64
; CHECK-NEXT:    [[TMP26:%.*]] = zext i32 [[TMP1]] to i64
; CHECK-NEXT:    [[TMP27:%.*]] = mul i64 [[TMP25]], [[TMP26]]
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = lshr i64 [[TMP27]], 32
; CHECK-NEXT:    [[TMP30:%.*]] = trunc i64 [[TMP29]] to i32
; CHECK-NEXT:    [[TMP31:%.*]] = mul i32 [[TMP30]], [[TMP2]]
; CHECK-NEXT:    [[TMP32:%.*]] = sub i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP33:%.*]] = icmp uge i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP34:%.*]] = icmp uge i32 [[TMP1]], [[TMP31]]
; CHECK-NEXT:    [[TMP35:%.*]] = and i1 [[TMP33]], [[TMP34]]
; CHECK-NEXT:    [[TMP36:%.*]] = sub i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP37:%.*]] = add i32 [[TMP32]], [[TMP2]]
; CHECK-NEXT:    [[TMP38:%.*]] = select i1 [[TMP35]], i32 [[TMP36]], i32 [[TMP32]]
; CHECK-NEXT:    [[TMP39:%.*]] = select i1 [[TMP34]], i32 [[TMP38]], i32 [[TMP37]]
; CHECK-NEXT:    [[TMP40:%.*]] = insertelement <2 x i32> undef, i32 [[TMP39]], i64 0
; CHECK-NEXT:    [[TMP41:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP42:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP43:%.*]] = uitofp i32 [[TMP42]] to float
; CHECK-NEXT:    [[TMP44:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP43]])
; CHECK-NEXT:    [[TMP45:%.*]] = fmul fast float [[TMP44]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP46:%.*]] = fptoui float [[TMP45]] to i32
; CHECK-NEXT:    [[TMP47:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP48:%.*]] = zext i32 [[TMP42]] to i64
; CHECK-NEXT:    [[TMP49:%.*]] = mul i64 [[TMP47]], [[TMP48]]
; CHECK-NEXT:    [[TMP50:%.*]] = trunc i64 [[TMP49]] to i32
; CHECK-NEXT:    [[TMP51:%.*]] = lshr i64 [[TMP49]], 32
; CHECK-NEXT:    [[TMP52:%.*]] = trunc i64 [[TMP51]] to i32
; CHECK-NEXT:    [[TMP53:%.*]] = sub i32 0, [[TMP50]]
; CHECK-NEXT:    [[TMP54:%.*]] = icmp eq i32 [[TMP52]], 0
; CHECK-NEXT:    [[TMP55:%.*]] = select i1 [[TMP54]], i32 [[TMP53]], i32 [[TMP50]]
; CHECK-NEXT:    [[TMP56:%.*]] = zext i32 [[TMP55]] to i64
; CHECK-NEXT:    [[TMP57:%.*]] = zext i32 [[TMP46]] to i64
; CHECK-NEXT:    [[TMP58:%.*]] = mul i64 [[TMP56]], [[TMP57]]
; CHECK-NEXT:    [[TMP59:%.*]] = trunc i64 [[TMP58]] to i32
; CHECK-NEXT:    [[TMP60:%.*]] = lshr i64 [[TMP58]], 32
; CHECK-NEXT:    [[TMP61:%.*]] = trunc i64 [[TMP60]] to i32
; CHECK-NEXT:    [[TMP62:%.*]] = add i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP63:%.*]] = sub i32 [[TMP46]], [[TMP61]]
; CHECK-NEXT:    [[TMP64:%.*]] = select i1 [[TMP54]], i32 [[TMP62]], i32 [[TMP63]]
; CHECK-NEXT:    [[TMP65:%.*]] = zext i32 [[TMP64]] to i64
; CHECK-NEXT:    [[TMP66:%.*]] = zext i32 [[TMP41]] to i64
; CHECK-NEXT:    [[TMP67:%.*]] = mul i64 [[TMP65]], [[TMP66]]
; CHECK-NEXT:    [[TMP68:%.*]] = trunc i64 [[TMP67]] to i32
; CHECK-NEXT:    [[TMP69:%.*]] = lshr i64 [[TMP67]], 32
; CHECK-NEXT:    [[TMP70:%.*]] = trunc i64 [[TMP69]] to i32
; CHECK-NEXT:    [[TMP71:%.*]] = mul i32 [[TMP70]], [[TMP42]]
; CHECK-NEXT:    [[TMP72:%.*]] = sub i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = icmp uge i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP74:%.*]] = icmp uge i32 [[TMP41]], [[TMP71]]
; CHECK-NEXT:    [[TMP75:%.*]] = and i1 [[TMP73]], [[TMP74]]
; CHECK-NEXT:    [[TMP76:%.*]] = sub i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP77:%.*]] = add i32 [[TMP72]], [[TMP42]]
; CHECK-NEXT:    [[TMP78:%.*]] = select i1 [[TMP75]], i32 [[TMP76]], i32 [[TMP72]]
; CHECK-NEXT:    [[TMP79:%.*]] = select i1 [[TMP74]], i32 [[TMP78]], i32 [[TMP77]]
; CHECK-NEXT:    [[TMP80:%.*]] = insertelement <2 x i32> [[TMP40]], i32 [[TMP79]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP80]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v2i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xd
; GCN-NEXT:    s_movk_i32 s4, 0x1000
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b32 s10, s4, s2
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s10
; GCN-NEXT:    s_mov_b32 s2, 0x4f800000
; GCN-NEXT:    s_lshl_b32 s11, s4, s3
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s11
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0xb
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v1
; GCN-NEXT:    v_mul_f32_e32 v0, s2, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_f32_e32 v1, s2, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s10
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s10
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v2
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v3
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v0
; GCN-NEXT:    v_mul_lo_u32 v3, v1, s11
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v2, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v2, v0
; GCN-NEXT:    v_mul_hi_u32 v2, v1, s11
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v4, s[0:1]
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, 0, v3
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s8
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v3, v4, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v2, v2, v1
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s10
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v2, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v5, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s9
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s8, v0
; GCN-NEXT:    v_cmp_ge_u32_e64 s[0:1], s8, v0
; GCN-NEXT:    v_cmp_le_u32_e64 s[2:3], s10, v3
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s11
; GCN-NEXT:    v_add_i32_e32 v4, vcc, s10, v3
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s10, v3
; GCN-NEXT:    s_and_b64 vcc, s[2:3], s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v3, v0, vcc
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s9, v1
; GCN-NEXT:    v_cndmask_b32_e64 v0, v4, v0, s[0:1]
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s9, v1
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s11, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s11, v2
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, s11, v2
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v2, v1, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v1, v3, v1, s[2:3]
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i32> <i32 4096, i32 4096>, %y
  %r = urem <2 x i32> %x, %shl.y
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i32_oddk_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @sdiv_i32_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = sdiv i32 [[X:%.*]], 1235195
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i32_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    v_mov_b32_e32 v0, 0xd9528441
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_i32 v0, s0, v0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    v_lshrrev_b32_e32 v1, 31, v0
; GCN-NEXT:    v_ashrrev_i32_e32 v0, 20, v0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i32 %x, 1235195
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i32_pow2k_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @sdiv_i32_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = sdiv i32 [[X:%.*]], 4096
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s1, s0, 31
; GCN-NEXT:    s_lshr_b32 s1, s1, 20
; GCN-NEXT:    s_add_i32 s0, s0, s1
; GCN-NEXT:    s_ashr_i32 s0, s0, 12
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i32 %x, 4096
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i32_pow2_shl_denom(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @sdiv_i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i32 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = sdiv i32 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b32 s3, 0x1000, s3
; GCN-NEXT:    s_ashr_i32 s8, s3, 31
; GCN-NEXT:    s_add_i32 s3, s3, s8
; GCN-NEXT:    s_xor_b32 s9, s3, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s9
; GCN-NEXT:    s_ashr_i32 s3, s2, 31
; GCN-NEXT:    s_add_i32 s2, s2, s3
; GCN-NEXT:    s_xor_b32 s2, s2, s3
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_xor_b32 s3, s3, s8
; GCN-NEXT:    v_mul_f32_e32 v0, 0x4f800000, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s9
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s9
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s2
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s9
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v0
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v0
; GCN-NEXT:    v_cmp_ge_u32_e64 s[0:1], s2, v1
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s2, v1
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s9, v1
; GCN-NEXT:    s_and_b64 vcc, vcc, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v3, v0, s[0:1]
; GCN-NEXT:    v_xor_b32_e32 v0, s3, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s3, v0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i32 4096, %y
  %r = sdiv i32 %x, %shl.y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v2i32_pow2k_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x) {
; CHECK-LABEL: @sdiv_v2i32_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = sdiv i32 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> undef, i32 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = sdiv i32 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v2i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s2, s0, 31
; GCN-NEXT:    s_lshr_b32 s2, s2, 20
; GCN-NEXT:    s_ashr_i32 s3, s1, 31
; GCN-NEXT:    s_add_i32 s0, s0, s2
; GCN-NEXT:    s_lshr_b32 s2, s3, 20
; GCN-NEXT:    s_add_i32 s1, s1, s2
; GCN-NEXT:    s_ashr_i32 s0, s0, 12
; GCN-NEXT:    s_ashr_i32 s1, s1, 12
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv <2 x i32> %x, <i32 4096, i32 4096>
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @ssdiv_v2i32_mixed_pow2k_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x) {
; CHECK-LABEL: @ssdiv_v2i32_mixed_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = sdiv i32 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> undef, i32 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = sdiv i32 [[TMP4]], 4095
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: ssdiv_v2i32_mixed_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    v_mov_b32_e32 v0, 0x80080081
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_i32 v0, s1, v0
; GCN-NEXT:    s_ashr_i32 s2, s0, 31
; GCN-NEXT:    s_lshr_b32 s2, s2, 20
; GCN-NEXT:    s_add_i32 s0, s0, s2
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s1, v0
; GCN-NEXT:    v_lshrrev_b32_e32 v1, 31, v0
; GCN-NEXT:    v_ashrrev_i32_e32 v0, 11, v0
; GCN-NEXT:    s_ashr_i32 s0, s0, 12
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v0
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv <2 x i32> %x, <i32 4096, i32 4095>
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v2i32_pow2_shl_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x, <2 x i32> %y) {
; CHECK-LABEL: @sdiv_v2i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i32> <i32 4096, i32 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = ashr i32 [[TMP1]], 31
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP2]], 31
; CHECK-NEXT:    [[TMP5:%.*]] = xor i32 [[TMP3]], [[TMP4]]
; CHECK-NEXT:    [[TMP6:%.*]] = add i32 [[TMP1]], [[TMP3]]
; CHECK-NEXT:    [[TMP7:%.*]] = add i32 [[TMP2]], [[TMP4]]
; CHECK-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP3]]
; CHECK-NEXT:    [[TMP9:%.*]] = xor i32 [[TMP7]], [[TMP4]]
; CHECK-NEXT:    [[TMP10:%.*]] = uitofp i32 [[TMP9]] to float
; CHECK-NEXT:    [[TMP11:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP10]])
; CHECK-NEXT:    [[TMP12:%.*]] = fmul fast float [[TMP11]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP13:%.*]] = fptoui float [[TMP12]] to i32
; CHECK-NEXT:    [[TMP14:%.*]] = zext i32 [[TMP13]] to i64
; CHECK-NEXT:    [[TMP15:%.*]] = zext i32 [[TMP9]] to i64
; CHECK-NEXT:    [[TMP16:%.*]] = mul i64 [[TMP14]], [[TMP15]]
; CHECK-NEXT:    [[TMP17:%.*]] = trunc i64 [[TMP16]] to i32
; CHECK-NEXT:    [[TMP18:%.*]] = lshr i64 [[TMP16]], 32
; CHECK-NEXT:    [[TMP19:%.*]] = trunc i64 [[TMP18]] to i32
; CHECK-NEXT:    [[TMP20:%.*]] = sub i32 0, [[TMP17]]
; CHECK-NEXT:    [[TMP21:%.*]] = icmp eq i32 [[TMP19]], 0
; CHECK-NEXT:    [[TMP22:%.*]] = select i1 [[TMP21]], i32 [[TMP20]], i32 [[TMP17]]
; CHECK-NEXT:    [[TMP23:%.*]] = zext i32 [[TMP22]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = zext i32 [[TMP13]] to i64
; CHECK-NEXT:    [[TMP25:%.*]] = mul i64 [[TMP23]], [[TMP24]]
; CHECK-NEXT:    [[TMP26:%.*]] = trunc i64 [[TMP25]] to i32
; CHECK-NEXT:    [[TMP27:%.*]] = lshr i64 [[TMP25]], 32
; CHECK-NEXT:    [[TMP28:%.*]] = trunc i64 [[TMP27]] to i32
; CHECK-NEXT:    [[TMP29:%.*]] = add i32 [[TMP13]], [[TMP28]]
; CHECK-NEXT:    [[TMP30:%.*]] = sub i32 [[TMP13]], [[TMP28]]
; CHECK-NEXT:    [[TMP31:%.*]] = select i1 [[TMP21]], i32 [[TMP29]], i32 [[TMP30]]
; CHECK-NEXT:    [[TMP32:%.*]] = zext i32 [[TMP31]] to i64
; CHECK-NEXT:    [[TMP33:%.*]] = zext i32 [[TMP8]] to i64
; CHECK-NEXT:    [[TMP34:%.*]] = mul i64 [[TMP32]], [[TMP33]]
; CHECK-NEXT:    [[TMP35:%.*]] = trunc i64 [[TMP34]] to i32
; CHECK-NEXT:    [[TMP36:%.*]] = lshr i64 [[TMP34]], 32
; CHECK-NEXT:    [[TMP37:%.*]] = trunc i64 [[TMP36]] to i32
; CHECK-NEXT:    [[TMP38:%.*]] = mul i32 [[TMP37]], [[TMP9]]
; CHECK-NEXT:    [[TMP39:%.*]] = sub i32 [[TMP8]], [[TMP38]]
; CHECK-NEXT:    [[TMP40:%.*]] = icmp uge i32 [[TMP39]], [[TMP9]]
; CHECK-NEXT:    [[TMP41:%.*]] = icmp uge i32 [[TMP8]], [[TMP38]]
; CHECK-NEXT:    [[TMP42:%.*]] = and i1 [[TMP40]], [[TMP41]]
; CHECK-NEXT:    [[TMP43:%.*]] = add i32 [[TMP37]], 1
; CHECK-NEXT:    [[TMP44:%.*]] = sub i32 [[TMP37]], 1
; CHECK-NEXT:    [[TMP45:%.*]] = select i1 [[TMP42]], i32 [[TMP43]], i32 [[TMP37]]
; CHECK-NEXT:    [[TMP46:%.*]] = select i1 [[TMP41]], i32 [[TMP45]], i32 [[TMP44]]
; CHECK-NEXT:    [[TMP47:%.*]] = xor i32 [[TMP46]], [[TMP5]]
; CHECK-NEXT:    [[TMP48:%.*]] = sub i32 [[TMP47]], [[TMP5]]
; CHECK-NEXT:    [[TMP49:%.*]] = insertelement <2 x i32> undef, i32 [[TMP48]], i64 0
; CHECK-NEXT:    [[TMP50:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP51:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP52:%.*]] = ashr i32 [[TMP50]], 31
; CHECK-NEXT:    [[TMP53:%.*]] = ashr i32 [[TMP51]], 31
; CHECK-NEXT:    [[TMP54:%.*]] = xor i32 [[TMP52]], [[TMP53]]
; CHECK-NEXT:    [[TMP55:%.*]] = add i32 [[TMP50]], [[TMP52]]
; CHECK-NEXT:    [[TMP56:%.*]] = add i32 [[TMP51]], [[TMP53]]
; CHECK-NEXT:    [[TMP57:%.*]] = xor i32 [[TMP55]], [[TMP52]]
; CHECK-NEXT:    [[TMP58:%.*]] = xor i32 [[TMP56]], [[TMP53]]
; CHECK-NEXT:    [[TMP59:%.*]] = uitofp i32 [[TMP58]] to float
; CHECK-NEXT:    [[TMP60:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP59]])
; CHECK-NEXT:    [[TMP61:%.*]] = fmul fast float [[TMP60]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP62:%.*]] = fptoui float [[TMP61]] to i32
; CHECK-NEXT:    [[TMP63:%.*]] = zext i32 [[TMP62]] to i64
; CHECK-NEXT:    [[TMP64:%.*]] = zext i32 [[TMP58]] to i64
; CHECK-NEXT:    [[TMP65:%.*]] = mul i64 [[TMP63]], [[TMP64]]
; CHECK-NEXT:    [[TMP66:%.*]] = trunc i64 [[TMP65]] to i32
; CHECK-NEXT:    [[TMP67:%.*]] = lshr i64 [[TMP65]], 32
; CHECK-NEXT:    [[TMP68:%.*]] = trunc i64 [[TMP67]] to i32
; CHECK-NEXT:    [[TMP69:%.*]] = sub i32 0, [[TMP66]]
; CHECK-NEXT:    [[TMP70:%.*]] = icmp eq i32 [[TMP68]], 0
; CHECK-NEXT:    [[TMP71:%.*]] = select i1 [[TMP70]], i32 [[TMP69]], i32 [[TMP66]]
; CHECK-NEXT:    [[TMP72:%.*]] = zext i32 [[TMP71]] to i64
; CHECK-NEXT:    [[TMP73:%.*]] = zext i32 [[TMP62]] to i64
; CHECK-NEXT:    [[TMP74:%.*]] = mul i64 [[TMP72]], [[TMP73]]
; CHECK-NEXT:    [[TMP75:%.*]] = trunc i64 [[TMP74]] to i32
; CHECK-NEXT:    [[TMP76:%.*]] = lshr i64 [[TMP74]], 32
; CHECK-NEXT:    [[TMP77:%.*]] = trunc i64 [[TMP76]] to i32
; CHECK-NEXT:    [[TMP78:%.*]] = add i32 [[TMP62]], [[TMP77]]
; CHECK-NEXT:    [[TMP79:%.*]] = sub i32 [[TMP62]], [[TMP77]]
; CHECK-NEXT:    [[TMP80:%.*]] = select i1 [[TMP70]], i32 [[TMP78]], i32 [[TMP79]]
; CHECK-NEXT:    [[TMP81:%.*]] = zext i32 [[TMP80]] to i64
; CHECK-NEXT:    [[TMP82:%.*]] = zext i32 [[TMP57]] to i64
; CHECK-NEXT:    [[TMP83:%.*]] = mul i64 [[TMP81]], [[TMP82]]
; CHECK-NEXT:    [[TMP84:%.*]] = trunc i64 [[TMP83]] to i32
; CHECK-NEXT:    [[TMP85:%.*]] = lshr i64 [[TMP83]], 32
; CHECK-NEXT:    [[TMP86:%.*]] = trunc i64 [[TMP85]] to i32
; CHECK-NEXT:    [[TMP87:%.*]] = mul i32 [[TMP86]], [[TMP58]]
; CHECK-NEXT:    [[TMP88:%.*]] = sub i32 [[TMP57]], [[TMP87]]
; CHECK-NEXT:    [[TMP89:%.*]] = icmp uge i32 [[TMP88]], [[TMP58]]
; CHECK-NEXT:    [[TMP90:%.*]] = icmp uge i32 [[TMP57]], [[TMP87]]
; CHECK-NEXT:    [[TMP91:%.*]] = and i1 [[TMP89]], [[TMP90]]
; CHECK-NEXT:    [[TMP92:%.*]] = add i32 [[TMP86]], 1
; CHECK-NEXT:    [[TMP93:%.*]] = sub i32 [[TMP86]], 1
; CHECK-NEXT:    [[TMP94:%.*]] = select i1 [[TMP91]], i32 [[TMP92]], i32 [[TMP86]]
; CHECK-NEXT:    [[TMP95:%.*]] = select i1 [[TMP90]], i32 [[TMP94]], i32 [[TMP93]]
; CHECK-NEXT:    [[TMP96:%.*]] = xor i32 [[TMP95]], [[TMP54]]
; CHECK-NEXT:    [[TMP97:%.*]] = sub i32 [[TMP96]], [[TMP54]]
; CHECK-NEXT:    [[TMP98:%.*]] = insertelement <2 x i32> [[TMP49]], i32 [[TMP97]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP98]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v2i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xd
; GCN-NEXT:    s_movk_i32 s4, 0x1000
; GCN-NEXT:    s_mov_b32 s14, 0x4f800000
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[6:7], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b32 s2, s4, s2
; GCN-NEXT:    s_ashr_i32 s5, s2, 31
; GCN-NEXT:    s_add_i32 s2, s2, s5
; GCN-NEXT:    s_xor_b32 s13, s2, s5
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s13
; GCN-NEXT:    s_ashr_i32 s2, s6, 31
; GCN-NEXT:    s_lshl_b32 s0, s4, s3
; GCN-NEXT:    s_add_i32 s1, s6, s2
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_ashr_i32 s6, s0, 31
; GCN-NEXT:    s_add_i32 s4, s0, s6
; GCN-NEXT:    s_xor_b32 s3, s1, s2
; GCN-NEXT:    v_mul_f32_e32 v0, s14, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    s_xor_b32 s15, s4, s6
; GCN-NEXT:    s_xor_b32 s12, s2, s5
; GCN-NEXT:    s_mov_b32 s10, -1
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s13
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s13
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[0:1], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s15
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v3, s[0:1]
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v2
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s3
; GCN-NEXT:    v_mul_f32_e32 v1, s14, v1
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s13
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v0
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s3, v2
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s13, v4
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s15
; GCN-NEXT:    v_mul_hi_u32 v5, v1, s15
; GCN-NEXT:    s_ashr_i32 s13, s7, 31
; GCN-NEXT:    s_add_i32 s7, s7, s13
; GCN-NEXT:    v_sub_i32_e32 v6, vcc, 0, v4
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v5
; GCN-NEXT:    v_cndmask_b32_e64 v4, v4, v6, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v4, v4, v1
; GCN-NEXT:    s_xor_b32 s7, s7, s13
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s3, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v4, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v4, v1
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v5, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s7
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v3, v0, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v2, v1, s15
; GCN-NEXT:    v_xor_b32_e32 v0, s12, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s12, v0
; GCN-NEXT:    s_xor_b32 s4, s13, s6
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, s7, v2
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s15, v3
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s7, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, -1, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, 1, v1
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v1, v3, v1, s[2:3]
; GCN-NEXT:    v_xor_b32_e32 v1, s4, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, s4, v1
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[8:11], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i32> <i32 4096, i32 4096>, %y
  %r = sdiv <2 x i32> %x, %shl.y
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i32_oddk_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @srem_i32_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = srem i32 [[X:%.*]], 1235195
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i32_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    v_mov_b32_e32 v0, 0xd9528441
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_hi_i32 v0, s0, v0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    v_lshrrev_b32_e32 v1, 31, v0
; GCN-NEXT:    v_ashrrev_i32_e32 v0, 20, v0
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_mul_i32_i24_e32 v0, 0x12d8fb, v0
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem i32 %x, 1235195
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i32_pow2k_denom(i32 addrspace(1)* %out, i32 %x) {
; CHECK-LABEL: @srem_i32_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = srem i32 [[X:%.*]], 4096
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s0, s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s1, s0, 31
; GCN-NEXT:    s_lshr_b32 s1, s1, 20
; GCN-NEXT:    s_add_i32 s1, s0, s1
; GCN-NEXT:    s_and_b32 s1, s1, 0xfffff000
; GCN-NEXT:    s_sub_i32 s0, s0, s1
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem i32 %x, 4096
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i32_pow2_shl_denom(i32 addrspace(1)* %out, i32 %x, i32 %y) {
; CHECK-LABEL: @srem_i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i32 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = srem i32 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i32 [[R]], i32 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0xb
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b32 s2, 0x1000, s5
; GCN-NEXT:    s_ashr_i32 s3, s2, 31
; GCN-NEXT:    s_add_i32 s2, s2, s3
; GCN-NEXT:    s_xor_b32 s10, s2, s3
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s10
; GCN-NEXT:    s_ashr_i32 s8, s4, 31
; GCN-NEXT:    s_add_i32 s4, s4, s8
; GCN-NEXT:    s_xor_b32 s9, s4, s8
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    v_mul_f32_e32 v0, 0x4f800000, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s10
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s10
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[2:3], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v2, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s9
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s10
; GCN-NEXT:    v_sub_i32_e32 v1, vcc, s9, v0
; GCN-NEXT:    v_cmp_ge_u32_e64 s[0:1], s9, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, s10, v1
; GCN-NEXT:    v_cmp_le_u32_e64 s[2:3], s10, v1
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s10, v1
; GCN-NEXT:    s_and_b64 vcc, s[2:3], s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v1, v0, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v2, v0, s[0:1]
; GCN-NEXT:    v_xor_b32_e32 v0, s8, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s8, v0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    buffer_store_dword v0, off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i32 4096, %y
  %r = srem i32 %x, %shl.y
  store i32 %r, i32 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v2i32_pow2k_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x) {
; CHECK-LABEL: @srem_v2i32_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = srem i32 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i32> undef, i32 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = srem i32 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i32> [[TMP3]], i32 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP6]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v2i32_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx2 s[0:1], s[0:1], 0xb
; GCN-NEXT:    s_movk_i32 s2, 0xf000
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s3, s0, 31
; GCN-NEXT:    s_lshr_b32 s3, s3, 20
; GCN-NEXT:    s_add_i32 s3, s0, s3
; GCN-NEXT:    s_and_b32 s3, s3, s2
; GCN-NEXT:    s_sub_i32 s0, s0, s3
; GCN-NEXT:    s_ashr_i32 s3, s1, 31
; GCN-NEXT:    s_lshr_b32 s3, s3, 20
; GCN-NEXT:    s_add_i32 s3, s1, s3
; GCN-NEXT:    s_and_b32 s2, s3, s2
; GCN-NEXT:    s_sub_i32 s1, s1, s2
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem <2 x i32> %x, <i32 4096, i32 4096>
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v2i32_pow2_shl_denom(<2 x i32> addrspace(1)* %out, <2 x i32> %x, <2 x i32> %y) {
; CHECK-LABEL: @srem_v2i32_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i32> <i32 4096, i32 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i32> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = ashr i32 [[TMP1]], 31
; CHECK-NEXT:    [[TMP4:%.*]] = ashr i32 [[TMP2]], 31
; CHECK-NEXT:    [[TMP5:%.*]] = add i32 [[TMP1]], [[TMP3]]
; CHECK-NEXT:    [[TMP6:%.*]] = add i32 [[TMP2]], [[TMP4]]
; CHECK-NEXT:    [[TMP7:%.*]] = xor i32 [[TMP5]], [[TMP3]]
; CHECK-NEXT:    [[TMP8:%.*]] = xor i32 [[TMP6]], [[TMP4]]
; CHECK-NEXT:    [[TMP9:%.*]] = uitofp i32 [[TMP8]] to float
; CHECK-NEXT:    [[TMP10:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP9]])
; CHECK-NEXT:    [[TMP11:%.*]] = fmul fast float [[TMP10]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP12:%.*]] = fptoui float [[TMP11]] to i32
; CHECK-NEXT:    [[TMP13:%.*]] = zext i32 [[TMP12]] to i64
; CHECK-NEXT:    [[TMP14:%.*]] = zext i32 [[TMP8]] to i64
; CHECK-NEXT:    [[TMP15:%.*]] = mul i64 [[TMP13]], [[TMP14]]
; CHECK-NEXT:    [[TMP16:%.*]] = trunc i64 [[TMP15]] to i32
; CHECK-NEXT:    [[TMP17:%.*]] = lshr i64 [[TMP15]], 32
; CHECK-NEXT:    [[TMP18:%.*]] = trunc i64 [[TMP17]] to i32
; CHECK-NEXT:    [[TMP19:%.*]] = sub i32 0, [[TMP16]]
; CHECK-NEXT:    [[TMP20:%.*]] = icmp eq i32 [[TMP18]], 0
; CHECK-NEXT:    [[TMP21:%.*]] = select i1 [[TMP20]], i32 [[TMP19]], i32 [[TMP16]]
; CHECK-NEXT:    [[TMP22:%.*]] = zext i32 [[TMP21]] to i64
; CHECK-NEXT:    [[TMP23:%.*]] = zext i32 [[TMP12]] to i64
; CHECK-NEXT:    [[TMP24:%.*]] = mul i64 [[TMP22]], [[TMP23]]
; CHECK-NEXT:    [[TMP25:%.*]] = trunc i64 [[TMP24]] to i32
; CHECK-NEXT:    [[TMP26:%.*]] = lshr i64 [[TMP24]], 32
; CHECK-NEXT:    [[TMP27:%.*]] = trunc i64 [[TMP26]] to i32
; CHECK-NEXT:    [[TMP28:%.*]] = add i32 [[TMP12]], [[TMP27]]
; CHECK-NEXT:    [[TMP29:%.*]] = sub i32 [[TMP12]], [[TMP27]]
; CHECK-NEXT:    [[TMP30:%.*]] = select i1 [[TMP20]], i32 [[TMP28]], i32 [[TMP29]]
; CHECK-NEXT:    [[TMP31:%.*]] = zext i32 [[TMP30]] to i64
; CHECK-NEXT:    [[TMP32:%.*]] = zext i32 [[TMP7]] to i64
; CHECK-NEXT:    [[TMP33:%.*]] = mul i64 [[TMP31]], [[TMP32]]
; CHECK-NEXT:    [[TMP34:%.*]] = trunc i64 [[TMP33]] to i32
; CHECK-NEXT:    [[TMP35:%.*]] = lshr i64 [[TMP33]], 32
; CHECK-NEXT:    [[TMP36:%.*]] = trunc i64 [[TMP35]] to i32
; CHECK-NEXT:    [[TMP37:%.*]] = mul i32 [[TMP36]], [[TMP8]]
; CHECK-NEXT:    [[TMP38:%.*]] = sub i32 [[TMP7]], [[TMP37]]
; CHECK-NEXT:    [[TMP39:%.*]] = icmp uge i32 [[TMP38]], [[TMP8]]
; CHECK-NEXT:    [[TMP40:%.*]] = icmp uge i32 [[TMP7]], [[TMP37]]
; CHECK-NEXT:    [[TMP41:%.*]] = and i1 [[TMP39]], [[TMP40]]
; CHECK-NEXT:    [[TMP42:%.*]] = sub i32 [[TMP38]], [[TMP8]]
; CHECK-NEXT:    [[TMP43:%.*]] = add i32 [[TMP38]], [[TMP8]]
; CHECK-NEXT:    [[TMP44:%.*]] = select i1 [[TMP41]], i32 [[TMP42]], i32 [[TMP38]]
; CHECK-NEXT:    [[TMP45:%.*]] = select i1 [[TMP40]], i32 [[TMP44]], i32 [[TMP43]]
; CHECK-NEXT:    [[TMP46:%.*]] = xor i32 [[TMP45]], [[TMP3]]
; CHECK-NEXT:    [[TMP47:%.*]] = sub i32 [[TMP46]], [[TMP3]]
; CHECK-NEXT:    [[TMP48:%.*]] = insertelement <2 x i32> undef, i32 [[TMP47]], i64 0
; CHECK-NEXT:    [[TMP49:%.*]] = extractelement <2 x i32> [[X]], i64 1
; CHECK-NEXT:    [[TMP50:%.*]] = extractelement <2 x i32> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP51:%.*]] = ashr i32 [[TMP49]], 31
; CHECK-NEXT:    [[TMP52:%.*]] = ashr i32 [[TMP50]], 31
; CHECK-NEXT:    [[TMP53:%.*]] = add i32 [[TMP49]], [[TMP51]]
; CHECK-NEXT:    [[TMP54:%.*]] = add i32 [[TMP50]], [[TMP52]]
; CHECK-NEXT:    [[TMP55:%.*]] = xor i32 [[TMP53]], [[TMP51]]
; CHECK-NEXT:    [[TMP56:%.*]] = xor i32 [[TMP54]], [[TMP52]]
; CHECK-NEXT:    [[TMP57:%.*]] = uitofp i32 [[TMP56]] to float
; CHECK-NEXT:    [[TMP58:%.*]] = call fast float @llvm.amdgcn.rcp.f32(float [[TMP57]])
; CHECK-NEXT:    [[TMP59:%.*]] = fmul fast float [[TMP58]], 0x41F0000000000000
; CHECK-NEXT:    [[TMP60:%.*]] = fptoui float [[TMP59]] to i32
; CHECK-NEXT:    [[TMP61:%.*]] = zext i32 [[TMP60]] to i64
; CHECK-NEXT:    [[TMP62:%.*]] = zext i32 [[TMP56]] to i64
; CHECK-NEXT:    [[TMP63:%.*]] = mul i64 [[TMP61]], [[TMP62]]
; CHECK-NEXT:    [[TMP64:%.*]] = trunc i64 [[TMP63]] to i32
; CHECK-NEXT:    [[TMP65:%.*]] = lshr i64 [[TMP63]], 32
; CHECK-NEXT:    [[TMP66:%.*]] = trunc i64 [[TMP65]] to i32
; CHECK-NEXT:    [[TMP67:%.*]] = sub i32 0, [[TMP64]]
; CHECK-NEXT:    [[TMP68:%.*]] = icmp eq i32 [[TMP66]], 0
; CHECK-NEXT:    [[TMP69:%.*]] = select i1 [[TMP68]], i32 [[TMP67]], i32 [[TMP64]]
; CHECK-NEXT:    [[TMP70:%.*]] = zext i32 [[TMP69]] to i64
; CHECK-NEXT:    [[TMP71:%.*]] = zext i32 [[TMP60]] to i64
; CHECK-NEXT:    [[TMP72:%.*]] = mul i64 [[TMP70]], [[TMP71]]
; CHECK-NEXT:    [[TMP73:%.*]] = trunc i64 [[TMP72]] to i32
; CHECK-NEXT:    [[TMP74:%.*]] = lshr i64 [[TMP72]], 32
; CHECK-NEXT:    [[TMP75:%.*]] = trunc i64 [[TMP74]] to i32
; CHECK-NEXT:    [[TMP76:%.*]] = add i32 [[TMP60]], [[TMP75]]
; CHECK-NEXT:    [[TMP77:%.*]] = sub i32 [[TMP60]], [[TMP75]]
; CHECK-NEXT:    [[TMP78:%.*]] = select i1 [[TMP68]], i32 [[TMP76]], i32 [[TMP77]]
; CHECK-NEXT:    [[TMP79:%.*]] = zext i32 [[TMP78]] to i64
; CHECK-NEXT:    [[TMP80:%.*]] = zext i32 [[TMP55]] to i64
; CHECK-NEXT:    [[TMP81:%.*]] = mul i64 [[TMP79]], [[TMP80]]
; CHECK-NEXT:    [[TMP82:%.*]] = trunc i64 [[TMP81]] to i32
; CHECK-NEXT:    [[TMP83:%.*]] = lshr i64 [[TMP81]], 32
; CHECK-NEXT:    [[TMP84:%.*]] = trunc i64 [[TMP83]] to i32
; CHECK-NEXT:    [[TMP85:%.*]] = mul i32 [[TMP84]], [[TMP56]]
; CHECK-NEXT:    [[TMP86:%.*]] = sub i32 [[TMP55]], [[TMP85]]
; CHECK-NEXT:    [[TMP87:%.*]] = icmp uge i32 [[TMP86]], [[TMP56]]
; CHECK-NEXT:    [[TMP88:%.*]] = icmp uge i32 [[TMP55]], [[TMP85]]
; CHECK-NEXT:    [[TMP89:%.*]] = and i1 [[TMP87]], [[TMP88]]
; CHECK-NEXT:    [[TMP90:%.*]] = sub i32 [[TMP86]], [[TMP56]]
; CHECK-NEXT:    [[TMP91:%.*]] = add i32 [[TMP86]], [[TMP56]]
; CHECK-NEXT:    [[TMP92:%.*]] = select i1 [[TMP89]], i32 [[TMP90]], i32 [[TMP86]]
; CHECK-NEXT:    [[TMP93:%.*]] = select i1 [[TMP88]], i32 [[TMP92]], i32 [[TMP91]]
; CHECK-NEXT:    [[TMP94:%.*]] = xor i32 [[TMP93]], [[TMP51]]
; CHECK-NEXT:    [[TMP95:%.*]] = sub i32 [[TMP94]], [[TMP51]]
; CHECK-NEXT:    [[TMP96:%.*]] = insertelement <2 x i32> [[TMP48]], i32 [[TMP95]], i64 1
; CHECK-NEXT:    store <2 x i32> [[TMP96]], <2 x i32> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v2i32_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[2:3], s[0:1], 0xd
; GCN-NEXT:    s_movk_i32 s4, 0x1000
; GCN-NEXT:    s_mov_b32 s14, 0x4f800000
; GCN-NEXT:    s_load_dwordx2 s[6:7], s[0:1], 0xb
; GCN-NEXT:    s_load_dwordx2 s[8:9], s[0:1], 0x9
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b32 s2, s4, s2
; GCN-NEXT:    s_ashr_i32 s5, s2, 31
; GCN-NEXT:    s_add_i32 s2, s2, s5
; GCN-NEXT:    s_xor_b32 s13, s2, s5
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s13
; GCN-NEXT:    s_lshl_b32 s2, s4, s3
; GCN-NEXT:    s_ashr_i32 s12, s6, 31
; GCN-NEXT:    s_add_i32 s3, s6, s12
; GCN-NEXT:    v_rcp_iflag_f32_e32 v0, v0
; GCN-NEXT:    s_ashr_i32 s4, s2, 31
; GCN-NEXT:    s_add_i32 s6, s2, s4
; GCN-NEXT:    s_xor_b32 s5, s3, s12
; GCN-NEXT:    v_mul_f32_e32 v0, s14, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    s_xor_b32 s15, s6, s4
; GCN-NEXT:    s_ashr_i32 s6, s7, 31
; GCN-NEXT:    s_add_i32 s7, s7, s6
; GCN-NEXT:    v_mul_lo_u32 v1, v0, s13
; GCN-NEXT:    v_mul_hi_u32 v2, v0, s13
; GCN-NEXT:    s_xor_b32 s7, s7, s6
; GCN-NEXT:    s_mov_b32 s11, 0xf000
; GCN-NEXT:    v_sub_i32_e32 v3, vcc, 0, v1
; GCN-NEXT:    v_cmp_eq_u32_e64 s[2:3], 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v3, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, v0
; GCN-NEXT:    v_cvt_f32_u32_e32 v2, s15
; GCN-NEXT:    s_mov_b32 s10, -1
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v1, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, v1, v0
; GCN-NEXT:    v_rcp_iflag_f32_e32 v1, v2
; GCN-NEXT:    v_cndmask_b32_e64 v0, v0, v3, s[2:3]
; GCN-NEXT:    v_mul_hi_u32 v0, v0, s5
; GCN-NEXT:    v_mul_f32_e32 v1, s14, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s13
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s15
; GCN-NEXT:    v_mul_hi_u32 v5, v1, s15
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s5, v0
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s5, v0
; GCN-NEXT:    v_sub_i32_e32 v6, vcc, 0, v4
; GCN-NEXT:    v_cmp_eq_u32_e64 s[4:5], 0, v5
; GCN-NEXT:    v_cndmask_b32_e64 v4, v4, v6, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v4, v4, v1
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s13, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s13, v2
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s13, v2
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v4, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, v4, v1
; GCN-NEXT:    v_cndmask_b32_e64 v1, v1, v5, s[4:5]
; GCN-NEXT:    v_mul_hi_u32 v1, v1, s7
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v2, v0, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v0, v3, v0, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s15
; GCN-NEXT:    v_xor_b32_e32 v0, s12, v0
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s12, v0
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s7, v1
; GCN-NEXT:    v_cmp_ge_u32_e64 s[2:3], s7, v1
; GCN-NEXT:    v_cmp_le_u32_e64 s[0:1], s15, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, s15, v2
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, s15, v2
; GCN-NEXT:    s_and_b64 vcc, s[0:1], s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v2, v1, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v1, v3, v1, s[2:3]
; GCN-NEXT:    v_xor_b32_e32 v1, s6, v1
; GCN-NEXT:    v_subrev_i32_e32 v1, vcc, s6, v1
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[8:11], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i32> <i32 4096, i32 4096>, %y
  %r = srem <2 x i32> %x, %shl.y
  store <2 x i32> %r, <2 x i32> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i64_oddk_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @udiv_i64_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = udiv i64 [[X:%.*]], 1235195949943
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i64_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    v_mov_b32_e32 v0, 0x4f176a73
; GCN-NEXT:    v_mov_b32_e32 v1, 0x4f800000
; GCN-NEXT:    v_madmk_f32 v0, v1, 0x438f8000, v0
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_movk_i32 s2, 0xfee0
; GCN-NEXT:    s_mov_b32 s3, 0x68958c89
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x9
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s8
; GCN-NEXT:    s_movk_i32 s8, 0x11f
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s2
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s3
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s3
; GCN-NEXT:    v_mul_lo_u32 v5, v0, s3
; GCN-NEXT:    s_mov_b32 s5, s9
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v4, v2
; GCN-NEXT:    v_mul_lo_u32 v3, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v4, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v7, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v5
; GCN-NEXT:    v_mul_hi_u32 v5, v1, v5
; GCN-NEXT:    s_movk_i32 s9, 0x11e
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v4, v5, vcc
; GCN-NEXT:    v_mov_b32_e32 v4, 0
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v6, 0
; GCN-NEXT:    v_add_i32_e64 v0, s[0:1], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, v0, s2
; GCN-NEXT:    v_mul_hi_u32 v7, v0, s3
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v8, v2, s3
; GCN-NEXT:    s_mov_b32 s2, 0x976a7377
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_mul_lo_u32 v7, v0, s3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v5, v8
; GCN-NEXT:    v_mul_lo_u32 v8, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v9, v0, v7
; GCN-NEXT:    v_mul_hi_u32 v11, v2, v5
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v9, v8
; GCN-NEXT:    v_addc_u32_e32 v9, vcc, 0, v10, vcc
; GCN-NEXT:    v_mul_lo_u32 v10, v2, v7
; GCN-NEXT:    v_mul_hi_u32 v7, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v5
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v8, v10
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v9, v7, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v11, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[0:1]
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s10, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v7, s11, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s11, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s11, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s11, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v6, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s8
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s2
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s2
; GCN-NEXT:    v_mov_b32_e32 v5, s8
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mul_lo_u32 v3, v0, s2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v4
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s11, v2
; GCN-NEXT:    v_sub_i32_e64 v3, s[0:1], s10, v3
; GCN-NEXT:    v_subb_u32_e64 v4, vcc, v4, v5, s[0:1]
; GCN-NEXT:    v_subrev_i32_e32 v5, vcc, s2, v3
; GCN-NEXT:    v_subbrev_u32_e32 v4, vcc, 0, v4, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s9, v4
; GCN-NEXT:    s_mov_b32 s10, 0x976a7376
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s10, v5
; GCN-NEXT:    v_cndmask_b32_e64 v5, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s8, v4
; GCN-NEXT:    v_cndmask_b32_e32 v4, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v5, vcc, 2, v0
; GCN-NEXT:    v_addc_u32_e32 v6, vcc, 0, v1, vcc
; GCN-NEXT:    v_add_i32_e32 v7, vcc, 1, v0
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, 0, v1, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, v8, v6, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v6, s11
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v6, v2, s[0:1]
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s9, v2
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s10, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s8, v2
; GCN-NEXT:    v_cndmask_b32_e32 v2, v6, v3, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v7, v5, s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v4, vcc
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i64 %x, 1235195949943
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i64_pow2k_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @udiv_i64_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = udiv i64 [[X:%.*]], 4096
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s4
; GCN-NEXT:    s_mov_b32 s1, s5
; GCN-NEXT:    s_lshr_b64 s[4:5], s[6:7], 12
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    v_mov_b32_e32 v1, s5
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = udiv i64 %x, 4096
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_i64_pow2_shl_denom(i64 addrspace(1)* %out, i64 %x, i64 %y) {
; CHECK-LABEL: @udiv_i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i64 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = udiv i64 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s8, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s4
; GCN-NEXT:    s_add_i32 s8, s8, 12
; GCN-NEXT:    s_mov_b32 s1, s5
; GCN-NEXT:    s_lshr_b64 s[4:5], s[6:7], s8
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    v_mov_b32_e32 v1, s5
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i64 4096, %y
  %r = udiv i64 %x, %shl.y
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v2i64_pow2k_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x) {
; CHECK-LABEL: @udiv_v2i64_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = udiv i64 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = udiv i64 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP6]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v2i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshr_b64 s[0:1], s[0:1], 12
; GCN-NEXT:    s_lshr_b64 s[2:3], s[2:3], 12
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    v_mov_b32_e32 v2, s2
; GCN-NEXT:    v_mov_b32_e32 v3, s3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv <2 x i64> %x, <i64 4096, i64 4096>
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v2i64_mixed_pow2k_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x) {
; CHECK-LABEL: @udiv_v2i64_mixed_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = udiv i64 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = udiv i64 [[TMP4]], 4095
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP6]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v2i64_mixed_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    v_mov_b32_e32 v0, 0x4f800000
; GCN-NEXT:    v_madak_f32 v0, 0, v0, 0x457ff000
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_movk_i32 s6, 0xf001
; GCN-NEXT:    v_mov_b32_e32 v7, 0
; GCN-NEXT:    v_mov_b32_e32 v2, 0
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GCN-NEXT:    s_movk_i32 s0, 0xfff
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s6
; GCN-NEXT:    v_mul_lo_u32 v5, v1, s6
; GCN-NEXT:    v_mul_lo_u32 v4, v0, s6
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, v0, v3
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v5, v3
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v4
; GCN-NEXT:    v_mul_lo_u32 v5, v0, v3
; GCN-NEXT:    v_mul_hi_u32 v8, v0, v3
; GCN-NEXT:    v_mul_hi_u32 v9, v1, v3
; GCN-NEXT:    v_mul_lo_u32 v3, v1, v3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v6, v5
; GCN-NEXT:    v_addc_u32_e32 v6, vcc, v7, v8, vcc
; GCN-NEXT:    v_mul_lo_u32 v8, v1, v4
; GCN-NEXT:    v_mul_hi_u32 v4, v1, v4
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v8, v5
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v6, v4, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v9, v2, vcc
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_add_i32_e64 v0, s[2:3], v0, v3
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v7, v5, vcc
; GCN-NEXT:    v_mul_hi_u32 v5, v0, s6
; GCN-NEXT:    v_addc_u32_e64 v3, vcc, v1, v4, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v6, v3, s6
; GCN-NEXT:    v_mul_lo_u32 v8, v0, s6
; GCN-NEXT:    v_subrev_i32_e32 v5, vcc, v0, v5
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v5, v6
; GCN-NEXT:    v_mul_lo_u32 v6, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v9, v0, v8
; GCN-NEXT:    v_mul_hi_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v11, v3, v5
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v9, v6
; GCN-NEXT:    v_addc_u32_e32 v9, vcc, v7, v10, vcc
; GCN-NEXT:    v_mul_lo_u32 v10, v3, v8
; GCN-NEXT:    v_mul_hi_u32 v8, v3, v8
; GCN-NEXT:    v_mul_lo_u32 v3, v3, v5
; GCN-NEXT:    v_add_i32_e32 v6, vcc, v6, v10
; GCN-NEXT:    v_addc_u32_e32 v6, vcc, v9, v8, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v11, v2, vcc
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v4
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[2:3]
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v3
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    v_mul_lo_u32 v3, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v4, s10, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v6, s11, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s11, v1
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v7, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s11, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s11, v0
; GCN-NEXT:    s_lshr_b64 s[2:3], s[8:9], 12
; GCN-NEXT:    s_movk_i32 s8, 0xffe
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v5, v3
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v4, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v6, v2, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v7, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v1, s0
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s0
; GCN-NEXT:    v_mul_lo_u32 v4, v0, s0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v3, s11
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s10, v4
; GCN-NEXT:    v_subb_u32_e32 v2, vcc, v3, v2, vcc
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s0, v4
; GCN-NEXT:    v_subbrev_u32_e32 v5, vcc, 0, v2, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s8, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v5
; GCN-NEXT:    v_cndmask_b32_e32 v3, -1, v3, vcc
; GCN-NEXT:    v_add_i32_e32 v5, vcc, 2, v0
; GCN-NEXT:    v_addc_u32_e32 v6, vcc, 0, v1, vcc
; GCN-NEXT:    v_add_i32_e32 v7, vcc, 1, v0
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, 0, v1, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s8, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cmp_ne_u32_e64 s[0:1], 0, v3
; GCN-NEXT:    v_cndmask_b32_e32 v2, -1, v4, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v3, v8, v6, s[0:1]
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cndmask_b32_e32 v3, v1, v3, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v1, v7, v5, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v2, v0, v1, vcc
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_mov_b32_e32 v1, s3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = udiv <2 x i64> %x, <i64 4096, i64 4095>
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @udiv_v2i64_pow2_shl_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x, <2 x i64> %y) {
; CHECK-LABEL: @udiv_v2i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i64> <i64 4096, i64 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = udiv i64 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> undef, i64 [[TMP3]], i64 0
; CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP6:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP7:%.*]] = udiv i64 [[TMP5]], [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP7]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP8]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: udiv_v2i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x11
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_add_i32 s0, s0, 12
; GCN-NEXT:    s_add_i32 s2, s2, 12
; GCN-NEXT:    s_lshr_b64 s[0:1], s[8:9], s0
; GCN-NEXT:    s_lshr_b64 s[2:3], s[10:11], s2
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    v_mov_b32_e32 v2, s2
; GCN-NEXT:    v_mov_b32_e32 v3, s3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i64> <i64 4096, i64 4096>, %y
  %r = udiv <2 x i64> %x, %shl.y
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i64_oddk_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @urem_i64_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = urem i64 [[X:%.*]], 1235195393993
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i64_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    v_mov_b32_e32 v0, 0x4f1761f8
; GCN-NEXT:    v_mov_b32_e32 v1, 0x4f800000
; GCN-NEXT:    v_madmk_f32 v0, v1, 0x438f8000, v0
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_movk_i32 s2, 0xfee0
; GCN-NEXT:    s_mov_b32 s3, 0x689e0837
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x9
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s8
; GCN-NEXT:    s_movk_i32 s8, 0x11f
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s2
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s3
; GCN-NEXT:    v_mul_lo_u32 v4, v1, s3
; GCN-NEXT:    v_mul_lo_u32 v5, v0, s3
; GCN-NEXT:    s_mov_b32 s12, 0x9761f7c9
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v4, v2
; GCN-NEXT:    v_mul_lo_u32 v3, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v4, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v7, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v5
; GCN-NEXT:    v_mul_hi_u32 v5, v1, v5
; GCN-NEXT:    s_mov_b32 s5, s9
; GCN-NEXT:    s_movk_i32 s9, 0x11e
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v4, v5, vcc
; GCN-NEXT:    v_mov_b32_e32 v4, 0
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v6, 0
; GCN-NEXT:    v_add_i32_e64 v0, s[0:1], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, v0, s2
; GCN-NEXT:    v_mul_hi_u32 v7, v0, s3
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v8, v2, s3
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_mul_lo_u32 v7, v0, s3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v5, v8
; GCN-NEXT:    v_mul_lo_u32 v8, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v9, v0, v7
; GCN-NEXT:    v_mul_hi_u32 v11, v2, v5
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v9, v8
; GCN-NEXT:    v_addc_u32_e32 v9, vcc, 0, v10, vcc
; GCN-NEXT:    v_mul_lo_u32 v10, v2, v7
; GCN-NEXT:    v_mul_hi_u32 v7, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v5
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v8, v10
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v9, v7, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v11, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[0:1]
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s10, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v7, s11, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s11, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s11, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s11, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v6, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v0, s8
; GCN-NEXT:    v_mul_hi_u32 v3, v0, s12
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s12
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s12
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_sub_i32_e64 v0, s[0:1], s10, v0
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s11, v1
; GCN-NEXT:    v_mov_b32_e32 v3, s8
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v2, v3, s[0:1]
; GCN-NEXT:    v_subrev_i32_e64 v4, s[2:3], s12, v0
; GCN-NEXT:    v_subbrev_u32_e64 v5, vcc, 0, v2, s[2:3]
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s9, v5
; GCN-NEXT:    s_mov_b32 s10, 0x9761f7c8
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s10, v4
; GCN-NEXT:    v_cndmask_b32_e64 v7, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s8, v5
; GCN-NEXT:    v_cndmask_b32_e32 v6, v6, v7, vcc
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v2, v3, s[2:3]
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s12, v4
; GCN-NEXT:    v_subbrev_u32_e32 v2, vcc, 0, v2, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v6
; GCN-NEXT:    v_cndmask_b32_e64 v2, v5, v2, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v5, s11
; GCN-NEXT:    v_subb_u32_e64 v1, vcc, v5, v1, s[0:1]
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s9, v1
; GCN-NEXT:    v_cndmask_b32_e64 v5, 0, -1, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s10, v0
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s8, v1
; GCN-NEXT:    v_cndmask_b32_e32 v5, v5, v6, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v5
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v4, v3, s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem i64 %x, 1235195393993
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i64_pow2k_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @urem_i64_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = urem i64 [[X:%.*]], 4096
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    v_mov_b32_e32 v1, 0
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s4
; GCN-NEXT:    s_and_b32 s4, s6, 0xfff
; GCN-NEXT:    s_mov_b32 s1, s5
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = urem i64 %x, 4096
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_i64_pow2_shl_denom(i64 addrspace(1)* %out, i64 %x, i64 %y) {
; CHECK-LABEL: @urem_i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i64 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = urem i64 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_load_dword s8, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s4
; GCN-NEXT:    s_mov_b32 s1, s5
; GCN-NEXT:    s_mov_b32 s5, 0
; GCN-NEXT:    s_movk_i32 s4, 0x1000
; GCN-NEXT:    s_lshl_b64 s[4:5], s[4:5], s8
; GCN-NEXT:    s_add_u32 s4, s4, -1
; GCN-NEXT:    s_addc_u32 s5, s5, -1
; GCN-NEXT:    s_and_b64 s[4:5], s[6:7], s[4:5]
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    v_mov_b32_e32 v1, s5
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i64 4096, %y
  %r = urem i64 %x, %shl.y
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v2i64_pow2k_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x) {
; CHECK-LABEL: @urem_v2i64_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = urem i64 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = urem i64 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP6]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v2i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xd
; GCN-NEXT:    s_movk_i32 s8, 0xfff
; GCN-NEXT:    v_mov_b32_e32 v1, 0
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_and_b32 s0, s0, s8
; GCN-NEXT:    s_and_b32 s1, s2, s8
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v2, s1
; GCN-NEXT:    v_mov_b32_e32 v3, v1
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = urem <2 x i64> %x, <i64 4096, i64 4096>
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @urem_v2i64_pow2_shl_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x, <2 x i64> %y) {
; CHECK-LABEL: @urem_v2i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i64> <i64 4096, i64 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = urem i64 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> undef, i64 [[TMP3]], i64 0
; CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP6:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP7:%.*]] = urem i64 [[TMP5]], [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP7]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP8]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: urem_v2i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0x11
; GCN-NEXT:    s_mov_b32 s13, 0
; GCN-NEXT:    s_movk_i32 s12, 0x1000
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b64 s[2:3], s[12:13], s2
; GCN-NEXT:    s_lshl_b64 s[0:1], s[12:13], s0
; GCN-NEXT:    s_add_u32 s0, s0, -1
; GCN-NEXT:    s_addc_u32 s1, s1, -1
; GCN-NEXT:    s_and_b64 s[0:1], s[8:9], s[0:1]
; GCN-NEXT:    s_add_u32 s2, s2, -1
; GCN-NEXT:    s_addc_u32 s3, s3, -1
; GCN-NEXT:    s_and_b64 s[2:3], s[10:11], s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    v_mov_b32_e32 v2, s2
; GCN-NEXT:    v_mov_b32_e32 v3, s3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i64> <i64 4096, i64 4096>, %y
  %r = urem <2 x i64> %x, %shl.y
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i64_oddk_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @sdiv_i64_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = sdiv i64 [[X:%.*]], 1235195
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i64_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    v_mov_b32_e32 v0, 0x4f800000
; GCN-NEXT:    v_madak_f32 v0, 0, v0, 0x4996c7d8
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_mov_b32 s2, 0xffed2705
; GCN-NEXT:    v_mov_b32_e32 v8, 0
; GCN-NEXT:    v_mov_b32_e32 v7, 0
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_mul_hi_u32 v3, s2, v0
; GCN-NEXT:    v_mul_lo_u32 v2, v1, s2
; GCN-NEXT:    v_mul_lo_u32 v4, v0, s2
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s8
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, v0, v2
; GCN-NEXT:    v_mul_lo_u32 v5, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v4
; GCN-NEXT:    v_mul_hi_u32 v3, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v9, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v6, v5
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v4
; GCN-NEXT:    v_mul_hi_u32 v4, v1, v4
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v8, v3, vcc
; GCN-NEXT:    s_mov_b32 s5, s9
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v6, v5
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v3, v4, vcc
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v9, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e64 v0, s[0:1], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v8, v4, vcc
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v4, v2, s2
; GCN-NEXT:    v_mul_hi_u32 v5, s2, v0
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v5, v4
; GCN-NEXT:    v_mul_lo_u32 v5, v0, s2
; GCN-NEXT:    v_subrev_i32_e32 v4, vcc, v0, v4
; GCN-NEXT:    v_mul_lo_u32 v10, v0, v4
; GCN-NEXT:    v_mul_hi_u32 v12, v0, v4
; GCN-NEXT:    v_mul_hi_u32 v11, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v9, v2, v5
; GCN-NEXT:    v_mul_lo_u32 v5, v2, v5
; GCN-NEXT:    v_mul_hi_u32 v6, v2, v4
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v11, v10
; GCN-NEXT:    v_addc_u32_e32 v11, vcc, v8, v12, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v4
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v10, v5
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v11, v9, vcc
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v6, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v8, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    s_ashr_i32 s2, s11, 31
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v4, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s10, s2
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    s_mov_b32 s3, s2
; GCN-NEXT:    s_addc_u32 s1, s11, s2
; GCN-NEXT:    s_xor_b64 s[0:1], s[0:1], s[2:3]
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s0, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s0, v0
; GCN-NEXT:    v_mul_hi_u32 v4, s0, v1
; GCN-NEXT:    v_mul_hi_u32 v5, s1, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s1, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v8, v4, vcc
; GCN-NEXT:    v_mul_lo_u32 v4, s1, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s1, v0
; GCN-NEXT:    s_mov_b32 s3, 0x12d8fb
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v4, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v5, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v8, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v1, s3
; GCN-NEXT:    v_mul_hi_u32 v3, s3, v0
; GCN-NEXT:    v_mul_lo_u32 v4, v0, s3
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v3, s1
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s0, v4
; GCN-NEXT:    v_subb_u32_e32 v2, vcc, v3, v2, vcc
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s3, v4
; GCN-NEXT:    v_subbrev_u32_e32 v5, vcc, 0, v2, vcc
; GCN-NEXT:    s_mov_b32 s3, 0x12d8fa
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s3, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v5
; GCN-NEXT:    v_cndmask_b32_e32 v3, -1, v3, vcc
; GCN-NEXT:    v_add_i32_e32 v5, vcc, 2, v0
; GCN-NEXT:    v_addc_u32_e32 v6, vcc, 0, v1, vcc
; GCN-NEXT:    v_add_i32_e32 v7, vcc, 1, v0
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, 0, v1, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s3, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cmp_ne_u32_e64 s[0:1], 0, v3
; GCN-NEXT:    v_cndmask_b32_e32 v2, -1, v4, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v7, v5, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v3, v8, v6, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v3, vcc
; GCN-NEXT:    v_xor_b32_e32 v0, s2, v0
; GCN-NEXT:    v_xor_b32_e32 v1, s2, v1
; GCN-NEXT:    v_mov_b32_e32 v2, s2
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s2, v0
; GCN-NEXT:    v_subb_u32_e32 v1, vcc, v1, v2, vcc
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i64 %x, 1235195
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i64_pow2k_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @sdiv_i64_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = sdiv i64 [[X:%.*]], 4096
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s4
; GCN-NEXT:    s_ashr_i32 s4, s7, 31
; GCN-NEXT:    s_lshr_b32 s4, s4, 20
; GCN-NEXT:    s_add_u32 s4, s6, s4
; GCN-NEXT:    s_mov_b32 s1, s5
; GCN-NEXT:    s_addc_u32 s5, s7, 0
; GCN-NEXT:    s_ashr_i64 s[4:5], s[4:5], 12
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    v_mov_b32_e32 v1, s5
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv i64 %x, 4096
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_i64_pow2_shl_denom(i64 addrspace(1)* %out, i64 %x, i64 %y) {
; CHECK-LABEL: @sdiv_i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i64 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = sdiv i64 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dword s4, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0
; GCN-NEXT:    s_movk_i32 s2, 0x1000
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b64 s[2:3], s[2:3], s4
; GCN-NEXT:    s_ashr_i32 s12, s3, 31
; GCN-NEXT:    s_add_u32 s2, s2, s12
; GCN-NEXT:    s_mov_b32 s13, s12
; GCN-NEXT:    s_addc_u32 s3, s3, s12
; GCN-NEXT:    s_xor_b64 s[14:15], s[2:3], s[12:13]
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s14
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s15
; GCN-NEXT:    s_sub_u32 s2, 0, s14
; GCN-NEXT:    s_subb_u32 s3, 0, s15
; GCN-NEXT:    s_ashr_i32 s16, s11, 31
; GCN-NEXT:    v_mac_f32_e32 v0, 0x4f800000, v1
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_mov_b32 s17, s16
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_mov_b32 s4, s8
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_mov_b32 s5, s9
; GCN-NEXT:    v_mul_hi_u32 v3, s2, v0
; GCN-NEXT:    v_mul_lo_u32 v2, s2, v1
; GCN-NEXT:    v_mul_lo_u32 v5, s3, v0
; GCN-NEXT:    v_mul_lo_u32 v4, s2, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v5
; GCN-NEXT:    v_mul_hi_u32 v3, v0, v4
; GCN-NEXT:    v_mul_lo_u32 v5, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v7, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v3, v5
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v4
; GCN-NEXT:    v_mul_hi_u32 v4, v1, v4
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v5, v4, vcc
; GCN-NEXT:    v_mov_b32_e32 v4, 0
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v6, 0
; GCN-NEXT:    v_add_i32_e64 v0, s[0:1], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v5, vcc
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v5, s2, v2
; GCN-NEXT:    v_mul_hi_u32 v7, s2, v0
; GCN-NEXT:    v_mul_lo_u32 v8, s3, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_mul_lo_u32 v7, s2, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v8, v5
; GCN-NEXT:    v_mul_lo_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v12, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v11, v0, v7
; GCN-NEXT:    v_mul_hi_u32 v9, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v7, v2, v7
; GCN-NEXT:    v_mul_hi_u32 v8, v2, v5
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v11, v10
; GCN-NEXT:    v_addc_u32_e32 v11, vcc, 0, v12, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v5
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v10, v7
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v11, v9, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v8, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s10, s16
; GCN-NEXT:    s_addc_u32 s1, s11, s16
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    s_xor_b64 s[10:11], s[0:1], s[16:17]
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s10, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v7, s11, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s11, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s11, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s11, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v6, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s14, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s14, v0
; GCN-NEXT:    v_mul_lo_u32 v4, s15, v0
; GCN-NEXT:    v_mov_b32_e32 v5, s15
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mul_lo_u32 v3, s14, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v4
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s11, v2
; GCN-NEXT:    v_sub_i32_e64 v3, s[0:1], s10, v3
; GCN-NEXT:    v_subb_u32_e64 v4, vcc, v4, v5, s[0:1]
; GCN-NEXT:    v_subrev_i32_e32 v5, vcc, s14, v3
; GCN-NEXT:    v_subbrev_u32_e32 v4, vcc, 0, v4, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s15, v4
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s14, v5
; GCN-NEXT:    v_cndmask_b32_e64 v5, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s15, v4
; GCN-NEXT:    v_cndmask_b32_e32 v4, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v5, vcc, 2, v0
; GCN-NEXT:    v_addc_u32_e32 v6, vcc, 0, v1, vcc
; GCN-NEXT:    v_add_i32_e32 v7, vcc, 1, v0
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, 0, v1, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, v8, v6, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v6, s11
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v6, v2, s[0:1]
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s15, v2
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s14, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s15, v2
; GCN-NEXT:    v_cndmask_b32_e32 v2, v6, v3, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v7, v5, s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    s_xor_b64 s[0:1], s[16:17], s[12:13]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v4, vcc
; GCN-NEXT:    v_xor_b32_e32 v0, s0, v0
; GCN-NEXT:    v_xor_b32_e32 v1, s1, v1
; GCN-NEXT:    v_mov_b32_e32 v2, s1
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    v_subb_u32_e32 v1, vcc, v1, v2, vcc
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i64 4096, %y
  %r = sdiv i64 %x, %shl.y
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v2i64_pow2k_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x) {
; CHECK-LABEL: @sdiv_v2i64_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = sdiv i64 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = sdiv i64 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP6]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v2i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s8, s1, 31
; GCN-NEXT:    s_lshr_b32 s8, s8, 20
; GCN-NEXT:    s_add_u32 s0, s0, s8
; GCN-NEXT:    s_addc_u32 s1, s1, 0
; GCN-NEXT:    s_ashr_i32 s8, s3, 31
; GCN-NEXT:    s_ashr_i64 s[0:1], s[0:1], 12
; GCN-NEXT:    s_lshr_b32 s8, s8, 20
; GCN-NEXT:    s_add_u32 s2, s2, s8
; GCN-NEXT:    s_addc_u32 s3, s3, 0
; GCN-NEXT:    s_ashr_i64 s[2:3], s[2:3], 12
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    v_mov_b32_e32 v2, s2
; GCN-NEXT:    v_mov_b32_e32 v3, s3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv <2 x i64> %x, <i64 4096, i64 4096>
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @ssdiv_v2i64_mixed_pow2k_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x) {
; CHECK-LABEL: @ssdiv_v2i64_mixed_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = sdiv i64 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = sdiv i64 [[TMP4]], 4095
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP6]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: ssdiv_v2i64_mixed_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    v_mov_b32_e32 v0, 0x457ff000
; GCN-NEXT:    v_mov_b32_e32 v1, 0x4f800000
; GCN-NEXT:    v_mac_f32_e32 v0, 0, v1
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_movk_i32 s6, 0xf001
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s0, s9, 31
; GCN-NEXT:    s_lshr_b32 s0, s0, 20
; GCN-NEXT:    v_mul_hi_u32 v2, s6, v0
; GCN-NEXT:    v_mul_lo_u32 v3, v1, s6
; GCN-NEXT:    s_add_u32 s2, s8, s0
; GCN-NEXT:    s_addc_u32 s3, s9, 0
; GCN-NEXT:    s_ashr_i32 s8, s11, 31
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v3
; GCN-NEXT:    v_mul_lo_u32 v3, v0, s6
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, v0, v2
; GCN-NEXT:    v_mul_lo_u32 v4, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v5, v0, v3
; GCN-NEXT:    v_mul_hi_u32 v7, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    s_ashr_i64 s[2:3], s[2:3], 12
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v5, v4
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v3
; GCN-NEXT:    v_mul_hi_u32 v3, v1, v3
; GCN-NEXT:    s_mov_b32 s9, s8
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v6, v4
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v5, v3, vcc
; GCN-NEXT:    v_mov_b32_e32 v4, 0
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v6, 0
; GCN-NEXT:    v_add_i32_e64 v0, s[0:1], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v5, vcc
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v5, v2, s6
; GCN-NEXT:    v_mul_hi_u32 v7, s6, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_mul_lo_u32 v7, v0, s6
; GCN-NEXT:    v_subrev_i32_e32 v5, vcc, v0, v5
; GCN-NEXT:    v_mul_lo_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v12, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v11, v0, v7
; GCN-NEXT:    v_mul_hi_u32 v9, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v7, v2, v7
; GCN-NEXT:    v_mul_hi_u32 v8, v2, v5
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v11, v10
; GCN-NEXT:    v_addc_u32_e32 v11, vcc, 0, v12, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v5
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v10, v7
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v11, v9, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v8, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s10, s8
; GCN-NEXT:    s_addc_u32 s1, s11, s8
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    s_xor_b64 s[0:1], s[0:1], s[8:9]
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s0, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s0, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s0, v1
; GCN-NEXT:    v_mul_hi_u32 v7, s1, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s1, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s1, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s1, v0
; GCN-NEXT:    s_movk_i32 s9, 0xfff
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v6, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v1, s9
; GCN-NEXT:    v_mul_hi_u32 v3, s9, v0
; GCN-NEXT:    v_mul_lo_u32 v4, v0, s9
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v3, s1
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s0, v4
; GCN-NEXT:    v_subb_u32_e32 v2, vcc, v3, v2, vcc
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s9, v4
; GCN-NEXT:    v_subbrev_u32_e32 v5, vcc, 0, v2, vcc
; GCN-NEXT:    s_movk_i32 s9, 0xffe
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s9, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v5
; GCN-NEXT:    v_cndmask_b32_e32 v3, -1, v3, vcc
; GCN-NEXT:    v_add_i32_e32 v5, vcc, 2, v0
; GCN-NEXT:    v_addc_u32_e32 v6, vcc, 0, v1, vcc
; GCN-NEXT:    v_add_i32_e32 v7, vcc, 1, v0
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, 0, v1, vcc
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s9, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cmp_ne_u32_e64 s[0:1], 0, v3
; GCN-NEXT:    v_cndmask_b32_e32 v2, -1, v4, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cndmask_b32_e64 v2, v7, v5, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v3, v8, v6, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v3, vcc
; GCN-NEXT:    v_xor_b32_e32 v0, s8, v0
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, s8, v0
; GCN-NEXT:    v_xor_b32_e32 v1, s8, v1
; GCN-NEXT:    v_mov_b32_e32 v3, s8
; GCN-NEXT:    v_subb_u32_e32 v3, vcc, v1, v3, vcc
; GCN-NEXT:    v_mov_b32_e32 v0, s2
; GCN-NEXT:    v_mov_b32_e32 v1, s3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = sdiv <2 x i64> %x, <i64 4096, i64 4095>
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @sdiv_v2i64_pow2_shl_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x, <2 x i64> %y) {
; CHECK-LABEL: @sdiv_v2i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i64> <i64 4096, i64 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = sdiv i64 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> undef, i64 [[TMP3]], i64 0
; CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP6:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP7:%.*]] = sdiv i64 [[TMP5]], [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP7]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP8]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: sdiv_v2i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x11
; GCN-NEXT:    s_mov_b32 s3, 0
; GCN-NEXT:    s_movk_i32 s2, 0x1000
; GCN-NEXT:    s_mov_b32 s20, 0x4f800000
; GCN-NEXT:    s_mov_b32 s21, 0x5f7ffffc
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b64 s[12:13], s[2:3], s6
; GCN-NEXT:    s_lshl_b64 s[2:3], s[2:3], s4
; GCN-NEXT:    s_ashr_i32 s16, s3, 31
; GCN-NEXT:    s_add_u32 s2, s2, s16
; GCN-NEXT:    s_mov_b32 s17, s16
; GCN-NEXT:    s_addc_u32 s3, s3, s16
; GCN-NEXT:    s_xor_b64 s[14:15], s[2:3], s[16:17]
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s14
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s15
; GCN-NEXT:    s_mov_b32 s22, 0x2f800000
; GCN-NEXT:    s_mov_b32 s23, 0xcf800000
; GCN-NEXT:    s_sub_u32 s6, 0, s14
; GCN-NEXT:    v_mac_f32_e32 v0, s20, v1
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_subb_u32 s7, 0, s15
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GCN-NEXT:    v_mul_f32_e32 v0, s21, v0
; GCN-NEXT:    v_mul_f32_e32 v1, s22, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, s23, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s18, s9, 31
; GCN-NEXT:    s_add_u32 s0, s8, s18
; GCN-NEXT:    v_mul_hi_u32 v3, s6, v0
; GCN-NEXT:    v_mul_lo_u32 v2, s6, v1
; GCN-NEXT:    v_mul_lo_u32 v4, s7, v0
; GCN-NEXT:    v_mul_lo_u32 v5, s6, v0
; GCN-NEXT:    s_mov_b32 s19, s18
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v4
; GCN-NEXT:    v_mul_lo_u32 v3, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v4, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v7, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v5
; GCN-NEXT:    v_mul_hi_u32 v5, v1, v5
; GCN-NEXT:    s_addc_u32 s1, s9, s18
; GCN-NEXT:    s_xor_b64 s[8:9], s[0:1], s[18:19]
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v4, v5, vcc
; GCN-NEXT:    v_mov_b32_e32 v4, 0
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v6, 0
; GCN-NEXT:    v_add_i32_e64 v0, s[2:3], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v5, vcc
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v5, s6, v2
; GCN-NEXT:    v_mul_hi_u32 v7, s6, v0
; GCN-NEXT:    v_mul_lo_u32 v8, s7, v0
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_mul_lo_u32 v7, s6, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v8, v5
; GCN-NEXT:    v_mul_lo_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v12, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v11, v0, v7
; GCN-NEXT:    v_mul_hi_u32 v9, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v7, v2, v7
; GCN-NEXT:    v_mul_hi_u32 v8, v2, v5
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v11, v10
; GCN-NEXT:    v_addc_u32_e32 v11, vcc, 0, v12, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v5
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v10, v7
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v11, v9, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v8, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[2:3]
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s8, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s8, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s8, v1
; GCN-NEXT:    v_mul_hi_u32 v7, s9, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s9, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s9, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s9, v0
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v6, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s14, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s14, v0
; GCN-NEXT:    v_mul_lo_u32 v5, s15, v0
; GCN-NEXT:    v_mov_b32_e32 v7, s15
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mul_lo_u32 v3, s14, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v5
; GCN-NEXT:    v_sub_i32_e32 v5, vcc, s9, v2
; GCN-NEXT:    v_sub_i32_e64 v3, s[0:1], s8, v3
; GCN-NEXT:    v_subb_u32_e64 v5, vcc, v5, v7, s[0:1]
; GCN-NEXT:    v_subrev_i32_e32 v7, vcc, s14, v3
; GCN-NEXT:    v_subbrev_u32_e32 v5, vcc, 0, v5, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s15, v5
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s14, v7
; GCN-NEXT:    v_cndmask_b32_e64 v7, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s15, v5
; GCN-NEXT:    v_cndmask_b32_e32 v5, v8, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v7, vcc, 2, v0
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, 0, v1, vcc
; GCN-NEXT:    v_add_i32_e32 v9, vcc, 1, v0
; GCN-NEXT:    v_addc_u32_e32 v10, vcc, 0, v1, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v5
; GCN-NEXT:    v_cndmask_b32_e64 v5, v10, v8, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v8, s9
; GCN-NEXT:    s_xor_b64 s[8:9], s[18:19], s[16:17]
; GCN-NEXT:    s_ashr_i32 s16, s13, 31
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v8, v2, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s12, s16
; GCN-NEXT:    s_mov_b32 s17, s16
; GCN-NEXT:    s_addc_u32 s1, s13, s16
; GCN-NEXT:    s_xor_b64 s[12:13], s[0:1], s[16:17]
; GCN-NEXT:    v_cvt_f32_u32_e32 v10, s12
; GCN-NEXT:    v_cvt_f32_u32_e32 v11, s13
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s15, v2
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s14, v3
; GCN-NEXT:    v_cndmask_b32_e64 v3, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s15, v2
; GCN-NEXT:    v_mac_f32_e32 v10, s20, v11
; GCN-NEXT:    v_cndmask_b32_e32 v2, v8, v3, vcc
; GCN-NEXT:    v_rcp_f32_e32 v3, v10
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v2
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v5, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v9, v7, s[2:3]
; GCN-NEXT:    v_mul_f32_e32 v3, s21, v3
; GCN-NEXT:    v_mul_f32_e32 v5, s22, v3
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_mac_f32_e32 v3, s23, v5
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v5, v5
; GCN-NEXT:    s_sub_u32 s2, 0, s12
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_mul_hi_u32 v2, s2, v3
; GCN-NEXT:    v_mul_lo_u32 v7, s2, v5
; GCN-NEXT:    s_subb_u32 s3, 0, s13
; GCN-NEXT:    v_mul_lo_u32 v8, s3, v3
; GCN-NEXT:    s_ashr_i32 s14, s11, 31
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v7, s2, v3
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v8
; GCN-NEXT:    v_mul_lo_u32 v8, v3, v2
; GCN-NEXT:    v_mul_hi_u32 v10, v3, v2
; GCN-NEXT:    v_mul_hi_u32 v9, v3, v7
; GCN-NEXT:    v_mul_hi_u32 v11, v5, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v5, v2
; GCN-NEXT:    s_mov_b32 s15, s14
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v9, v8
; GCN-NEXT:    v_addc_u32_e32 v9, vcc, 0, v10, vcc
; GCN-NEXT:    v_mul_lo_u32 v10, v5, v7
; GCN-NEXT:    v_mul_hi_u32 v7, v5, v7
; GCN-NEXT:    v_xor_b32_e32 v0, s8, v0
; GCN-NEXT:    v_xor_b32_e32 v1, s9, v1
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v10, v8
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v9, v7, vcc
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, v11, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_add_i32_e64 v2, s[0:1], v3, v2
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v6, v8, vcc
; GCN-NEXT:    v_addc_u32_e64 v3, vcc, v5, v7, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v8, s2, v3
; GCN-NEXT:    v_mul_hi_u32 v9, s2, v2
; GCN-NEXT:    v_mul_lo_u32 v10, s3, v2
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v9, v8
; GCN-NEXT:    v_mul_lo_u32 v9, s2, v2
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v10, v8
; GCN-NEXT:    v_mul_lo_u32 v12, v2, v8
; GCN-NEXT:    v_mul_hi_u32 v14, v2, v8
; GCN-NEXT:    v_mul_hi_u32 v13, v2, v9
; GCN-NEXT:    v_mul_hi_u32 v11, v3, v9
; GCN-NEXT:    v_mul_lo_u32 v9, v3, v9
; GCN-NEXT:    v_mul_hi_u32 v10, v3, v8
; GCN-NEXT:    v_add_i32_e32 v12, vcc, v13, v12
; GCN-NEXT:    v_addc_u32_e32 v13, vcc, 0, v14, vcc
; GCN-NEXT:    v_mul_lo_u32 v3, v3, v8
; GCN-NEXT:    v_add_i32_e32 v9, vcc, v12, v9
; GCN-NEXT:    v_addc_u32_e32 v9, vcc, v13, v11, vcc
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, v10, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v9, v3
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, v6, v8, vcc
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v5, v7
; GCN-NEXT:    v_addc_u32_e64 v5, vcc, v5, v8, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s10, s14
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v3
; GCN-NEXT:    s_addc_u32 s1, s11, s14
; GCN-NEXT:    s_xor_b64 s[10:11], s[0:1], s[14:15]
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s10, v3
; GCN-NEXT:    v_mul_hi_u32 v7, s10, v2
; GCN-NEXT:    v_mul_hi_u32 v9, s10, v3
; GCN-NEXT:    v_mul_hi_u32 v10, s11, v3
; GCN-NEXT:    v_mul_lo_u32 v3, s11, v3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, 0, v9, vcc
; GCN-NEXT:    v_mul_lo_u32 v9, s11, v2
; GCN-NEXT:    v_mul_hi_u32 v2, s11, v2
; GCN-NEXT:    v_mov_b32_e32 v8, s9
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v9, v5
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v2, vcc
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v10, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v4, vcc
; GCN-NEXT:    v_mul_lo_u32 v4, s12, v3
; GCN-NEXT:    v_mul_hi_u32 v5, s12, v2
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s8, v0
; GCN-NEXT:    v_mul_lo_u32 v6, s13, v2
; GCN-NEXT:    v_subb_u32_e32 v1, vcc, v1, v8, vcc
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v5, v4
; GCN-NEXT:    v_mul_lo_u32 v5, s12, v2
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v4, v6
; GCN-NEXT:    v_sub_i32_e32 v6, vcc, s11, v4
; GCN-NEXT:    v_mov_b32_e32 v7, s13
; GCN-NEXT:    v_sub_i32_e64 v5, s[0:1], s10, v5
; GCN-NEXT:    v_subb_u32_e64 v6, vcc, v6, v7, s[0:1]
; GCN-NEXT:    v_subrev_i32_e32 v7, vcc, s12, v5
; GCN-NEXT:    v_subbrev_u32_e32 v6, vcc, 0, v6, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s13, v6
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s12, v7
; GCN-NEXT:    v_cndmask_b32_e64 v7, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s13, v6
; GCN-NEXT:    v_cndmask_b32_e32 v6, v8, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v7, vcc, 2, v2
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, 0, v3, vcc
; GCN-NEXT:    v_add_i32_e32 v9, vcc, 1, v2
; GCN-NEXT:    v_addc_u32_e32 v10, vcc, 0, v3, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v6
; GCN-NEXT:    v_cndmask_b32_e64 v6, v10, v8, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v8, s11
; GCN-NEXT:    v_subb_u32_e64 v4, vcc, v8, v4, s[0:1]
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s13, v4
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s12, v5
; GCN-NEXT:    v_cndmask_b32_e64 v5, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s13, v4
; GCN-NEXT:    v_cndmask_b32_e32 v4, v8, v5, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v4
; GCN-NEXT:    v_cndmask_b32_e64 v4, v9, v7, s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v2, v2, v4, vcc
; GCN-NEXT:    s_xor_b64 s[0:1], s[14:15], s[16:17]
; GCN-NEXT:    v_cndmask_b32_e32 v3, v3, v6, vcc
; GCN-NEXT:    v_xor_b32_e32 v2, s0, v2
; GCN-NEXT:    v_xor_b32_e32 v3, s1, v3
; GCN-NEXT:    v_mov_b32_e32 v4, s1
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, s0, v2
; GCN-NEXT:    v_subb_u32_e32 v3, vcc, v3, v4, vcc
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i64> <i64 4096, i64 4096>, %y
  %r = sdiv <2 x i64> %x, %shl.y
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i64_oddk_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @srem_i64_oddk_denom(
; CHECK-NEXT:    [[R:%.*]] = srem i64 [[X:%.*]], 1235195
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i64_oddk_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    v_mov_b32_e32 v0, 0x4f800000
; GCN-NEXT:    v_madak_f32 v0, 0, v0, 0x4996c7d8
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_mov_b32 s2, 0xffed2705
; GCN-NEXT:    v_mov_b32_e32 v8, 0
; GCN-NEXT:    v_mov_b32_e32 v7, 0
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_mul_hi_u32 v3, s2, v0
; GCN-NEXT:    v_mul_lo_u32 v2, v1, s2
; GCN-NEXT:    v_mul_lo_u32 v4, v0, s2
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s4, s8
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, v0, v2
; GCN-NEXT:    v_mul_lo_u32 v5, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v4
; GCN-NEXT:    v_mul_hi_u32 v3, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v9, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v6, v5
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v4
; GCN-NEXT:    v_mul_hi_u32 v4, v1, v4
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v8, v3, vcc
; GCN-NEXT:    s_mov_b32 s5, s9
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v6, v5
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v3, v4, vcc
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v9, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e64 v0, s[0:1], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v8, v4, vcc
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v4, v2, s2
; GCN-NEXT:    v_mul_hi_u32 v5, s2, v0
; GCN-NEXT:    v_add_i32_e32 v4, vcc, v5, v4
; GCN-NEXT:    v_mul_lo_u32 v5, v0, s2
; GCN-NEXT:    v_subrev_i32_e32 v4, vcc, v0, v4
; GCN-NEXT:    v_mul_lo_u32 v10, v0, v4
; GCN-NEXT:    v_mul_hi_u32 v12, v0, v4
; GCN-NEXT:    v_mul_hi_u32 v11, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v9, v2, v5
; GCN-NEXT:    v_mul_lo_u32 v5, v2, v5
; GCN-NEXT:    v_mul_hi_u32 v6, v2, v4
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v11, v10
; GCN-NEXT:    v_addc_u32_e32 v11, vcc, v8, v12, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v4
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v10, v5
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v11, v9, vcc
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v6, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v8, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    s_ashr_i32 s2, s11, 31
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v4, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s10, s2
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    s_mov_b32 s3, s2
; GCN-NEXT:    s_addc_u32 s1, s11, s2
; GCN-NEXT:    s_xor_b64 s[0:1], s[0:1], s[2:3]
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s0, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s0, v0
; GCN-NEXT:    v_mul_hi_u32 v4, s0, v1
; GCN-NEXT:    v_mul_hi_u32 v5, s1, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s1, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v8, v4, vcc
; GCN-NEXT:    v_mul_lo_u32 v4, s1, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s1, v0
; GCN-NEXT:    s_mov_b32 s3, 0x12d8fb
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v4, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v5, v7, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v8, v2, vcc
; GCN-NEXT:    v_mul_hi_u32 v2, s3, v0
; GCN-NEXT:    v_mul_lo_u32 v1, v1, s3
; GCN-NEXT:    v_mul_lo_u32 v0, v0, s3
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_mov_b32_e32 v2, s1
; GCN-NEXT:    v_sub_i32_e32 v0, vcc, s0, v0
; GCN-NEXT:    v_subb_u32_e32 v1, vcc, v2, v1, vcc
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, s3, v0
; GCN-NEXT:    v_subbrev_u32_e32 v3, vcc, 0, v1, vcc
; GCN-NEXT:    v_subrev_i32_e32 v4, vcc, s3, v2
; GCN-NEXT:    v_subbrev_u32_e32 v5, vcc, 0, v3, vcc
; GCN-NEXT:    s_mov_b32 s3, 0x12d8fa
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s3, v2
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v3
; GCN-NEXT:    v_cndmask_b32_e32 v6, -1, v6, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[0:1], 0, v6
; GCN-NEXT:    v_cmp_lt_u32_e32 vcc, s3, v0
; GCN-NEXT:    v_cndmask_b32_e64 v3, v3, v5, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e64 v5, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, 0, v1
; GCN-NEXT:    v_cndmask_b32_e32 v5, -1, v5, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v5
; GCN-NEXT:    v_cndmask_b32_e64 v2, v2, v4, s[0:1]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v3, vcc
; GCN-NEXT:    v_xor_b32_e32 v0, s2, v0
; GCN-NEXT:    v_xor_b32_e32 v1, s2, v1
; GCN-NEXT:    v_mov_b32_e32 v2, s2
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s2, v0
; GCN-NEXT:    v_subb_u32_e32 v1, vcc, v1, v2, vcc
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem i64 %x, 1235195
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i64_pow2k_denom(i64 addrspace(1)* %out, i64 %x) {
; CHECK-LABEL: @srem_i64_pow2k_denom(
; CHECK-NEXT:    [[R:%.*]] = srem i64 [[X:%.*]], 4096
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s3, 0xf000
; GCN-NEXT:    s_mov_b32 s2, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_mov_b32 s0, s4
; GCN-NEXT:    s_ashr_i32 s4, s7, 31
; GCN-NEXT:    s_lshr_b32 s4, s4, 20
; GCN-NEXT:    s_add_u32 s4, s6, s4
; GCN-NEXT:    s_mov_b32 s1, s5
; GCN-NEXT:    s_addc_u32 s5, s7, 0
; GCN-NEXT:    s_and_b32 s4, s4, 0xfffff000
; GCN-NEXT:    s_sub_u32 s4, s6, s4
; GCN-NEXT:    s_subb_u32 s5, s7, s5
; GCN-NEXT:    v_mov_b32_e32 v0, s4
; GCN-NEXT:    v_mov_b32_e32 v1, s5
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[0:3], 0
; GCN-NEXT:    s_endpgm
  %r = srem i64 %x, 4096
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_i64_pow2_shl_denom(i64 addrspace(1)* %out, i64 %x, i64 %y) {
; CHECK-LABEL: @srem_i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl i64 4096, [[Y:%.*]]
; CHECK-NEXT:    [[R:%.*]] = srem i64 [[X:%.*]], [[SHL_Y]]
; CHECK-NEXT:    store i64 [[R]], i64 addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dword s4, s[0:1], 0xd
; GCN-NEXT:    s_mov_b32 s3, 0
; GCN-NEXT:    s_movk_i32 s2, 0x1000
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0x9
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b64 s[2:3], s[2:3], s4
; GCN-NEXT:    s_ashr_i32 s4, s3, 31
; GCN-NEXT:    s_add_u32 s2, s2, s4
; GCN-NEXT:    s_mov_b32 s5, s4
; GCN-NEXT:    s_addc_u32 s3, s3, s4
; GCN-NEXT:    s_xor_b64 s[12:13], s[2:3], s[4:5]
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s12
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s13
; GCN-NEXT:    s_sub_u32 s2, 0, s12
; GCN-NEXT:    s_subb_u32 s3, 0, s13
; GCN-NEXT:    s_ashr_i32 s14, s11, 31
; GCN-NEXT:    v_mac_f32_e32 v0, 0x4f800000, v1
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_mov_b32 s15, s14
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_mov_b32 s4, s8
; GCN-NEXT:    v_mul_f32_e32 v0, 0x5f7ffffc, v0
; GCN-NEXT:    v_mul_f32_e32 v1, 0x2f800000, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, 0xcf800000, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_mov_b32 s5, s9
; GCN-NEXT:    v_mul_hi_u32 v3, s2, v0
; GCN-NEXT:    v_mul_lo_u32 v2, s2, v1
; GCN-NEXT:    v_mul_lo_u32 v5, s3, v0
; GCN-NEXT:    v_mul_lo_u32 v4, s2, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v5
; GCN-NEXT:    v_mul_hi_u32 v3, v0, v4
; GCN-NEXT:    v_mul_lo_u32 v5, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v7, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v3, v5
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v4
; GCN-NEXT:    v_mul_hi_u32 v4, v1, v4
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v5, v4, vcc
; GCN-NEXT:    v_mov_b32_e32 v4, 0
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v6, 0
; GCN-NEXT:    v_add_i32_e64 v0, s[0:1], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v5, vcc
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v5, s2, v2
; GCN-NEXT:    v_mul_hi_u32 v7, s2, v0
; GCN-NEXT:    v_mul_lo_u32 v8, s3, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_mul_lo_u32 v7, s2, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v8, v5
; GCN-NEXT:    v_mul_lo_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v12, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v11, v0, v7
; GCN-NEXT:    v_mul_hi_u32 v9, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v7, v2, v7
; GCN-NEXT:    v_mul_hi_u32 v8, v2, v5
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v11, v10
; GCN-NEXT:    v_addc_u32_e32 v11, vcc, 0, v12, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v5
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v10, v7
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v11, v9, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v8, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s10, s14
; GCN-NEXT:    s_addc_u32 s1, s11, s14
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    s_xor_b64 s[10:11], s[0:1], s[14:15]
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s10, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s10, v1
; GCN-NEXT:    v_mul_hi_u32 v7, s11, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s11, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s11, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s11, v0
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v6, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v1, s12, v1
; GCN-NEXT:    v_mul_hi_u32 v2, s12, v0
; GCN-NEXT:    v_mul_lo_u32 v3, s13, v0
; GCN-NEXT:    v_mul_lo_u32 v0, s12, v0
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_sub_i32_e64 v0, s[0:1], s10, v0
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s11, v1
; GCN-NEXT:    v_mov_b32_e32 v3, s13
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v2, v3, s[0:1]
; GCN-NEXT:    v_subrev_i32_e64 v4, s[2:3], s12, v0
; GCN-NEXT:    v_subbrev_u32_e64 v5, vcc, 0, v2, s[2:3]
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s13, v5
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s12, v4
; GCN-NEXT:    v_cndmask_b32_e64 v7, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s13, v5
; GCN-NEXT:    v_cndmask_b32_e32 v6, v6, v7, vcc
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v2, v3, s[2:3]
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s12, v4
; GCN-NEXT:    v_subbrev_u32_e32 v2, vcc, 0, v2, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v6
; GCN-NEXT:    v_cndmask_b32_e64 v2, v5, v2, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v5, s11
; GCN-NEXT:    v_subb_u32_e64 v1, vcc, v5, v1, s[0:1]
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s13, v1
; GCN-NEXT:    v_cndmask_b32_e64 v5, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s12, v0
; GCN-NEXT:    v_cndmask_b32_e64 v6, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s13, v1
; GCN-NEXT:    v_cndmask_b32_e32 v5, v5, v6, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v5
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v4, v3, s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_xor_b32_e32 v0, s14, v0
; GCN-NEXT:    v_xor_b32_e32 v1, s14, v1
; GCN-NEXT:    v_mov_b32_e32 v2, s14
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s14, v0
; GCN-NEXT:    v_subb_u32_e32 v1, vcc, v1, v2, vcc
; GCN-NEXT:    buffer_store_dwordx2 v[0:1], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl i64 4096, %y
  %r = srem i64 %x, %shl.y
  store i64 %r, i64 addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v2i64_pow2k_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x) {
; CHECK-LABEL: @srem_v2i64_pow2k_denom(
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = srem i64 [[TMP1]], 4096
; CHECK-NEXT:    [[TMP3:%.*]] = insertelement <2 x i64> undef, i64 [[TMP2]], i64 0
; CHECK-NEXT:    [[TMP4:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP5:%.*]] = srem i64 [[TMP4]], 4096
; CHECK-NEXT:    [[TMP6:%.*]] = insertelement <2 x i64> [[TMP3]], i64 [[TMP5]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP6]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v2i64_pow2k_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[0:3], s[0:1], 0xd
; GCN-NEXT:    s_movk_i32 s8, 0xf000
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s9, s1, 31
; GCN-NEXT:    s_lshr_b32 s9, s9, 20
; GCN-NEXT:    s_add_u32 s9, s0, s9
; GCN-NEXT:    s_addc_u32 s10, s1, 0
; GCN-NEXT:    s_and_b32 s9, s9, s8
; GCN-NEXT:    s_sub_u32 s0, s0, s9
; GCN-NEXT:    s_subb_u32 s1, s1, s10
; GCN-NEXT:    s_ashr_i32 s9, s3, 31
; GCN-NEXT:    s_lshr_b32 s9, s9, 20
; GCN-NEXT:    s_add_u32 s9, s2, s9
; GCN-NEXT:    s_addc_u32 s10, s3, 0
; GCN-NEXT:    s_and_b32 s8, s9, s8
; GCN-NEXT:    s_sub_u32 s2, s2, s8
; GCN-NEXT:    s_subb_u32 s3, s3, s10
; GCN-NEXT:    v_mov_b32_e32 v0, s0
; GCN-NEXT:    v_mov_b32_e32 v1, s1
; GCN-NEXT:    v_mov_b32_e32 v2, s2
; GCN-NEXT:    v_mov_b32_e32 v3, s3
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %r = srem <2 x i64> %x, <i64 4096, i64 4096>
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}

define amdgpu_kernel void @srem_v2i64_pow2_shl_denom(<2 x i64> addrspace(1)* %out, <2 x i64> %x, <2 x i64> %y) {
; CHECK-LABEL: @srem_v2i64_pow2_shl_denom(
; CHECK-NEXT:    [[SHL_Y:%.*]] = shl <2 x i64> <i64 4096, i64 4096>, [[Y:%.*]]
; CHECK-NEXT:    [[TMP1:%.*]] = extractelement <2 x i64> [[X:%.*]], i64 0
; CHECK-NEXT:    [[TMP2:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 0
; CHECK-NEXT:    [[TMP3:%.*]] = srem i64 [[TMP1]], [[TMP2]]
; CHECK-NEXT:    [[TMP4:%.*]] = insertelement <2 x i64> undef, i64 [[TMP3]], i64 0
; CHECK-NEXT:    [[TMP5:%.*]] = extractelement <2 x i64> [[X]], i64 1
; CHECK-NEXT:    [[TMP6:%.*]] = extractelement <2 x i64> [[SHL_Y]], i64 1
; CHECK-NEXT:    [[TMP7:%.*]] = srem i64 [[TMP5]], [[TMP6]]
; CHECK-NEXT:    [[TMP8:%.*]] = insertelement <2 x i64> [[TMP4]], i64 [[TMP7]], i64 1
; CHECK-NEXT:    store <2 x i64> [[TMP8]], <2 x i64> addrspace(1)* [[OUT:%.*]]
; CHECK-NEXT:    ret void
;
; GCN-LABEL: srem_v2i64_pow2_shl_denom:
; GCN:       ; %bb.0:
; GCN-NEXT:    s_load_dwordx4 s[4:7], s[0:1], 0x11
; GCN-NEXT:    s_mov_b32 s3, 0
; GCN-NEXT:    s_movk_i32 s2, 0x1000
; GCN-NEXT:    s_mov_b32 s18, 0x4f800000
; GCN-NEXT:    s_mov_b32 s19, 0x5f7ffffc
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_lshl_b64 s[14:15], s[2:3], s6
; GCN-NEXT:    s_lshl_b64 s[2:3], s[2:3], s4
; GCN-NEXT:    s_ashr_i32 s4, s3, 31
; GCN-NEXT:    s_add_u32 s2, s2, s4
; GCN-NEXT:    s_mov_b32 s5, s4
; GCN-NEXT:    s_addc_u32 s3, s3, s4
; GCN-NEXT:    s_xor_b64 s[16:17], s[2:3], s[4:5]
; GCN-NEXT:    v_cvt_f32_u32_e32 v0, s16
; GCN-NEXT:    v_cvt_f32_u32_e32 v1, s17
; GCN-NEXT:    s_mov_b32 s20, 0x2f800000
; GCN-NEXT:    s_mov_b32 s21, 0xcf800000
; GCN-NEXT:    s_sub_u32 s6, 0, s16
; GCN-NEXT:    v_mac_f32_e32 v0, s18, v1
; GCN-NEXT:    v_rcp_f32_e32 v0, v0
; GCN-NEXT:    s_subb_u32 s7, 0, s17
; GCN-NEXT:    s_load_dwordx2 s[4:5], s[0:1], 0x9
; GCN-NEXT:    s_load_dwordx4 s[8:11], s[0:1], 0xd
; GCN-NEXT:    v_mul_f32_e32 v0, s19, v0
; GCN-NEXT:    v_mul_f32_e32 v1, s20, v0
; GCN-NEXT:    v_trunc_f32_e32 v1, v1
; GCN-NEXT:    v_mac_f32_e32 v0, s21, v1
; GCN-NEXT:    v_cvt_u32_f32_e32 v0, v0
; GCN-NEXT:    v_cvt_u32_f32_e32 v1, v1
; GCN-NEXT:    s_waitcnt lgkmcnt(0)
; GCN-NEXT:    s_ashr_i32 s12, s9, 31
; GCN-NEXT:    s_add_u32 s0, s8, s12
; GCN-NEXT:    v_mul_hi_u32 v3, s6, v0
; GCN-NEXT:    v_mul_lo_u32 v2, s6, v1
; GCN-NEXT:    v_mul_lo_u32 v4, s7, v0
; GCN-NEXT:    v_mul_lo_u32 v5, s6, v0
; GCN-NEXT:    s_mov_b32 s13, s12
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v4
; GCN-NEXT:    v_mul_lo_u32 v3, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v4, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v6, v0, v2
; GCN-NEXT:    v_mul_hi_u32 v7, v1, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v1, v2
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, 0, v6, vcc
; GCN-NEXT:    v_mul_lo_u32 v6, v1, v5
; GCN-NEXT:    v_mul_hi_u32 v5, v1, v5
; GCN-NEXT:    s_addc_u32 s1, s9, s12
; GCN-NEXT:    s_xor_b64 s[8:9], s[0:1], s[12:13]
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v6, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v4, v5, vcc
; GCN-NEXT:    v_mov_b32_e32 v4, 0
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_mov_b32_e32 v6, 0
; GCN-NEXT:    v_add_i32_e64 v0, s[2:3], v0, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v5, vcc
; GCN-NEXT:    v_addc_u32_e64 v2, vcc, v1, v3, s[2:3]
; GCN-NEXT:    v_mul_lo_u32 v5, s6, v2
; GCN-NEXT:    v_mul_hi_u32 v7, s6, v0
; GCN-NEXT:    v_mul_lo_u32 v8, s7, v0
; GCN-NEXT:    s_mov_b32 s7, 0xf000
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_mul_lo_u32 v7, s6, v0
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v8, v5
; GCN-NEXT:    v_mul_lo_u32 v10, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v12, v0, v5
; GCN-NEXT:    v_mul_hi_u32 v11, v0, v7
; GCN-NEXT:    v_mul_hi_u32 v9, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v7, v2, v7
; GCN-NEXT:    v_mul_hi_u32 v8, v2, v5
; GCN-NEXT:    v_add_i32_e32 v10, vcc, v11, v10
; GCN-NEXT:    v_addc_u32_e32 v11, vcc, 0, v12, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, v2, v5
; GCN-NEXT:    v_add_i32_e32 v7, vcc, v10, v7
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v11, v9, vcc
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v8, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_addc_u32_e32 v5, vcc, v6, v5, vcc
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_addc_u32_e64 v1, vcc, v1, v5, s[2:3]
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v2
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, 0, v1, vcc
; GCN-NEXT:    v_mul_lo_u32 v2, s8, v1
; GCN-NEXT:    v_mul_hi_u32 v3, s8, v0
; GCN-NEXT:    v_mul_hi_u32 v5, s8, v1
; GCN-NEXT:    v_mul_hi_u32 v7, s9, v1
; GCN-NEXT:    v_mul_lo_u32 v1, s9, v1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v3, v2
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s9, v0
; GCN-NEXT:    v_mul_hi_u32 v0, s9, v0
; GCN-NEXT:    s_mov_b32 s6, -1
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v5, v2
; GCN-NEXT:    v_addc_u32_e32 v0, vcc, v3, v0, vcc
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v0, vcc, v0, v1
; GCN-NEXT:    v_addc_u32_e32 v1, vcc, v6, v2, vcc
; GCN-NEXT:    v_mul_lo_u32 v1, s16, v1
; GCN-NEXT:    v_mul_hi_u32 v2, s16, v0
; GCN-NEXT:    v_mul_lo_u32 v3, s17, v0
; GCN-NEXT:    v_mul_lo_u32 v0, s16, v0
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v2, v1
; GCN-NEXT:    v_add_i32_e32 v1, vcc, v1, v3
; GCN-NEXT:    v_sub_i32_e64 v0, s[0:1], s8, v0
; GCN-NEXT:    v_sub_i32_e32 v2, vcc, s9, v1
; GCN-NEXT:    v_mov_b32_e32 v3, s17
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v2, v3, s[0:1]
; GCN-NEXT:    v_subrev_i32_e64 v5, s[2:3], s16, v0
; GCN-NEXT:    v_subbrev_u32_e64 v7, vcc, 0, v2, s[2:3]
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s17, v7
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s16, v5
; GCN-NEXT:    v_cndmask_b32_e64 v9, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s17, v7
; GCN-NEXT:    v_cndmask_b32_e32 v8, v8, v9, vcc
; GCN-NEXT:    v_subb_u32_e64 v2, vcc, v2, v3, s[2:3]
; GCN-NEXT:    v_subrev_i32_e32 v3, vcc, s16, v5
; GCN-NEXT:    v_subbrev_u32_e32 v2, vcc, 0, v2, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v2, v7, v2, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v7, s9
; GCN-NEXT:    v_subb_u32_e64 v1, vcc, v7, v1, s[0:1]
; GCN-NEXT:    s_ashr_i32 s0, s15, 31
; GCN-NEXT:    s_add_u32 s8, s14, s0
; GCN-NEXT:    s_mov_b32 s1, s0
; GCN-NEXT:    s_addc_u32 s9, s15, s0
; GCN-NEXT:    s_xor_b64 s[8:9], s[8:9], s[0:1]
; GCN-NEXT:    v_cvt_f32_u32_e32 v9, s8
; GCN-NEXT:    v_cvt_f32_u32_e32 v10, s9
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s17, v1
; GCN-NEXT:    v_cndmask_b32_e64 v7, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s16, v0
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s17, v1
; GCN-NEXT:    v_mac_f32_e32 v9, s18, v10
; GCN-NEXT:    v_cndmask_b32_e32 v7, v7, v8, vcc
; GCN-NEXT:    v_rcp_f32_e32 v8, v9
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v7
; GCN-NEXT:    v_cndmask_b32_e32 v1, v1, v2, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v2, v5, v3, s[2:3]
; GCN-NEXT:    v_mul_f32_e32 v3, s19, v8
; GCN-NEXT:    v_mul_f32_e32 v5, s20, v3
; GCN-NEXT:    v_trunc_f32_e32 v5, v5
; GCN-NEXT:    v_mac_f32_e32 v3, s21, v5
; GCN-NEXT:    v_cvt_u32_f32_e32 v3, v3
; GCN-NEXT:    v_cvt_u32_f32_e32 v5, v5
; GCN-NEXT:    s_sub_u32 s2, 0, s8
; GCN-NEXT:    v_cndmask_b32_e32 v0, v0, v2, vcc
; GCN-NEXT:    v_mul_hi_u32 v2, s2, v3
; GCN-NEXT:    v_mul_lo_u32 v7, s2, v5
; GCN-NEXT:    s_subb_u32 s3, 0, s9
; GCN-NEXT:    v_mul_lo_u32 v8, s3, v3
; GCN-NEXT:    s_ashr_i32 s14, s11, 31
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v7
; GCN-NEXT:    v_mul_lo_u32 v7, s2, v3
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v8
; GCN-NEXT:    v_mul_lo_u32 v8, v3, v2
; GCN-NEXT:    v_mul_hi_u32 v10, v3, v2
; GCN-NEXT:    v_mul_hi_u32 v9, v3, v7
; GCN-NEXT:    v_mul_hi_u32 v11, v5, v2
; GCN-NEXT:    v_mul_lo_u32 v2, v5, v2
; GCN-NEXT:    s_mov_b32 s15, s14
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v9, v8
; GCN-NEXT:    v_addc_u32_e32 v9, vcc, 0, v10, vcc
; GCN-NEXT:    v_mul_lo_u32 v10, v5, v7
; GCN-NEXT:    v_mul_hi_u32 v7, v5, v7
; GCN-NEXT:    v_xor_b32_e32 v0, s12, v0
; GCN-NEXT:    v_xor_b32_e32 v1, s12, v1
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v10, v8
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v9, v7, vcc
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, v11, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v7, v2
; GCN-NEXT:    v_add_i32_e64 v2, s[0:1], v3, v2
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, v6, v8, vcc
; GCN-NEXT:    v_addc_u32_e64 v3, vcc, v5, v7, s[0:1]
; GCN-NEXT:    v_mul_lo_u32 v8, s2, v3
; GCN-NEXT:    v_mul_hi_u32 v9, s2, v2
; GCN-NEXT:    v_mul_lo_u32 v10, s3, v2
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v9, v8
; GCN-NEXT:    v_mul_lo_u32 v9, s2, v2
; GCN-NEXT:    v_add_i32_e32 v8, vcc, v10, v8
; GCN-NEXT:    v_mul_lo_u32 v12, v2, v8
; GCN-NEXT:    v_mul_hi_u32 v14, v2, v8
; GCN-NEXT:    v_mul_hi_u32 v13, v2, v9
; GCN-NEXT:    v_mul_hi_u32 v11, v3, v9
; GCN-NEXT:    v_mul_lo_u32 v9, v3, v9
; GCN-NEXT:    v_mul_hi_u32 v10, v3, v8
; GCN-NEXT:    v_add_i32_e32 v12, vcc, v13, v12
; GCN-NEXT:    v_addc_u32_e32 v13, vcc, 0, v14, vcc
; GCN-NEXT:    v_mul_lo_u32 v3, v3, v8
; GCN-NEXT:    v_add_i32_e32 v9, vcc, v12, v9
; GCN-NEXT:    v_addc_u32_e32 v9, vcc, v13, v11, vcc
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, v10, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v9, v3
; GCN-NEXT:    v_addc_u32_e32 v8, vcc, v6, v8, vcc
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v5, v7
; GCN-NEXT:    v_addc_u32_e64 v5, vcc, v5, v8, s[0:1]
; GCN-NEXT:    s_add_u32 s0, s10, s14
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v3
; GCN-NEXT:    s_addc_u32 s1, s11, s14
; GCN-NEXT:    s_xor_b64 s[10:11], s[0:1], s[14:15]
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, 0, v5, vcc
; GCN-NEXT:    v_mul_lo_u32 v5, s10, v3
; GCN-NEXT:    v_mul_hi_u32 v7, s10, v2
; GCN-NEXT:    v_mul_hi_u32 v9, s10, v3
; GCN-NEXT:    v_mul_hi_u32 v10, s11, v3
; GCN-NEXT:    v_mul_lo_u32 v3, s11, v3
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v7, v5
; GCN-NEXT:    v_addc_u32_e32 v7, vcc, 0, v9, vcc
; GCN-NEXT:    v_mul_lo_u32 v9, s11, v2
; GCN-NEXT:    v_mul_hi_u32 v2, s11, v2
; GCN-NEXT:    v_mov_b32_e32 v8, s12
; GCN-NEXT:    v_add_i32_e32 v5, vcc, v9, v5
; GCN-NEXT:    v_addc_u32_e32 v2, vcc, v7, v2, vcc
; GCN-NEXT:    v_addc_u32_e32 v4, vcc, v10, v4, vcc
; GCN-NEXT:    v_add_i32_e32 v2, vcc, v2, v3
; GCN-NEXT:    v_addc_u32_e32 v3, vcc, v6, v4, vcc
; GCN-NEXT:    v_mul_lo_u32 v3, s8, v3
; GCN-NEXT:    v_mul_hi_u32 v4, s8, v2
; GCN-NEXT:    v_mul_lo_u32 v5, s9, v2
; GCN-NEXT:    v_mul_lo_u32 v2, s8, v2
; GCN-NEXT:    v_subrev_i32_e32 v0, vcc, s12, v0
; GCN-NEXT:    v_subb_u32_e32 v1, vcc, v1, v8, vcc
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v4, v3
; GCN-NEXT:    v_add_i32_e32 v3, vcc, v3, v5
; GCN-NEXT:    v_sub_i32_e64 v2, s[0:1], s10, v2
; GCN-NEXT:    v_sub_i32_e32 v4, vcc, s11, v3
; GCN-NEXT:    v_mov_b32_e32 v5, s9
; GCN-NEXT:    v_subb_u32_e64 v4, vcc, v4, v5, s[0:1]
; GCN-NEXT:    v_subrev_i32_e64 v6, s[2:3], s8, v2
; GCN-NEXT:    v_subbrev_u32_e64 v7, vcc, 0, v4, s[2:3]
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s9, v7
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s8, v6
; GCN-NEXT:    v_cndmask_b32_e64 v9, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s9, v7
; GCN-NEXT:    v_cndmask_b32_e32 v8, v8, v9, vcc
; GCN-NEXT:    v_subb_u32_e64 v4, vcc, v4, v5, s[2:3]
; GCN-NEXT:    v_subrev_i32_e32 v5, vcc, s8, v6
; GCN-NEXT:    v_subbrev_u32_e32 v4, vcc, 0, v4, vcc
; GCN-NEXT:    v_cmp_ne_u32_e64 s[2:3], 0, v8
; GCN-NEXT:    v_cndmask_b32_e64 v4, v7, v4, s[2:3]
; GCN-NEXT:    v_mov_b32_e32 v7, s11
; GCN-NEXT:    v_subb_u32_e64 v3, vcc, v7, v3, s[0:1]
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s9, v3
; GCN-NEXT:    v_cndmask_b32_e64 v7, 0, -1, vcc
; GCN-NEXT:    v_cmp_le_u32_e32 vcc, s8, v2
; GCN-NEXT:    v_cndmask_b32_e64 v8, 0, -1, vcc
; GCN-NEXT:    v_cmp_eq_u32_e32 vcc, s9, v3
; GCN-NEXT:    v_cndmask_b32_e32 v7, v7, v8, vcc
; GCN-NEXT:    v_cmp_ne_u32_e32 vcc, 0, v7
; GCN-NEXT:    v_cndmask_b32_e32 v3, v3, v4, vcc
; GCN-NEXT:    v_cndmask_b32_e64 v4, v6, v5, s[2:3]
; GCN-NEXT:    v_cndmask_b32_e32 v2, v2, v4, vcc
; GCN-NEXT:    v_xor_b32_e32 v2, s14, v2
; GCN-NEXT:    v_xor_b32_e32 v3, s14, v3
; GCN-NEXT:    v_mov_b32_e32 v4, s14
; GCN-NEXT:    v_subrev_i32_e32 v2, vcc, s14, v2
; GCN-NEXT:    v_subb_u32_e32 v3, vcc, v3, v4, vcc
; GCN-NEXT:    buffer_store_dwordx4 v[0:3], off, s[4:7], 0
; GCN-NEXT:    s_endpgm
  %shl.y = shl <2 x i64> <i64 4096, i64 4096>, %y
  %r = srem <2 x i64> %x, %shl.y
  store <2 x i64> %r, <2 x i64> addrspace(1)* %out
  ret void
}
